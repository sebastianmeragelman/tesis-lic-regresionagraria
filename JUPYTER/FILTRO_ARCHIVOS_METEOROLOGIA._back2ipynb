{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fea698-b5d5-4c3a-a7b2-ef7c0396e6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a739b51-3b72-4450-b9df-9d86cffdba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos path de carpeta del proyecto\n",
    "path_relativo =  r\"../SET DE DATOS/UNIDO/CLIMA/Provinciales\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c2dfed-4bc4-4911-aee3-b6759eb4fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos los archivos disponibles\n",
    "!ls \"../SET DE DATOS/UNIDO/CLIMA/Provinciales\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b435cf1e-9013-4850-b03e-56605d265381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4d3d6-c6c5-446f-85d1-d6e72bfcbd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3ca55e-a6bc-45e5-956e-970f11231607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listar_archivos_zip(directorio):\n",
    "  \"\"\"\n",
    "  Lista todos los archivos .xls en el directorio especificado.\n",
    "\n",
    "  Args:\n",
    "    directorio: La ruta del directorio a listar.\n",
    "  \"\"\"\n",
    "\n",
    "  archivos_xls = []\n",
    "  try:\n",
    "    for archivo in os.listdir(directorio):\n",
    "      if archivo.endswith(\".zip\"):\n",
    "        archivos_xls.append(archivo)\n",
    "    return archivos_xls\n",
    "  except FileNotFoundError:\n",
    "    print(f\"Error: El directorio '{directorio}' no existe.\")\n",
    "    return []\n",
    "\n",
    "\n",
    "def listar_archivos_xls(directorio):\n",
    "  \"\"\"\n",
    "  Lista todos los archivos .xls en el directorio especificado.\n",
    "\n",
    "  Args:\n",
    "    directorio: La ruta del directorio a listar.\n",
    "  \"\"\"\n",
    "\n",
    "  archivos_xls = []\n",
    "  try:\n",
    "    for archivo in os.listdir(directorio):\n",
    "      if archivo.endswith(\".xls\"):\n",
    "        archivos_xls.append(archivo)\n",
    "    return archivos_xls\n",
    "  except FileNotFoundError:\n",
    "    print(f\"Error: El directorio '{directorio}' no existe.\")\n",
    "    return []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def descomprimir_zip(archivo_zip, directorio_destino):\n",
    "    \"\"\"\n",
    "    Descomprime un archivo ZIP en el directorio de destino especificado.\n",
    "\n",
    "    Args:\n",
    "        archivo_zip: La ruta del archivo ZIP que se va a descomprimir.\n",
    "        directorio_destino: La ruta del directorio donde se extraerán los archivos.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(archivo_zip, 'r') as zip_ref:\n",
    "            zip_ref.extractall(directorio_destino)\n",
    "        print(f\"El archivo '{archivo_zip}' se ha descomprimido correctamente en '{directorio_destino}'.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: El archivo '{archivo_zip}' no se encontró.\")\n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"Error: El archivo '{archivo_zip}' no es un archivo ZIP válido.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error inesperado: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa825972-03e3-4860-91d1-2655a1adc55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1168ebe9-31e1-42cb-a560-45ed075e2acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomprimimos los archivos zip con los xls\n",
    "for archivo in listar_archivos_zip(path_relativo):\n",
    "    descomprimir_zip(path_relativo+'/'+archivo, path_relativo+'/ARCHIVOS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108ca90-090a-48cf-80e8-18b2e5071ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ecf5d8-a800-4de3-b5b8-59af71e631df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listamos los archivos obtenidos\n",
    "listar_archivos_xls(path_relativo+'/ARCHIVOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff0ff1-c5c4-4127-9edb-1c1d7727e1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0580543-6b3f-49f2-a4f9-a6046e344996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abro unos de los archivos xls para ver el formato - convierto en DataFrame\n",
    "df_tmp = pd.read_excel(path_relativo+'/ARCHIVOS/'+listar_archivos_xls(path_relativo+'/ARCHIVOS')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e014b-afc8-4e78-9873-f428baf59b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f5a2b-5666-4451-aed3-e9ef9ae5b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa43b846-e53e-4b62-ad19-c52d35f75a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebadc19b-f97c-4a12-9ef9-93475edb5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizamos los datos del dataframe para obtener datos sobre los registros que tiene\n",
    "def control_reg_utiles(df) -> dict:\n",
    "    inicio = df['Fecha'].min()\n",
    "    fin = df['Fecha'].max()\n",
    "    n_registros= df_tmp.shape[0]\n",
    "\n",
    "    dic_parametros = {}\n",
    "    for columna in df.columns:\n",
    "        reg = (df[~df[columna].isnull()].shape[0]*100)/n_registros\n",
    "        dic_parametros[columna] = reg\n",
    "        print(f\"{columna} : {reg:.2f}% validos\")\n",
    "    return dic_parametros\n",
    "control_reg_utiles(df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c1327-06e8-4e31-adb4-9a24d176dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listamos todas las columnas que encontramos entre todos los archivos y mostramos aquellos que no tienen formatu usable\n",
    "eliminar = []\n",
    "columnas=[]\n",
    "for archivo in listar_archivos_xls(path_relativo+'/ARCHIVOS'):\n",
    "    try:\n",
    "        df_tmp = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo)\n",
    "        for columna in df_tmp.columns:\n",
    "            columnas.append(columna)\n",
    "    except:\n",
    "        print(archivo)\n",
    "        eliminar.append(path_relativo+'/ARCHIVOS/'+archivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7792f-ea01-4755-82ad-b64c73f2fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_archivos(lista_archivos):\n",
    "    \"\"\"\n",
    "    Elimina los archivos especificados en la lista.\n",
    "\n",
    "    Args:\n",
    "        lista_archivos: Una lista de rutas de archivos a eliminar.\n",
    "    \"\"\"\n",
    "    for archivo in lista_archivos:\n",
    "        try:\n",
    "            os.remove(archivo)\n",
    "            print(f\"Archivo eliminado: {archivo}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: El archivo no fue encontrado: {archivo}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al eliminar el archivo {archivo}: {e}\")\n",
    "\n",
    "eliminar_archivos(eliminar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4347517-904f-4433-ad38-a7606549e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = list(set(columnas))\n",
    "\n",
    "len(columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5136e455-7d0e-47c7-ab11-3116fee880b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f70318a-02f8-46f8-9697-f00e7bf5b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_de_interes= ['Radiacion_Global','Heliofania_Efectiva','Radiacion_Neta','Velocidad_Viento_200cm_Media','Temperatura_Abrigo_150cm_Maxima','Temperatura_Inte_5cm','Humedad_Media','Tesion_Vapor_Media','Rocio_Medio','Precipitacion_Pluviometrica','Precipitacion_Maxima_30minutos','Temperatura_Intemperie_5cm_Minima','Temperatura_Suelo_10cm_Media','Temperatura_Suelo_5cm_Media','Humedad_Media_8_14_20','Temperatura_Intemperie_50cm_Minima','Velocidad_Viento_Maxima','Temperatura_Abrigo_150cm','Evapotranspiracion_Potencial','Temperatura_Intemperie_150cm_Minima','Granizo','Temperatura_Abrigo_150cm_Minima']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecdfe79-2cf1-49eb-9046-61b90d6909dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_variables ={}\n",
    "for i in variables_de_interes:\n",
    "    dic_variables[i] = 0\n",
    "print(dic_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17acfc9a-2d47-4017-a925-f3a0f760274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_archivos = 0\n",
    "lista_descripcion_archivo=[]\n",
    "for archivo in listar_archivos_xls(path_relativo+'/ARCHIVOS'):\n",
    "    print(archivo)\n",
    "    df_tmp = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo)\n",
    "    cantidad_archivos=cantidad_archivos+1\n",
    "    inicio = df_tmp['Fecha'].min()\n",
    "    fin = df_tmp['Fecha'].max()\n",
    "    n_registros= df_tmp.shape[0]\n",
    "    lista_descripcion_archivo.append((archivo,inicio,fin,n_registros))\n",
    "\n",
    "    print(f\"-----{archivo}----------\")\n",
    "    for columna in variables_de_interes:\n",
    "        try:\n",
    "            print(f\"{columna} : {(df_tmp[~df_tmp[columna].isnull()].shape[0]*100)/n_registros:.2f}% validos\")    \n",
    "            print(f\"Primer registro: {inicio} - Ultimo Registro: {fin}\")\n",
    "            dic_variables[columna] = dic_variables[columna] + 1\n",
    "        except:\n",
    "            pass\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6829ef-f88c-49e5-b395-d9ce03bad9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que las columnas esten presentes en todos los archivos\n",
    "dic_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf29da-ed4e-4f6b-9b60-6a52165e1f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e07852e-fc8b-4cc0-bc73-11c8c71d5be0",
   "metadata": {},
   "source": [
    "La mayoria de los archivos contienen los mismos registros, el problema que se plantea es que la variable Granizo solo esta presente en 26 de los archivos y es una variable de gran importancia, vamos a identificar cuales son los archivos y su procedencia para ver si el motivo es la falta de granizo en los otros 99 archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b07202-b27b-4e91-8577-1209ae31efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for archivo in listar_archivos_xls(path_relativo+'/ARCHIVOS'):\n",
    "    df_tmp = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo)\n",
    "    if 'Granizo' in df_tmp.columns:\n",
    "        print(archivo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044aa60-b2f9-4b50-8a43-516f1998b0de",
   "metadata": {},
   "source": [
    "Se presenta el problema que solo algunos centros meteorologicos guardan registros sobre el granizo, por lo que podemos perder mucha información de utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c4d926-591e-4393-9dcb-ac391185d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el resumen de registros de todos los archivos\n",
    "lista_descripcion_archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218cdb5-7f35-414a-a666-8250a9eb3458",
   "metadata": {},
   "source": [
    "No nos es de utilidad trabajar con registros truncos , buscamos la mayor amplitud de datos posible con una fecha de corte cercana a 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342389a3-97d6-410e-ad56-a8389812c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumen_archivos = pd.DataFrame(lista_descripcion_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ce35d-34e3-45a0-bf89-4c67a48b921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumen_archivos.columns = ['Nombre','Inicio','Fin','Registros']\n",
    "df_resumen_archivos.info()\n",
    "df_resumen_archivos['Inicio'] = pd.to_datetime(df_resumen_archivos['Inicio'])\n",
    "df_resumen_archivos['Fin'] = pd.to_datetime(df_resumen_archivos['Fin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b5b82-7076-411c-b634-a4d9848588b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumen_archivos[df_resumen_archivos['Registros']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c52e8f-3e54-4037-a0f5-05ba04e550a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumen_archivos[df_resumen_archivos['Registros']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5d885-2c94-4c46-8731-13a654094d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f7d994-f6ee-4c20-9e66-8ed7d983af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos un vistazo de cuantos archivos tienen registros hasta determinada fecha\n",
    "fecha_limite = pd.to_datetime('2021-12-31')\n",
    "print(f\"Archivos con registros hasta el 2021 incluido {df_resumen_archivos[df_resumen_archivos['Fin']>=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('2022-12-31')\n",
    "print(f\"Archivos con registros hasta el 2022 incluido {df_resumen_archivos[df_resumen_archivos['Fin']>=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('2023-12-31')\n",
    "print(f\"Archivos con registros hasta el 2023 incluido {df_resumen_archivos[df_resumen_archivos['Fin']>=fecha_limite].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c160bb5-31e9-4072-8d07-4bff01035d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos listado de archivos que vamos a conservar \n",
    "fecha_limite = pd.to_datetime('2022-12-31')\n",
    "df_listado_archivos_validos = df_resumen_archivos[df_resumen_archivos['Fin']>=fecha_limite]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a312ff-eaf2-4178-8145-4dd252e78c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos ahora la fecha de inicio de los registros, mas antiguo sea el dato mejor sera\n",
    "fecha_limite = pd.to_datetime('1970-01-01')\n",
    "print(f\"Archivos con registros desde el 1970 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('1980-01-01')\n",
    "print(f\"Archivos con registros desde el 1980 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('1990-01-01')\n",
    "print(f\"Archivos con registros desde el 1990 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('2000-01-01')\n",
    "print(f\"Archivos con registros desde el 2000 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('2010-01-01')\n",
    "print(f\"Archivos con registros desde el 2010 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "\n",
    "fecha_limite = pd.to_datetime('2012-01-01')\n",
    "print(f\"Archivos con registros desde el 2012 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('2013-01-01')\n",
    "print(f\"Archivos con registros desde el 2013 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('2014-01-01')\n",
    "print(f\"Archivos con registros desde el 2014 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fecha_limite = pd.to_datetime('2020-01-01')\n",
    "print(f\"Archivos con registros desde el 2020 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad7b339-d997-4af4-9261-c3261dde46d8",
   "metadata": {},
   "source": [
    "De los archivos iniciales nos quedamos con 209 que tenian formato valido, luego determinamos que uno de ellos no tenia registros, posterior a eso encontramos que entre 115 y 130 archivos tienen registros \"actuales\", de estos archivos tomamos aquellos con registros hasta el 31/12/2022 y verificamos que entre 12 y 19 archivos tienen registros de 1970 y 2010. Desde el 2012 comienzan a sumarse nuevas estaciones meteorologicas para registrar datos, llegando a 106 en 2020\n",
    "\n",
    "Vamos a generar dos set de datos para poder trabajar en una etapa posterior con la intención de buscar desde una generalidad poder predecir la tendencia mas especifica, asi uniremos por un lado los 11 archivos con registros desde el 1970 hasta el 2022 inclusive, y por otro lado los archivos desde el 2020 hasta el 2022 inclusive. La intención en una primera instancia sera ver si un modelo mas general pero con registros mas antiguos puede ser predictor para registros posteriores usando el otro set de datos (considerando que las ubicaciones geograficas de los centros meteorologicos no son las mismas, pero esperamos que los datos de latitud y longitud puedan brindar una tendencia semejante)\n",
    "\n",
    "Listado \"largo\" : Tendra mayor cantidad de registros historicos pero menor cantidad de provincias\n",
    "Listado \"corto\" : Tendra menor cantidad de registros historicos pero mayor alcance en cantidad de provincias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2180d2fc-60f8-4311-b20a-118bc5bf8aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion y creacion del DataFrame de mayor rango de fecha\n",
    "fecha_limite = pd.to_datetime('1970-01-01')\n",
    "df_listado_archivos_validos_largo = df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite]\n",
    "\n",
    "# Definicion y creacion del DataFrame de menor rango de fecha\n",
    "fecha_limite = pd.to_datetime('2020-01-01')\n",
    "df_listado_archivos_validos_corto = df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570dd78-6d06-40f5-a6e2-c3151dbb2a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listado_archivos_validos_corto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fee40c-e77e-4811-957c-b16c53c64366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587595e-0d55-4079-b1be-454afa6581df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el formato de la segunda hoja para ver si todos los archivos tienen el mismo formato\n",
    "columnas_extendido= []\n",
    "for archivo in listar_archivos_xls(path_relativo+'/ARCHIVOS'):\n",
    "    df_tmp = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo,sheet_name=1)\n",
    "    columnas= list(df_tmp.columns)\n",
    "    for col in columnas:\n",
    "        if col not in columnas_extendido:\n",
    "            columnas_extendido.append(col)\n",
    "        else:\n",
    "            pass\n",
    "print(columnas_extendido)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96334752-e2e3-4cbb-8ce4-77bdf2345a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resumen_validos = []\n",
    "for archivo_valido in list(df_listado_archivos_validos_corto['Nombre']):\n",
    "    df_tmp = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo_valido)\n",
    "\n",
    "    resumen_validos.append(control_reg_utiles(df_tmp) )\n",
    "    \n",
    "\n",
    "    \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b884a48d-610b-47ae-9c3c-ef3609996e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5664621-5ec7-45de-80ff-9656de25b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_resumen = {}\n",
    "for i in resumen_validos:\n",
    "    for parametro in list(i.keys()):\n",
    "        try:\n",
    "            dict_resumen[parametro] = i[parametro] + dict_resumen[parametro]\n",
    "        except:\n",
    "            dict_resumen[parametro] = i[parametro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa79beea-fc5f-43d7-bf27-1a59eead7ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la media de la usabilidad de una columna sobre el total de los archivos \n",
    "for param,valor in dict_resumen.items():\n",
    "    print(f\"{param} {valor/len(resumen_validos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaabe5e-445f-4b62-8441-d6954070b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la media de la usabilidad de una columna sobre el total de los archivos \n",
    "for param,valor in dict_resumen.items():\n",
    "    indice = valor/len(resumen_validos)\n",
    "    if indice > 70:\n",
    "        print(f\"{param} {indice}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fcfc84-9009-4bf6-b653-57844d57d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basado en el marco teorico seleccionamos las variables que puedan ser de interes a nuestro objetivo\n",
    "columnas_utiles= ['Fecha','Humedad_Media','Tesion_Vapor_Media','Rocio_Medio','Precipitacion_Pluviometrica','Temperatura_Suelo_10cm_Media','Humedad_Media_8_14_20','Velocidad_Viento_Maxima','Temperatura_Abrigo_150cm','Temperatura_Abrigo_150cm_Minima','Velocidad_Viento_200cm_Media','Temperatura_Abrigo_150cm_Maxima']\n",
    "                                                                        \n",
    "archivos_utiles_corto = df_listado_archivos_validos_corto['Nombre'].to_list()\n",
    "archivos_utiles_largo = df_listado_archivos_validos_largo['Nombre'].to_list()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad7254-4525-4c6b-877f-4ddbad3ae44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un DataFrame con todos los registros unidos de todos los archivos, seleccionando previamente los archivos que omitimos, las colunas de interes, y sumando datos de la estacion meteorologica\n",
    "df_corto = pd.DataFrame()\n",
    "\n",
    "for archivo in archivos_utiles_corto:\n",
    "    df_tmp_h0 = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo)\n",
    "    df_tmp_h1 = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo,sheet_name=1)\n",
    "    df_tmp_h1 = df_tmp_h1[['Provincia','Localidad','Latitud','Longitud']]\n",
    "    # Generamos el DataFrame con las columnas que vamos a rescatar de los registros\n",
    "    df_tmp_h0 = df_tmp_h0[columnas_utiles]\n",
    "    # Agregamos los datos de la segunda hoja\n",
    "    df_tmp_h0[['Provincia','Localidad','Latitud','Longitud']] = df_tmp_h1.iloc[0].tolist()\n",
    "    # Unimos todos los archivos en un unico dataframe\n",
    "    df_corto = pd.concat([df_corto,df_tmp_h0])        \n",
    "df_corto['Fecha'] = pd.to_datetime(df_corto['Fecha'])\n",
    "#punto de respaldo y backup - generamos archivo\n",
    "df_corto.to_csv(\"registro_meteorologico_20al22.csv\")\n",
    "\n",
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8fafc4-419f-4b71-8db8-8fcf548aba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" En caso de reiniciar el entorno se puede descomentar las siguientes 2 lineas y avanzar desde este punto\"\"\"\n",
    "#df_corto = pd.read_csv(\"registro_meteorologico_20al22.csv\")\n",
    "#df_corto.drop(df_corto.columns[0],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a3aeb-097f-472f-8602-cd77d48a3b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Producimos el Data Frame largo\n",
    "df_largo = pd.DataFrame()\n",
    "\n",
    "for archivo in archivos_utiles_largo:\n",
    "    df_tmp_h0 = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo)\n",
    "    df_tmp_h1 = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo,sheet_name=1)\n",
    "    df_tmp_h1 = df_tmp_h1[['Provincia','Localidad','Latitud','Longitud']]\n",
    "    # Generamos el DataFrame con las columnas que vamos a rescatar de los registros\n",
    "    df_tmp_h0 = df_tmp_h0[columnas_utiles]\n",
    "    # Agregamos los datos de la segunda hoja\n",
    "    df_tmp_h0[['Provincia','Localidad','Latitud','Longitud']] = df_tmp_h1.iloc[0].tolist()\n",
    "    # Unimos todos los archivos en un unico dataframe\n",
    "    df_largo = pd.concat([df_largo,df_tmp_h0])        \n",
    "\n",
    "df_largo['Fecha'] = pd.to_datetime(df_largo['Fecha'])\n",
    "# Respaldamos el archivo\n",
    "df_largo.to_csv(\"registro_meteorologico_70al22.csv\")\n",
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04905124-62bc-4022-8fb2-af845b529fa3",
   "metadata": {},
   "source": [
    "# INICIO ANALISIS DATAFRAME DE 2020 AL 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834f409-012b-4094-b8b4-18f17b896752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77acf3e1-611f-474f-8fcb-8ecbd564a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254c7db-065b-45a0-94c2-bed548f205d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay valores a controlar como el rocio medio cuyo minimo es un valor negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dcfce9-fe44-45b7-ac60-a3a963a43320",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_corto[df_corto['Rocio_Medio']<0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1060af-fba9-4a93-b53a-555119cc17af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos los valores negativos de Rocio Medio \n",
    "condicion = df_corto['Rocio_Medio']<0\n",
    "df_corto.loc[condicion, 'Rocio_Medio'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e441dd-90c4-491b-85c6-c1dc94462b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validamos que no hay valores negativo\n",
    "df_corto[df_corto['Rocio_Medio']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54bea9-b756-4e58-a893-13495b34bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos la distribucion de nulos por provincia por parametro\n",
    "for provincia in provincias:\n",
    "    print(f\"--------- {provincia}-----\")\n",
    "    print(df_corto[df_corto['Provincia']==provincia].info())\n",
    "    print(\"================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59cfa82-a6d3-4372-8cba-07e0447b67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a revisar los valores\n",
    "df_corto.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52118420-37e5-4fbe-b98a-d8faf44084bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos el alcance de que provincias estan listadas\n",
    "provincias = list(df_corto['Provincia'].unique())\n",
    "provincias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e95bb9-f9e6-4581-b128-f03b91b2e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos como estan conformados los registros por cada provincia\n",
    "for provincia in provincias:\n",
    "    print(f\"--------- {provincia}-----\")\n",
    "    print(df_corto[df_corto['Provincia']==provincia].info())\n",
    "    print(\"================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575fa85b-1c45-4007-a01c-28015ba9e890",
   "metadata": {},
   "source": [
    "Hay que evaluar como completar los registros faltantes de los campos que tienen valores nulos \n",
    "\n",
    " 1   Humedad_Media      \n",
    "\n",
    " 2   Tesion_Vapor_Media\n",
    " \n",
    " 3   Rocio_Medio       \n",
    " \n",
    " 4   Precipitacion_Pluviometrica\n",
    " \n",
    " 5   Temperatura_Suelo_10cm_Media \n",
    " \n",
    " 6   Humedad_Media_8_14_20        \n",
    " \n",
    " 7   Velocidad_Viento_Maxima      \n",
    " \n",
    " 8   Temperatura_Abrigo_150cm     \n",
    " \n",
    " 9   Temperatura_Abrigo_150cm_Minima\n",
    " \n",
    " 10  Velocidad_Viento_200cm_Media   \n",
    " \n",
    " 11  Temperatura_Abrigo_150cm_Maxima\n",
    "\n",
    "\n",
    " Vamos a definir una tecnica para cada parametro que siga las caracteristicas de dicha variable\n",
    " \n",
    " Humedad_Media\n",
    " \n",
    "Podriamos ver que parametros tenemos disponibles como no nulos para los valores nulos de humedad, y con esto armar un modelo simple de regresion lineal para obtener un valor estimado de humedad.\n",
    "\n",
    "Para esto vamos a verificar la correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc3f65-361f-4962-a15e-3ffebb9afc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que parametros tienen valores validos para nulos de Humedad Media\n",
    "df_corto[(df_corto['Humedad_Media'].isnull())].info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667d269-e460-475a-b36b-dbe0f62d235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_relacionadas = ['Velocidad_Viento_200cm_Media',\n",
    "                    'Velocidad_Viento_Maxima',\n",
    "                    'Temperatura_Abrigo_150cm_Maxima',\n",
    "                    'Humedad_Media',\n",
    "                    'Tesion_Vapor_Media',\n",
    "                    'Rocio_Medio',\n",
    "                    'Temperatura_Abrigo_150cm',\n",
    "                    'Temperatura_Abrigo_150cm_Minima',\n",
    "                    'Precipitacion_Pluviometrica',\n",
    "                    'Humedad_Media_8_14_20',\n",
    "                    'Temperatura_Suelo_10cm_Media'\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e423c0-d4ce-41f0-ba12-45d3fca83a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparamos los parametros para poder evaluar la correlacion eliminando los null\n",
    "df_corto_predictores = df_corto[var_relacionadas].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd82091-5693-404e-b709-07942ecfa348",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_correlacion = df_corto_predictores.corr()\n",
    "def ver_correlacion(matriz_correlacion):\n",
    "    # Configuración del estilo de seaborn\n",
    "    sns.set(style=\"white\")\n",
    "\n",
    "    # Creación de la máscara para la mitad superior de la matriz\n",
    "    mask = np.triu(np.ones_like(matriz_correlacion, dtype=bool))\n",
    "\n",
    "    # Configuración de la figura matplotlib\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Creación del mapa de calor con seaborn\n",
    "    cmap = sns.diverging_palette(230, 20, as_cmap=True) # Paleta de colores divergente\n",
    "    sns.heatmap(matriz_correlacion, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True, fmt=\".2f\")\n",
    "\n",
    "    # Título y ajustes adicionales\n",
    "    plt.title('Matriz de Correlación de Predictores', fontsize=16)\n",
    "    plt.xticks(rotation=45, ha='right') # Rotación de etiquetas del eje x\n",
    "    plt.yticks(rotation=0) # Asegura que las etiquetas del eje y no estén rotadas\n",
    "    plt.tight_layout() # Ajusta los parámetros de subtrama para un diseño compacto\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852dc3bd-fc15-4139-be57-83a9d2254dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ver_correlacion(matriz_correlacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c556f3d-6b36-4759-b35b-3107ceed6f03",
   "metadata": {},
   "source": [
    "La humedad media tiene un grado de correlación muy alto con la humedad_media_8_14_20 , por lo que vamos a tomar una sola de estas variables para el analisis y de ser posible y necesario completaremos la misma con los  valores de la variable Humedad_Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a75e4e-94fe-48d1-8091-446ba433b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos los registros de Humedad Media 8 14 20 nulos mientras Humedad Media no es nula\n",
    "df_corto[(df_corto['Humedad_Media_8_14_20'].isnull()) & (~df_corto['Humedad_Media'].isnull()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01afce9-1430-4b7f-a9c9-0b2ab4749614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el comportamiento estadistico de ambas variables\n",
    "df_corto[(~df_corto['Humedad_Media_8_14_20'].isnull()) & (~df_corto['Humedad_Media'].isnull()) ][['Humedad_Media_8_14_20','Humedad_Media']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb8f5f5-da4d-4893-9410-0bdae538f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La escala y valores de ambas caracteristicas es muy similar en los registros, por lo que vamos a realizar una asignacion directa de una variable a otra para los valores faltantes en vez de desarrollar una regresion para predecir los valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188cbf9-cb75-45b6-b457-61f3e4dc033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le asignamos los valores disponibles en Humedad_Media a Humedad_Media_8_14_20\n",
    "condicion = df_corto['Humedad_Media_8_14_20'].isnull() & (~df_corto['Humedad_Media'].isnull())\n",
    "df_corto.loc[condicion, 'Humedad_Media_8_14_20'] = df_corto.loc[condicion, 'Humedad_Media']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e16e8e6-29f8-4ee6-81ed-a05c72f3591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que no queden valores de Humedad_Media_8_14_20 null que puedan ser asignados por Humedad_Media\n",
    "df_corto[(df_corto['Humedad_Media_8_14_20'].isnull()) & (~df_corto['Humedad_Media'].isnull()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eab3ec-9fd6-490d-8aad-fec9da28f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a991f03-8aee-41e1-ae5a-2664e3ef0ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefinimos las variables de interes quitando la humedad_media\n",
    "df_corto = df_corto.drop(columns=['Humedad_Media'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48daa111-6018-49d9-b026-0d3005ad2c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los registros que tengan nulos en todas estas variables\n",
    "columnas_a_evaluar = [\n",
    "    'Tesion_Vapor_Media',\n",
    "    'Rocio_Medio',\n",
    "    'Precipitacion_Pluviometrica',\n",
    "    'Temperatura_Suelo_10cm_Media',\n",
    "    'Humedad_Media_8_14_20',\n",
    "    'Velocidad_Viento_Maxima',\n",
    "    'Temperatura_Abrigo_150cm',\n",
    "    'Temperatura_Abrigo_150cm_Minima',\n",
    "    'Velocidad_Viento_200cm_Media',\n",
    "    'Temperatura_Abrigo_150cm_Maxima'\n",
    "]\n",
    "\n",
    "# Crear una máscara booleana para filas con nulos en TODAS las columnas\n",
    "mascara_nulos_en_todas = df_corto[columnas_a_evaluar].isnull().all(axis=1)\n",
    "\n",
    "# Eliminar las filas que cumplen la condición (tienen nulos en TODAS las columnas)\n",
    "df_corto = df_corto[~mascara_nulos_en_todas]\n",
    "\n",
    "\n",
    "print(df_corto.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dec45a-cfbf-440e-b61b-6f8fcf73980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos la distribución de nulos en la Humedad por provincia\n",
    "for provincia in provincias:\n",
    "    print(f\"{provincia} Nulos en Humedad Media 8 14 20: {df_corto[df_corto['Provincia']==provincia]['Humedad_Media_8_14_20'].isnull().sum()} sobre {df_corto[df_corto['Provincia']==provincia]['Humedad_Media_8_14_20'].shape[0]} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055cc9a3-d075-4787-b317-f54f805da365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizar_nulos(serie):\n",
    "    \"\"\"Visualiza la ubicación de los valores nulos en una serie.\"\"\"\n",
    "    nulos = serie.isnull()\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(nulos, marker='|', linestyle='None')\n",
    "    plt.title('Ubicación de valores nulos')\n",
    "    plt.xlabel('Índice')\n",
    "    plt.ylabel('Nulo')\n",
    "    plt.yticks([0, 1], ['No Nulo', 'Nulo'])\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce6e7d-7a7e-46c7-94d3-63152c2729f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a ver graficamente la distribución de nulos en las principales prinvicias\n",
    "visualizar_nulos(df_corto[df_corto['Provincia']=='Buenos Aires']['Humedad_Media_8_14_20'])\n",
    "visualizar_nulos(df_corto[df_corto['Provincia']=='Buenos Aires']['Humedad_Media_8_14_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed541ad6-94a2-46a5-854a-a37d551c3c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196136af-8c68-40d2-a9b4-4b74b182f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de valores de humedad media en el tiempo por provincia\n",
    "for provincia in provincias:\n",
    "    datos = df_corto[df_corto['Provincia'] == provincia]\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.scatter(datos['Fecha'], datos['Humedad_Media_8_14_20'], alpha=0.6)\n",
    "    plt.title(f'Humedad Media (8-14-20) - {provincia}')\n",
    "    plt.xlabel('Índice / Fecha / Tiempo')\n",
    "    plt.ylabel('Humedad Media')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a660cf5-3017-4e7a-83d9-11b3dfbad640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos una muestra de boxplots por provincia por Humedad Media 8 14 20\n",
    "\n",
    "def plot_por_provincia_total(provincias:list,df,variable:str):\n",
    "    \"\"\"\n",
    "    Funcion para graficar un grid de boxplot de valor de la variable en la sumatoria de todos los meses\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cantidad de provincias\n",
    "    n = len(provincias)\n",
    "\n",
    "    # Organizamos el grid\n",
    "    cols = 3\n",
    "    rows = math.ceil(n / cols)\n",
    "\n",
    "    # Crear figura y ejes\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols * 5, rows * 4))\n",
    "    axs = axs.flatten()  # Para acceder a los ejes fácilmente en 1D\n",
    "\n",
    "    # Generar los boxplots\n",
    "    for i, provincia in enumerate(provincias):\n",
    "        datos = df[df['Provincia'] == provincia][variable].dropna()\n",
    "    \n",
    "        axs[i].boxplot(datos, vert=True)\n",
    "        axs[i].set_title(f'{provincia}')\n",
    "        axs[i].set_ylabel(variable)\n",
    "        axs[i].grid(True)\n",
    "\n",
    "    # Eliminar los subplots vacíos si hay menos provincias que cuadros\n",
    "    for j in range(i + 1, len(axs)):\n",
    "        fig.delaxes(axs[j])\n",
    "\n",
    "    fig.suptitle(f'Distribución de {variable} por Provincia', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Deja espacio para el título general\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#------\n",
    "def plot_por_provincia_mensual(provincias:list,df,variable:str):\n",
    "    \"\"\"\n",
    "    Funcion para graficar un grid de boxplot de valor de la variable desagregado por mes\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(12, 8))  # Ajusta el tamaño de la figura para mejor visualización\n",
    "\n",
    "    for provincia in provincias:\n",
    "        df_provincia = df[df['Provincia'] == provincia]\n",
    "        # Agrupa por MES y calcula el promedio de la variable\n",
    "        promedio_variable = df_provincia.groupby('MES')[variable].mean()\n",
    "        plt.plot(promedio_variable.index, promedio_variable.values, label=provincia)\n",
    "\n",
    "    plt.title(f'{variable} promedio por Mes y Provincia')\n",
    "    plt.xlabel('Mes')\n",
    "    plt.ylabel(variable)\n",
    "    plt.xticks(range(1, 13))  \n",
    "    plt.legend()  \n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_por_provincia_total(provincias,df_corto,'Humedad_Media_8_14_20')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd484e-1005-49ea-9ba3-e3a7389184e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a reformatear el campo Fecha para poder crear nuevas agrupaciones\n",
    "# Eliminar la hora en formato HH:MM:SS\n",
    "patron = r'\\d{2}:\\d{2}:\\d{2}'\n",
    "df_corto['Fecha'] = df_corto['Fecha'].str.replace(patron, \"\", regex=True)\n",
    "\n",
    "# Eliminar espacios extra en cada string (aplicado correctamente con .str)\n",
    "df_corto['Fecha'] = df_corto['Fecha'].str.strip()\n",
    "\n",
    "# Convertir a datetime\n",
    "df_corto['Fecha'] = pd.to_datetime(df_corto['Fecha'], format='%Y-%m-%d', errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b821a48-601b-4860-a11e-8c19eff1f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el campo MES\n",
    "df_corto['MES'] = df_corto['Fecha'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a28fc-9c31-419a-ad42-683d1a6164f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el valor medio mensual de humedad por provincia para completar los valores faltantes\n",
    "# Tomamos el valor medio mensual para el analisis debido a que el clima sigue patrones de series de tiempo regulares\n",
    "\n",
    "# Creamos un diccionario para registrar la media mensual por provincia\n",
    "dic_prov_humedad_media = {}\n",
    "\n",
    "# Asignamos a dicho diccionario la agrupacion mensual de la humedad_media_8_14_20 media\n",
    "for provincia in provincias:\n",
    "    dic_prov_humedad_media[provincia] = df_corto[df_corto['Provincia'] == provincia].groupby('MES')['Humedad_Media_8_14_20'].mean().to_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28bc512-321a-488e-83c9-2585afcbe534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteramos por cada provincia, por cada mes y asignamos el valor obtenido en el proceso anterior\n",
    "for provincia in provincias:\n",
    "    for mes in range(1, 13):  # Iteramos sobre los meses (1 a 12)\n",
    "        valor_medio = dic_prov_humedad_media[provincia][mes - 1]  # Obtenemos el valor medio del mes correspondiente\n",
    "        df_corto.loc[(df_corto['Provincia'] == provincia) & (df_corto['MES'] == mes) & (df_corto['Humedad_Media_8_14_20'].isnull()), 'Humedad_Media_8_14_20'] = valor_medio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc97b5c-3c3e-408c-8b2a-7c6fe2d0cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3798cf6-dfc1-4acb-9122-596c9ebb8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a verificar como queda la distrinución\n",
    "plot_por_provincia_total(provincias,df_corto,'Humedad_Media_8_14_20')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1843dcc-131c-4337-aaa7-42eb5784a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completar_valores_medios(df,variable:str,provincias:list):\n",
    "    # Asignamos el valor medio mensual de variable por provincia para completar los valores faltantes\n",
    "    dic_prov_media = {}\n",
    "\n",
    "    for provincia in provincias:\n",
    "        # Obtenemos el valor medio por mes por provicincia de la variable deseada , y lo cargamos en el diccionario como una lista de meses\n",
    "        dic_prov_media[provincia] = df[df['Provincia'] == provincia].groupby('MES')[variable].mean().to_list()\n",
    "\n",
    "\n",
    "    for provincia in provincias: \n",
    "        for mes in range(1, 13):  # Iteramos sobre los meses (1 a 12)\n",
    "            valor_medio = dic_prov_media[provincia][mes - 1]  # Obtenemos el valor medio del mes correspondiente\n",
    "            df.loc[(df['Provincia'] == provincia) & (df['MES'] == mes) & (df[variable].isnull()), variable] = valor_medio\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6c689-fde5-4dcc-95b1-bddb95a49f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos los valores faltantes/nulos como media de las siguientes variables\n",
    "df_corto = completar_valores_medios(df_corto,'Tesion_Vapor_Media',provincias)\n",
    "df_corto = completar_valores_medios(df_corto,'Rocio_Medio',provincias)\n",
    "df_corto = completar_valores_medios(df_corto,'Velocidad_Viento_200cm_Media',provincias)\n",
    "df_corto = completar_valores_medios(df_corto,'Precipitacion_Pluviometrica',provincias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b382d-7d75-4c1b-974b-351b8d422500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466ca5c-68bc-4bbc-b11b-97804abd3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_corto[['Temperatura_Abrigo_150cm','Temperatura_Abrigo_150cm_Minima','Temperatura_Abrigo_150cm_Maxima','Temperatura_Suelo_10cm_Media']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70bb76d-4b1a-44df-91a5-f39d7a1c2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto[['Temperatura_Abrigo_150cm','Temperatura_Abrigo_150cm_Minima','Temperatura_Abrigo_150cm_Maxima','Temperatura_Suelo_10cm_Media']].dropna().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea2829-317e-4e69-aecd-50b6365287aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "variables_predictoras = 'Temperatura_Abrigo_150cm'\n",
    "variable_objetivo = 'Temperatura_Suelo_10cm_Media'\n",
    "\n",
    "# Eliminar nulos\n",
    "df_filtrado = df_corto[(df_corto['Provincia']=='Buenos Aires') & (df_corto['MES']==1) ].dropna(subset=[variables_predictoras, variable_objetivo])\n",
    "\n",
    "# Seleccionar columnas\n",
    "X = df_filtrado[variables_predictoras]\n",
    "y = df_filtrado[variable_objetivo]\n",
    "\n",
    "\n",
    "# Graficar\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel(variables_predictoras)\n",
    "plt.ylabel(variable_objetivo)\n",
    "plt.title('Relación entre ' + variables_predictoras + ' y ' + variable_objetivo)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d718a5-3466-472f-83b7-88e9ce9997f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b2444e-bd2a-455c-8080-8f1cc6a3404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a completar los datos faltantes de Temperatura Suelo a 10cm media, como faltan tantos valores vamos a intentar \n",
    "#aprovechar que las otras temperaturas tienen una correlacion aceptable e intentaremos hacer un regresor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def regresion_lineal_total(df: pd.DataFrame, variables_predictoras: list,variable_objetivo: str):\n",
    "    \"\"\"\n",
    "    Funcion para obtener un regresor con sus metricas\n",
    "    \"\"\"\n",
    "\n",
    "    # Filtrar registros sin valores nulos en variables predictoras y objetivo\n",
    "    df_filtrado = df.dropna(subset=variables_predictoras + [variable_objetivo])\n",
    "\n",
    "    # Separar variables predictoras (X) y variable objetivo (y)\n",
    "    X = df_filtrado[variables_predictoras]\n",
    "    y = df_filtrado[variable_objetivo]\n",
    "\n",
    "    #División de los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    #Creación y entrenamiento del modelo de regresión lineal\n",
    "    modelo = LinearRegression()\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    #Predicciones y evaluación del modelo\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    # Calcular métricas de evaluación\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Error Cuadrático Medio (MSE): {mse}\")\n",
    "    print(f\"Coeficiente de Determinación (R2): {r2}\")\n",
    "\n",
    "    #Visualización de los resultados\n",
    "\n",
    "\n",
    "    plt.scatter(y_test, y_pred)\n",
    "    plt.xlabel(\"Valores reales\")\n",
    "    plt.ylabel(\"Valores predichos\")\n",
    "    plt.title(\"Valores reales vs. Valores predichos\")\n",
    "    plt.show()\n",
    "\n",
    "    return modelo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def regresion_lineal_provincial(df: pd.DataFrame ,prov,variables_predictoras: list,variable_objetivo: str):\n",
    "    \"\"\"\n",
    "    Funcion para obtener un regresor con sus metricas\n",
    "    \"\"\"\n",
    "\n",
    "    # Filtrar registros sin valores nulos en variables predictoras y objetivo\n",
    "    df_filtrado = df.dropna(subset=variables_predictoras + [variable_objetivo])\n",
    "\n",
    "    # Separar variables predictoras (X) y variable objetivo (y)\n",
    "    X = df_filtrado[df_filtrado['Provincia']==prov][variables_predictoras]\n",
    "    y = df_filtrado[df_filtrado['Provincia']==prov][variable_objetivo]\n",
    "\n",
    "    #División de los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    #Creación y entrenamiento del modelo de regresión lineal\n",
    "    modelo = LinearRegression()\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    #Predicciones y evaluación del modelo\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    # Calcular métricas de evaluación\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Error Cuadrático Medio (MSE): {mse}\")\n",
    "    print(f\"Coeficiente de Determinación (R2): {r2}\")\n",
    "\n",
    "    #Visualización de los resultados\n",
    "\n",
    "\n",
    "    plt.scatter(y_test, y_pred)\n",
    "    plt.xlabel(\"Valores reales\")\n",
    "    plt.ylabel(\"Valores predichos\")\n",
    "    plt.title(\"Valores reales vs. Valores predichos\")\n",
    "    plt.show()\n",
    "\n",
    "    return modelo\n",
    "\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm',\n",
    "    'Temperatura_Abrigo_150cm_Minima',\n",
    "    'Temperatura_Abrigo_150cm_Maxima'\n",
    "                        ]\n",
    "\n",
    "variable_objetivo = 'Temperatura_Suelo_10cm_Media'\n",
    "\n",
    "prov=\"Buenos Aires\"\n",
    "\n",
    "modelo_bsas = regresion_lineal_provincial(df_corto ,prov,variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4dd6dc-fc97-4297-baec-b3d352787ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_lineal_provincial_mensual(df: pd.DataFrame ,prov,variables_predictoras: list,variable_objetivo: str,mes=int):\n",
    "    \"\"\"\n",
    "    Funcion para obtener un regresor con sus metricas\n",
    "    \"\"\"\n",
    "\n",
    "    # Filtrar registros sin valores nulos en variables predictoras y objetivo\n",
    "    df_filtrado = df[ (df['Provincia']==prov) & (df['MES']==mes)].dropna(subset=variables_predictoras + [variable_objetivo])\n",
    "\n",
    "    # Separar variables predictoras (X) y variable objetivo (y)\n",
    "    X = df_filtrado[variables_predictoras]\n",
    "    y = df_filtrado[variable_objetivo]\n",
    "\n",
    "    #División de los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    #Creación y entrenamiento del modelo de regresión lineal\n",
    "    modelo = LinearRegression()\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    #Predicciones y evaluación del modelo\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    # Calcular métricas de evaluación\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Error Cuadrático Medio (MSE): {mse}\")\n",
    "    print(f\"Coeficiente de Determinación (R2): {r2}\")\n",
    "\n",
    "    #Visualización de los resultados\n",
    "\n",
    "\n",
    "    plt.scatter(y_test, y_pred)\n",
    "    plt.xlabel(\"Valores reales\")\n",
    "    plt.ylabel(\"Valores predichos\")\n",
    "    plt.title(\"Valores reales vs. Valores predichos\")\n",
    "    plt.show()\n",
    "\n",
    "    return modelo\n",
    "\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm',\n",
    "    'Temperatura_Abrigo_150cm_Minima',\n",
    "    'Temperatura_Abrigo_150cm_Maxima'\n",
    "                        ]\n",
    "\n",
    "variable_objetivo = 'Temperatura_Suelo_10cm_Media'\n",
    "\n",
    "prov=\"Buenos Aires\"\n",
    "\n",
    "modelo_bsas = regresion_lineal_provincial_mensual(df_corto ,prov,variables_predictoras,variable_objetivo,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c23b7b-72e6-4e19-81b0-87e3a1b3d367",
   "metadata": {},
   "source": [
    "Vemos un valor de predicción bastante malo, intentaremos otra forma de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b278104-dcca-4f45-9beb-1551415bb5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetimos quitando las variables con menor correlacion y ejecutamos sobre todo el set de datos\n",
    "\n",
    "\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm'\n",
    "]\n",
    "\n",
    "variable_objetivo = 'Temperatura_Suelo_10cm_Media'\n",
    "\n",
    "\n",
    "prov=\"Buenos Aires\"\n",
    "\n",
    "modelo_bsas = regresion_lineal_provincial(df_corto ,prov,variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d34a3-7f6d-42ee-b8da-408051520579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ae231ad-5a6f-4225-b6c3-3286ed08c4d1",
   "metadata": {},
   "source": [
    "Si bien logramos mejorar los resultados, siguen siendo muy bajos para que tenga sentido utilizar un regresor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc4aacc-a868-4b7a-b5e3-0dd8f6c6aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los valores siguen siendo bajos por lo que vamos a utilizar directamente el valor medio estacional\n",
    "df_corto = completar_valores_medios(df_corto,'Temperatura_Suelo_10cm_Media',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd12b8-9371-471e-8146-437f91dc813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e6b36a-7a4a-4fe1-ae8b-b32b4979b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avanzamos con la variable Precipitacion_Pluviometrica, para esto realizamos una inspeccion de sus estadisticos\n",
    "df_corto['Precipitacion_Pluviometrica'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f7df15-697d-4ff0-951a-9dcb30c4907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_por_provincia_mensual(provincias,df_corto,'Precipitacion_Pluviometrica')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eed728-9935-41ae-8684-2ce76a3c6160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_boxplot_grid(df, provincia_col:str, mes_col:str, valor_col:str):\n",
    "    \"\"\"Crea una grid de boxplots\n",
    "    in: \n",
    "        df: DataFrame a analizar\n",
    "        provincia_col: nombre de la columna donde estan listadas las provincias\n",
    "        mes_col: nombre de la columna donde estan listados los meses\n",
    "        valor_col: nombre de la columna a analizar\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Cada grupo tenga todos los meses\n",
    "    grupos_completos = []\n",
    "    for provincia in df[provincia_col].unique():\n",
    "        for mes in range(1, 13):\n",
    "            grupos_completos.append((provincia, mes))\n",
    "\n",
    "    df_grupos_completos = pd.DataFrame(grupos_completos, columns=[provincia_col, mes_col])\n",
    "    df_completo = pd.merge(df_grupos_completos, df, on=[provincia_col, mes_col], how='left')\n",
    "\n",
    "    # Crear FacetGrid con datos completos\n",
    "    g = sns.FacetGrid(df_completo, col=provincia_col, col_wrap=3, height=4, aspect=1.2)\n",
    "\n",
    "    # Crear boxplots\n",
    "    def boxplot_con_manejo_de_errores(data, **kwargs):\n",
    "        try:\n",
    "            sns.boxplot(data=data, x=mes_col, y=valor_col, **kwargs)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error en boxplot: {e}\")\n",
    "\n",
    "    g.map_dataframe(boxplot_con_manejo_de_errores)\n",
    "\n",
    "    g.set_axis_labels('Mes', valor_col)\n",
    "    g.set_titles(col_template='{col_name}')\n",
    "    g.set_xticklabels(range(1, 13))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "crear_boxplot_grid(df_corto, 'Provincia', 'MES', 'Precipitacion_Pluviometrica')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ee60d-452c-4329-89da-b51306e556ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El evento lluvia sigue siendo atipico , sobre todo en los meses mas lluviosos, en los menos lluviosos es menor el indice de valores oultiers\n",
    "# La matriz de correlacion no mostro ninguna correlacion lineal entre la lluvia y otras variables, por lo que vamos a tomar la normal mensual para completar los regisros.\n",
    "def completar_valores_normal(df: pd.DataFrame,variable:str,provincias:list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Funcion para completar los valores NA de la columna variable con los valores Normales de dicha columna por MES por Provincia\n",
    "    \"\"\"\n",
    "    # Obtenemos el valor medio mensual de humedad por provincia para completar los valores faltantes\n",
    "    dic_prov_normal = {}\n",
    "    # Obtengo la mediana o el valor normal mensual por provincia de la variable\n",
    "    for provincia in provincias:\n",
    "        dic_prov_normal[provincia] = df[df['Provincia'] == provincia].groupby('MES')[variable].median().to_list()\n",
    "\n",
    "\n",
    "    for provincia in provincias: \n",
    "        for mes in range(1, 13):  # Iteramos sobre los meses (1 a 12)\n",
    "            # Obtenemos el valor medio del mes correspondiente\n",
    "            valor_normal = dic_prov_normal[provincia][mes - 1]  \n",
    "            # Asignamos el valor medio del mes correspondiente para cada Provincia\n",
    "            df.loc[(df['Provincia'] == provincia) & (df['MES'] == mes) & (df[variable].isnull()), variable] = valor_normal\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af5da25-9c85-4495-b4d1-ad3f8efe4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completamos los NA de Precipitacion_Pluviometrica usando su valor normal mensua\n",
    "df_corto = completar_valores_normal(df_corto,'Precipitacion_Pluviometrica',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a61ccd-4d7a-42c2-976c-ecca2377b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26855837-620c-45f3-abe1-aea7f14a218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_por_provincia_mensual(provincias,df_corto,'Precipitacion_Pluviometrica')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b11dab-55aa-47a0-8487-6e71040d9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comenzamos a analizar la Velocidad_Viento_Maxima , corroboramos sus estadisticos\n",
    "df_corto[\"Velocidad_Viento_Maxima\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a20b07-e718-4cc6-9c4a-d638d40c9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_por_provincia_mensual(provincias,df_corto,'Velocidad_Viento_Maxima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d28a2b-a422-44bf-ad81-9c6b51e5bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_boxplot_grid(df_corto, 'Provincia', 'MES', 'Velocidad_Viento_Maxima')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec85d532-acf5-4dbb-a292-83afdbdceb4e",
   "metadata": {},
   "source": [
    "Pareceria que hay varias provincias que no tienen datos historicos sobre la velocidad de viento maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f163a543-f10c-40d8-813c-1e14b3f5182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a realizar un control mas simple sobre la cantidad de registros por mes por Provincia\n",
    "conteo_por_mes_provincia = df_corto.groupby(['Provincia', 'MES'])['Velocidad_Viento_Maxima'].count().reset_index(name='conteo')\n",
    "\n",
    "for provincia in provincias:\n",
    "    print(conteo_por_mes_provincia[conteo_por_mes_provincia['Provincia']==provincia])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96ba7c-fd67-497a-aea9-5f569d28cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si bien podriamos intentar generar artificialmente valores para las provincias que no tengan registros, no podemos hacerlo con mecanismos de aprendizaje supervizado, lo que nos llevaria a no tener una buena metrica para evaluar el resultado.\n",
    "# Por lo que vamos a completar los valores de las provincias que tenemos registros y esperar poder conseguir en un futuro registros desde otra base de datos.\n",
    "\n",
    "# Completamos los valores na con el valor normal entre ellos\n",
    "df_corto = completar_valores_normal(df_corto,'Velocidad_Viento_Maxima',provincias)\n",
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a07f197-0cc4-4ec5-bb85-8f84df5af56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_boxplot_grid(df_corto, 'Provincia', 'MES', 'Velocidad_Viento_Maxima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4a976-2efa-467a-aa3f-114ab0115ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_por_provincia_mensual(provincias,df_corto,'Velocidad_Viento_Maxima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62368ac8-f7b8-4528-9f95-b86962f5c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avanzamos con la reconstruccion de registros de las Temperaturas de Abrigo, para esto analizamos la correlacion entre ellas\n",
    "df_corto[['Temperatura_Abrigo_150cm','Temperatura_Abrigo_150cm_Minima','Temperatura_Abrigo_150cm_Maxima']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edbbd1-c2ed-4647-aec7-878391af2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos que variables podrian poblar a cual\n",
    "print(f\"Registros Temp Abrigo null con Temp Abrigo Min no null:{df_corto[(df_corto['Temperatura_Abrigo_150cm'].isnull()) & ~(df_corto['Temperatura_Abrigo_150cm_Minima'].isnull())].shape[0]}\")\n",
    "print(f\"Registros Temp Abrigo null con Temp Abrigo Max no null:{df_corto[(df_corto['Temperatura_Abrigo_150cm'].isnull()) & ~(df_corto['Temperatura_Abrigo_150cm_Maxima'].isnull())].shape[0]}\")\n",
    "print(f\"Registros Temp Abrigo null con Temp Abrigo Min y Max no null:{df_corto[(df_corto['Temperatura_Abrigo_150cm'].isnull()) & ~(df_corto['Temperatura_Abrigo_150cm_Maxima'].isnull()) & ~(df_corto['Temperatura_Abrigo_150cm_Minima'].isnull()) ].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc9d432-8544-4c4a-ac1c-35c4cfc8eb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm_Minima'\n",
    "    \n",
    "]\n",
    "\n",
    "# Variable objetivo\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "\n",
    "\n",
    "\n",
    "regresion_lineal_total(df_corto,variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcffc7d-b656-48be-9f15-d29decfe84cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedemos a probar regresiones que puedan servir para completar registros.\n",
    "#Preparación de los datos\n",
    "# Variables predictoras\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm_Minima'\n",
    "    \n",
    "]\n",
    "\n",
    "# Variable objetivo\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "\n",
    "\n",
    "regresion_lineal_provincial(df_corto,'Buenos Aires',variables_predictoras,variable_objetivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3695f39c-20dc-4b8a-be40-3efbf2773215",
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_lineal_provincial_mensual(df_corto,'Buenos Aires',variables_predictoras,variable_objetivo,mes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66364772-f427-4dfa-8e73-f1fa1ef24ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_lineal_provincial(df_corto,'Santa Fe',variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad048c8b-9c36-41ac-9580-57e12e0aa322",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_predictoras = [ 'Temperatura_Abrigo_150cm_Minima']\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "\n",
    "modelo_min = regresion_lineal_total(df_corto,variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6204a09c-018e-495d-a249-1bd8e434fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Preparación de los datos\n",
    "# Variables predictoras\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm_Maxima'\n",
    "    \n",
    "]\n",
    "\n",
    "# Variable objetivo\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "regresion_lineal_provincial(df_corto,'Santa Fe',variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083f737-d4ab-424f-a6df-a4b91d76cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_predictoras = [ 'Temperatura_Abrigo_150cm_Maxima']\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "\n",
    "modelo_max = regresion_lineal_total(df_corto,variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1fbe4-e0c9-4464-a3a6-d216e4d968b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Preparación de los datos\n",
    "# Variables predictoras\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm_Minima','Temperatura_Abrigo_150cm_Maxima'\n",
    "    \n",
    "]\n",
    "\n",
    "# Variable objetivo\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "regresion_lineal_provincial(df_corto,'Santa Fe',variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b59e75-8986-419b-bcba-a305605da7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_predictoras = ['Temperatura_Abrigo_150cm_Minima', 'Temperatura_Abrigo_150cm_Maxima']\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "modelo_comb = regresion_lineal_total(df_corto,variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c7719-2480-4f87-a00c-31b551eadc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos a los valores null de Temperatura Abrigo 150 los valores del modelo de regresion para las variables Minima y Maxima\n",
    "# Definir variables predictoras\n",
    "variables_predictoras = ['Temperatura_Abrigo_150cm_Minima', 'Temperatura_Abrigo_150cm_Maxima']\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "# Filtro de filas que cumplen ambas condiciones\n",
    "# Resguardamos el Df\n",
    "df_corto_bk = df_corto.copy()\n",
    "\n",
    "filtro = df_corto[variables_predictoras].notnull().all(axis=1) & df_corto[variable_objetivo].isnull()\n",
    "\n",
    "# Seleccionar las filas y variables predictoras para la predicción\n",
    "df_prediccion = df_corto.loc[filtro, variables_predictoras]\n",
    "\n",
    "# Realizar la predicción\n",
    "predicciones = modelo_comb.predict(df_prediccion)\n",
    "\n",
    "# Asignar las predicciones a los valores nulos en el DataFrame original\n",
    "df_corto.loc[filtro, variable_objetivo] = predicciones\n",
    "\n",
    "# 3. (Opcional) Verificar los resultados\n",
    "print(df_corto[filtro][[variable_objetivo] + variables_predictoras])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e676941b-ed89-4605-bd28-d2a4dea8bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos los valores predichos con la predictora de Minima\n",
    "\n",
    "# Definir variables predictoras\n",
    "variables_predictoras = ['Temperatura_Abrigo_150cm_Minima']\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "# Filtro de filas que cumplen ambas condiciones\n",
    "\n",
    "filtro = df_corto[variables_predictoras].notnull().all(axis=1) & df_corto[variable_objetivo].isnull()\n",
    "\n",
    "# Seleccionar las filas y variables predictoras para la predicción\n",
    "df_prediccion = df_corto.loc[filtro, variables_predictoras]\n",
    "\n",
    "# Realizar la predicción\n",
    "predicciones = modelo_min.predict(df_prediccion)\n",
    "\n",
    "# Asignar las predicciones a los valores nulos en el DataFrame original\n",
    "df_corto.loc[filtro, variable_objetivo] = predicciones\n",
    "\n",
    "\n",
    "print(df_corto[filtro][[variable_objetivo] + variables_predictoras])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04676bf5-af8e-4a0d-9a49-a591fec1950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos los valores predichos con la predictora de Maxima\n",
    "# Definir variables predictoras\n",
    "variables_predictoras = ['Temperatura_Abrigo_150cm_Maxima']\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "# Filtro de filas que cumplen ambas condiciones\n",
    "\n",
    "df_corto_bk = df_corto.copy()\n",
    "filtro = df_corto[variables_predictoras].notnull().all(axis=1) & df_corto[variable_objetivo].isnull()\n",
    "\n",
    "# Seleccionar las filas y variables predictoras para la predicción\n",
    "df_prediccion = df_corto.loc[filtro, variables_predictoras]\n",
    "\n",
    "# Realizar la predicción\n",
    "predicciones = modelo_max.predict(df_prediccion)\n",
    "\n",
    "# Asignar las predicciones a los valores nulos en el DataFrame original\n",
    "df_corto.loc[filtro, variable_objetivo] = predicciones\n",
    "\n",
    "# 3. (Opcional) Verificar los resultados\n",
    "print(df_corto[filtro][[variable_objetivo] + variables_predictoras])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef597dbe-661b-40c6-9dbc-af4276fbd5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a74f959-4ea0-4f52-8306-12ba5e734f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los registros que quedan sin completar los obtenemos por medio de la media mensual por provincia\n",
    "df_corto = completar_valores_medios(df_corto,'Temperatura_Abrigo_150cm',provincias)\n",
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3a26a-db9b-4850-9958-80c2410e7e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los registros que faltan los obtenemos por medio de la norma por provincia\n",
    "df_corto = completar_valores_normal(df_corto,'Temperatura_Abrigo_150cm_Minima',provincias)\n",
    "df_corto = completar_valores_normal(df_corto,'Temperatura_Abrigo_150cm_Maxima',provincias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e00b86-a626-4c95-b12c-259e460a612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad0af1b-9850-499d-8473-2e1d7692da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for provincia in list(df_corto['Provincia'].unique()):\n",
    "    print(f\"{provincia} - {df_corto[df_corto['Provincia'] == provincia]['Fecha'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710704e0-e3c6-4610-8538-b92b7f7a14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el set de datos reconstruido\n",
    "df_corto.to_csv(\"meteorologico_22_23.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa42da4b-6c11-4e84-939a-1bd7afefb3ba",
   "metadata": {},
   "source": [
    "# INICIO ANALISIS df_largo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2b1fc-fd01-41b1-af4f-48410c15c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_largo = pd.read_csv(\"registro_meteorologico_70al22.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac5849-f534-4133-aed4-c802fbd5ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22523a7e-55e1-4b5f-87f2-1f210f63dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f46cfc-2de7-42c8-ab1e-022a8fd2f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dejamos en 0 los valores de Rocio_Medio negativos\n",
    "condicion = df_largo['Rocio_Medio']<0\n",
    "df_largo.loc[condicion, 'Rocio_Medio'] = 0\n",
    "df_largo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f70074-2a56-4fed-9539-c33496d9dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un repaso de los registros historicos de este set de datos\n",
    "for provincia in list(df_largo['Provincia'].unique()):\n",
    "    print(f\"{provincia} - {df_largo[df_largo['Provincia'] == provincia]['Fecha'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a3c004-d601-4b0d-b212-5159e7048dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos la distribucion de nulos por provincia por parametro\n",
    "for provincia in provincias:\n",
    "    print(f\"--------- {provincia}-----\")\n",
    "    print(df_largo[df_largo['Provincia']==provincia].info())\n",
    "    print(\"================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ec6d2-c3c7-4180-a98e-9d6ca962a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos Chaco de los registros ya que no presenta ningun registro valido \n",
    "df_largo = df_largo[df_largo['Provincia']!=\"Chaco\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed3bcd-fca5-41b0-97b6-0685a64b2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comenzamos a regenerar los datos faltantes\n",
    "# Los datos originales de humedad media son muy pocos, por lo que intentar correr algun analisis sobre esta variable seria un desperdicio de recursos, ya vimos en el analisis de df_corto que era posible eliminar esta columna\n",
    "# Mismo criterio vamos a tener con la Temepratura_suelo_10cm\n",
    "df_largo.drop('Unnamed: 0', inplace=True,axis=1)\n",
    "df_largo.drop('Humedad_Media', inplace=True,axis=1)\n",
    "df_largo.drop('Temperatura_Suelo_10cm_Media', inplace=True,axis=1)\n",
    "df_largo.drop('Velocidad_Viento_Maxima', inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d2833-f36c-4678-9025-82929cae2fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2598c72-c2bc-4ab9-a0db-a924a9280c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la hora en formato HH:MM:SS\n",
    "patron = r'\\d{2}:\\d{2}:\\d{2}'\n",
    "df_largo['Fecha'] = df_largo['Fecha'].str.replace(patron, \"\", regex=True)\n",
    "\n",
    "# Eliminar espacios extra en cada string (aplicado correctamente con .str)\n",
    "df_largo['Fecha'] = df_largo['Fecha'].str.strip()\n",
    "\n",
    "# Convertir a datetime\n",
    "df_largo['Fecha'] = pd.to_datetime(df_largo['Fecha'], format='%Y-%m-%d', errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3decf32d-e08f-4c27-99de-9496a3d4ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Recortamos los registros para que no superen el 31 de dic de 2023 ya que no tendremos otros datos para cruzar\n",
    "fecha_limite_max = pd.to_datetime('2023-12-31')\n",
    "fecha_limite_min = pd.to_datetime('1970-01-01')\n",
    "\n",
    "# Filtrar el DataFrame primero por registros anteriores a fecha lim max\n",
    "df_filtrado = df_largo[df_largo['Fecha'] <= fecha_limite_max]\n",
    "# Filtrar por registros posteriores a fecha min\n",
    "df_filtrado = df_largo[df_largo['Fecha'] >= fecha_limite_min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421614a-f1ab-425a-af60-4ef4c3cbb52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c40477-7d62-4cd4-a8c1-2c985e170400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respaldamos el set de datos largo y pasamos a utilizar la version filtrada por años\n",
    "df_largo_bk = df_largo.copy()\n",
    "df_largo = df_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525e4bc0-879c-4697-98bd-b7f4ab0436a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f6b4e-6d33-487c-bfc1-babf2f52155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74e89e-105f-4fbe-a4e7-d60bb426b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correlaciones(df: pd.DataFrame,var_relacionadas:list):\n",
    "\n",
    "    # Eliminamos registros con NA para analizar la correlacion\n",
    "    df_largo_predictores = df[var_relacionadas].dropna()\n",
    "    matriz_correlacion = df_largo_predictores.corr()\n",
    "\n",
    "    # Configuración del estilo de seaborn\n",
    "    sns.set(style=\"white\")\n",
    "\n",
    "    # Creación de la máscara para la mitad superior de la matriz\n",
    "    mask = np.triu(np.ones_like(matriz_correlacion, dtype=bool))\n",
    "\n",
    "    # Configuración de la figura matplotlib\n",
    "    f, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "    # Creación del mapa de calor con seaborn\n",
    "    cmap = sns.diverging_palette(230, 20, as_cmap=True) # Paleta de colores divergente\n",
    "    sns.heatmap(matriz_correlacion, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True, fmt=\".2f\")\n",
    "\n",
    "    # Título y ajustes adicionales\n",
    "    plt.title('Matriz de Correlación de Predictores', fontsize=16)\n",
    "    plt.xticks(rotation=45, ha='right') # Rotación de etiquetas del eje x\n",
    "    plt.yticks(rotation=0) # Asegura que las etiquetas del eje y no estén rotadas\n",
    "    plt.tight_layout() # Ajusta los parámetros de subtrama para un diseño compacto\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ef0d0-8691-4335-a382-aec61aa57ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_relacionadas = ['Velocidad_Viento_200cm_Media', 'Temperatura_Abrigo_150cm_Maxima', 'Tesion_Vapor_Media', 'Rocio_Medio', 'Temperatura_Abrigo_150cm', 'Precipitacion_Pluviometrica', 'Humedad_Media_8_14_20','Temperatura_Abrigo_150cm_Minima']\n",
    "\n",
    "correlaciones(df_largo,var_relacionadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e95055-64e1-471b-9026-7a5641753618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero el parametro MES\n",
    "df_largo['MES'] = df_largo['Fecha'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ded13c-5788-4bc2-9212-3f3be854f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el parametro Tesion_Vapor_Media\n",
    "\n",
    "crear_boxplot_grid(df_largo, 'Provincia', 'MES', 'Tesion_Vapor_Media')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ffacf6-5c3a-4303-89c2-b2c8ae6b8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo[(df_largo['Provincia']==\"Corrientes\") & (df_largo['MES']==1)]['Tesion_Vapor_Media'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a86985-c7d3-4a4e-af8a-f39456535c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tesion_Vapor_Media nulos: {df_largo['Tesion_Vapor_Media'].isnull().sum()}\")\n",
    "print(f\"Rocio_Medio nulos: {df_largo['Rocio_Medio'].isnull().sum()}\")\n",
    "\n",
    "# Cruces de condiciones\n",
    "print(\"Rocio Medio Nulo para Tesion Vapor Media válido:\")\n",
    "print(df_largo[df_largo['Tesion_Vapor_Media'].notnull() & df_largo['Rocio_Medio'].isnull()].shape[0])\n",
    "\n",
    "print(\"Tesion de Vapor Media Nulo para Rocio Medio válido:\")\n",
    "print(df_largo[df_largo['Tesion_Vapor_Media'].isnull() & df_largo['Rocio_Medio'].notnull()].shape[0])\n",
    "\n",
    "print(\"Tesion de Vapor Media Nulo para Temperatura de Abrigo Mínima válida:\")\n",
    "print(df_largo[df_largo['Tesion_Vapor_Media'].isnull() & df_largo['Temperatura_Abrigo_150cm_Minima'].notnull()].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85165788-ed46-44d2-8acb-8cab43c1ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_predictoras = ['Tesion_Vapor_Media']\n",
    "variable_objetivo = 'Rocio_Medio'\n",
    "modelo1 = regresion_lineal_total(df_largo,variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa6db5c-ff0e-4708-98f8-ecda6d2888c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resguardamos el Df\n",
    "df_largo_bk = df_largo.copy()\n",
    "\n",
    "filtro = df_largo[variables_predictoras].notnull().all(axis=1) & df_largo[variable_objetivo].isnull()\n",
    "\n",
    "# Seleccionar las filas y variables predictoras para la predicción\n",
    "df_prediccion = df_largo.loc[filtro, variables_predictoras]\n",
    "\n",
    "# Realizar la predicción\n",
    "predicciones = modelo1.predict(df_prediccion)\n",
    "\n",
    "# Asignar las predicciones a los valores nulos en el DataFrame original\n",
    "df_largo.loc[filtro, variable_objetivo] = predicciones\n",
    "\n",
    "# 3. (Opcional) Verificar los resultados\n",
    "print(df_largo[filtro][[variable_objetivo] + variables_predictoras])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b2f583-c7f3-4372-8de7-3bef0bcecce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corregimos los valores por debajo de 0\n",
    "df_largo.loc[df_largo['Rocio_Medio'] < 0, 'Rocio_Medio'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b318458-08b3-45e8-996f-97d29ce37e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedemos a completar los valores faltantes usando la media y la moda\n",
    "provincias = list(df_largo['Provincia'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5105c-a157-487a-ba68-201f2ac5b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo = completar_valores_normal(df_largo,'Tesion_Vapor_Media',provincias)\n",
    "df_largo = completar_valores_normal(df_largo,'Rocio_Medio',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc018d-7705-4cc9-9539-b4a9c1cade86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71753957-39b1-4799-97f3-6cb2b4b6b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empezamos a verificar los valores de Humedad_Media_8_14_20\n",
    "crear_boxplot_grid(df_largo, 'Provincia', 'MES', 'Humedad_Media_8_14_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f7ab6-655c-4627-9a5a-a8306aad6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como ya se pudo ver la humedad no tiene correlacion con otras variables, y no encontramos grandes cantidades de outliers, por lo que usamos la media\n",
    "df_largo = completar_valores_medios(df_largo,'Humedad_Media_8_14_20',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d65256-3c66-4182-a641-bae05822cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_boxplot_grid(df_largo, 'Provincia', 'MES', 'Temperatura_Abrigo_150cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d8f9c-1972-4b2b-830e-03c055b23571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo['Temperatura_Abrigo_150cm'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afffb32-5928-4723-8d8d-a5ee64f6c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo['Temperatura_Abrigo_150cm'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8074acac-6a9a-4bcb-ab02-c16fa2068d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16a547-b16e-4afe-8a2a-67fd34b554d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo = completar_valores_medios(df_largo,'Temperatura_Abrigo_150cm',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb1bf4-7e64-4466-adb2-53357135f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313c77f-85e2-41a5-9fa5-de509005ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_boxplot_grid(df_largo, 'Provincia', 'MES', 'Precipitacion_Pluviometrica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981dbfb4-2742-445a-8144-8b9992fd1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673478b1-fc6e-465a-98ec-c9ebab34a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def asignar_precipitacion_global(df):\n",
    "    \"\"\"\n",
    "    Asigna valores de 'Precipitacion_Pluviometrica' de registros válidos a registros nulos\n",
    "    en la misma fecha y provincia, pero en diferente localidad, latitud o longitud.\n",
    "\n",
    "    Args:\n",
    "        df: El DataFrame a modificar.\n",
    "\n",
    "    Returns:\n",
    "        El DataFrame modificado con los valores nulos de 'Precipitacion_Pluviometrica' actualizados.\n",
    "    \"\"\"\n",
    "    # 1. Agrupar por 'Provincia' y 'Fecha'\n",
    "    grouped = df.groupby(['Provincia', 'Fecha'])\n",
    "\n",
    "    # 2. Función para aplicar a cada grupo\n",
    "    def asignar_grupo(grupo):\n",
    "        # 3. Verificar si hay algún valor no nulo de 'Precipitacion_Pluviometrica' en el grupo\n",
    "        existen_validos = grupo['Precipitacion_Pluviometrica'].notnull().any()\n",
    "\n",
    "        if existen_validos:\n",
    "            # 4. Filtrar los registros nulos de 'Precipitacion_Pluviometrica' en el grupo\n",
    "            df_nulos = grupo[grupo['Precipitacion_Pluviometrica'].isnull()]\n",
    "\n",
    "            # 5. Filtrar los registros no nulos de 'Precipitacion_Pluviometrica' en el grupo\n",
    "            df_no_nulos = grupo[grupo['Precipitacion_Pluviometrica'].notnull()]\n",
    "\n",
    "            # 6. Verificar si existen registros no nulos con diferente Localidad, Latitud o Longitud\n",
    "            if not df_nulos.empty:\n",
    "                registros_validos_distintos = df_no_nulos[\n",
    "                    (~df_no_nulos['Localidad'].isin(df_nulos['Localidad'].unique())) |\n",
    "                    (~df_no_nulos['Latitud'].isin(df_nulos['Latitud'].unique())) |\n",
    "                    (~df_no_nulos['Longitud'].isin(df_nulos['Longitud'].unique()))\n",
    "                ]\n",
    "                if not registros_validos_distintos.empty:\n",
    "                    # 7. Asignar el primer valor no nulo de 'Precipitacion_Pluviometrica' a los registros nulos\n",
    "                    valor_asignar = registros_validos_distintos.iloc[0]['Precipitacion_Pluviometrica']\n",
    "                    grupo.loc[grupo['Precipitacion_Pluviometrica'].isnull(), 'Precipitacion_Pluviometrica'] = valor_asignar\n",
    "        return grupo\n",
    "\n",
    "    # 8. Aplicar la función a cada grupo y concatenar los resultados\n",
    "    df_modificado = grouped.apply(asignar_grupo).reset_index(level=[0,1], drop=True)\n",
    "    return df_modificado\n",
    "\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# Supongamos que tienes un DataFrame llamado df_largo\n",
    "df_largo_modificado = asignar_precipitacion_global(df_largo.copy()) #Se realiza una copia para no modificar el dataframe original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747d9f4-e335-4223-9223-48a6c6bd8fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo_modificado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f4da6-fa31-4b2c-875a-b310d1519a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_por_provincia_mensual(provincias,df_largo_modificado,'Precipitacion_Pluviometrica')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa74e65d-759f-49b8-8db3-bfeaf59e3d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo = df_largo_modificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e53411-a105-4c2d-811d-73e1aca7120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo[(df_largo['Temperatura_Abrigo_150cm_Minima'].isnull()) & (~df_largo['Temperatura_Abrigo_150cm'].isnull())]['Temperatura_Abrigo_150cm_Minima'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfb4957-62d2-4dc5-934a-a54f15ed2e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preparación de los datos\n",
    "# Variables predictoras\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm'\n",
    "    \n",
    "]\n",
    "\n",
    "# Variable objetivo\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm_Minima'\n",
    "\n",
    "modelo1 = regresion_lineal_total(df_largo,variables_predictoras,variable_objetivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e41fc-3f0a-4494-bf27-b793c6ffc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_lineal_provincial(df_largo ,'Buenos Aires',variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abecfcc-707c-44bf-989b-2af150511190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtro de filas que cumplen ambas condiciones\n",
    "# Resguardamos el Df\n",
    "df_largo_bk = df_corto.copy()\n",
    "\n",
    "filtro = df_largo[variables_predictoras].notnull().all(axis=1) & df_largo[variable_objetivo].isnull()\n",
    "\n",
    "# Seleccionar las filas y variables predictoras para la predicción\n",
    "df_prediccion = df_largo.loc[filtro, variables_predictoras]\n",
    "\n",
    "# Realizar la predicción\n",
    "predicciones = modelo1.predict(df_prediccion)\n",
    "\n",
    "# Asignar las predicciones a los valores nulos en el DataFrame original\n",
    "df_largo.loc[filtro, variable_objetivo] = predicciones\n",
    "\n",
    "# 3. (Opcional) Verificar los resultados\n",
    "print(df_largo[filtro][[variable_objetivo] + variables_predictoras])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727fccb-44a7-4135-823d-8fcd293e5fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b4047-94c2-45c8-83ee-58ff5cee9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables= ['Tesion_Vapor_Media',\n",
    " 'Rocio_Medio',\n",
    " 'Precipitacion_Pluviometrica',\n",
    " 'Humedad_Media_8_14_20',\n",
    " 'Temperatura_Abrigo_150cm',\n",
    " 'Temperatura_Abrigo_150cm_Minima',\n",
    " 'Velocidad_Viento_200cm_Media',\n",
    " 'Temperatura_Abrigo_150cm_Maxima']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1925c279-f7b9-4f80-b9b4-48b7b9409bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlaciones(df_largo, variables )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab1d99c-2eea-4763-b55d-7341a5929e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_boxplot_grid(df_largo,'Provincia','MES','Humedad_Media_8_14_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdc496d-22eb-4d98-bbb5-6f11ad68810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos los valores medios\n",
    "completar_valores_medios(df_largo,'Humedad_Media_8_14_20',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf8218-69d5-4684-a91a-437ca4e0560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b52f92-7b40-4bf6-8dcc-64544dfdcb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preparación de los datos\n",
    "# Variables predictoras\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm','Rocio_Medio'\n",
    "    \n",
    "]\n",
    "\n",
    "# Variable objetivo\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm_Maxima'\n",
    "\n",
    "\n",
    "modelo1 = regresion_lineal_total(df_largo , variables_predictoras,variable_objetivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ae6dc-8300-4242-aea7-b3c904e68ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Filtro de filas que cumplen ambas condiciones\n",
    "# Resguardamos el Df\n",
    "df_largo_bk = df_largo.copy()\n",
    "\n",
    "filtro = df_largo[variables_predictoras].notnull().all(axis=1) & df_largo[variable_objetivo].isnull()\n",
    "\n",
    "# Seleccionar las filas y variables predictoras para la predicción\n",
    "\n",
    "df_prediccion = df_largo.loc[filtro, variables_predictoras]\n",
    "\n",
    "# Realizar la predicción\n",
    "predicciones = modelo1.predict(df_prediccion)\n",
    "\n",
    "# Asignar las predicciones a los valores nulos en el DataFrame original\n",
    "df_largo.loc[filtro, variable_objetivo] = predicciones\n",
    "\n",
    "# 3. (Opcional) Verificar los resultados\n",
    "print(df_largo[filtro][[variable_objetivo] + variables_predictoras])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9da1e-8404-49bc-84e3-10b90a51f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c95261-15df-4f82-b1c2-1cef1c83fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_boxplot_grid(df_largo, 'Provincia', 'MES', 'Velocidad_Viento_200cm_Media')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee3dd1a-e0c3-4e3d-98ed-d4c7de32776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo = completar_valores_normal(df_largo,'Velocidad_Viento_200cm_Media',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56306f6-d8be-4849-b784-3f68b9cdcef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487ee05-2c71-4c04-afe6-fa5bdd5df095",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo = completar_valores_normal(df_largo,'Precipitacion_Pluviometrica',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c31cfcb-0300-4b63-a389-55ef48db5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo['YEAR'] = df_largo['Fecha'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9069500-403e-4e69-a6e5-f1a7b13fe6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.groupby(['Provincia','YEAR'])['Fecha'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9401e4-778e-4c4e-a188-03d9762d63b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for provincia in provincias:\n",
    "    min=df_largo[df_largo['Provincia']==provincia]['YEAR'].min()\n",
    "    max=df_largo[df_largo['Provincia']==provincia]['YEAR'].max()\n",
    "    year = df_largo[df_largo['Provincia']==provincia]['YEAR'].unique()\n",
    "    year_reg = year.size\n",
    "    mes_a =0\n",
    "    for a in year:\n",
    "        mes_reg = df_largo[(df_largo['Provincia']==provincia) & (df_largo['YEAR']==a) ]['MES'].unique().size\n",
    "        mes_a = mes_a + mes_reg\n",
    "    \n",
    "    print(\"----------\")\n",
    "    print(f\"{provincia} --- {min}-{max}\")\n",
    "    print(f\"Cantidad de años esperados: {max+1-min} registrados: {year_reg}\")\n",
    "    print(f\"Cantidad de meses esperados: {(max+1-min)*12} registrados: {mes_a}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efaa3e6-45bc-40ba-8c26-0ca755e42063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitamos los set de datos a registros de años completos, es decir con registros desde que comienza hasta que termina el año\n",
    "\n",
    "# Paso 1: Obtener año mínimo y máximo por provincia\n",
    "rango_años = df_largo.groupby(\"Provincia\")[\"Fecha\"].agg([\"min\", \"max\"]).reset_index()\n",
    "\n",
    "# Paso 2: Crear los límites ajustados\n",
    "rango_años[\"Fecha_min\"] = pd.to_datetime(rango_años[\"min\"].dt.year.astype(str) + \"-01-01\")\n",
    "rango_años[\"Fecha_max\"] = pd.to_datetime((rango_años[\"max\"].dt.year - 1).astype(str) + \"-12-31\")\n",
    "\n",
    "# Paso 3: Merge con el dataframe original\n",
    "df = df_largo.merge(rango_años[[\"Provincia\", \"Fecha_min\", \"Fecha_max\"]], on=\"Provincia\")\n",
    "\n",
    "# Paso 4: Filtrar según esas fechas\n",
    "df_filtrado = df[(df[\"Fecha\"] >= df[\"Fecha_min\"]) & (df[\"Fecha\"] <= df[\"Fecha_max\"])]\n",
    "\n",
    "# Paso 5:  eliminar columnas auxiliares\n",
    "df_filtrado = df_filtrado.drop(columns=[\"Fecha_min\", \"Fecha_max\"])\n",
    "df_filtrado['Fecha'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367a9ab-59ee-4454-8759-5188df21715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado['Fecha'].max()\n",
    "df_filtrado[\"Fecha\"] = pd.to_datetime(df_filtrado[\"Fecha\"])\n",
    "\n",
    "# obtener rango de fechas para cada provincia\n",
    "rango_fechas = df_filtrado.groupby(\"Provincia\")[\"Fecha\"].agg([\"min\", \"max\"]).reset_index()\n",
    "rango_fechas[\"Fecha_min\"] = pd.to_datetime(rango_fechas[\"min\"].dt.year.astype(str) + \"-01-01\")\n",
    "rango_fechas[\"Fecha_max\"] = pd.to_datetime((rango_fechas[\"max\"].dt.year - 1).astype(str) + \"-12-31\")\n",
    "\n",
    "# para cada provincia, generar fechas completas y comparar\n",
    "fechas_faltantes = []\n",
    "\n",
    "for _, row in rango_fechas.iterrows():\n",
    "    provincia = row[\"Provincia\"]\n",
    "    fecha_inicio = row[\"Fecha_min\"]\n",
    "    fecha_fin = row[\"Fecha_max\"]\n",
    "    \n",
    "    # Generar fechas completas\n",
    "    fechas_completas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq=\"D\")\n",
    "    \n",
    "    # Fechas realmente presentes en df_filtrado\n",
    "    fechas_existentes = df_filtrado[df_filtrado[\"Provincia\"] == provincia][\"Fecha\"].unique()\n",
    "    \n",
    "    # Fechas faltantes\n",
    "    faltantes = sorted(set(fechas_completas) - set(fechas_existentes))\n",
    "    \n",
    "    # Guardar en una lista\n",
    "    fechas_faltantes.extend([{\"Provincia\": provincia, \"Fecha\": f} for f in faltantes])\n",
    "\n",
    "# convertir a DataFrame final\n",
    "df_fechas_faltantes = pd.DataFrame(fechas_faltantes)# Suponiendo que df_filtrado es el dataframe previamente generado\n",
    "df_filtrado[\"Fecha\"] = pd.to_datetime(df_filtrado[\"Fecha\"])\n",
    "\n",
    "# obtener rango de fechas ideal para cada provincia\n",
    "rango_fechas = df_filtrado.groupby(\"Provincia\")[\"Fecha\"].agg([\"min\", \"max\"]).reset_index()\n",
    "rango_fechas[\"Fecha_min\"] = pd.to_datetime(rango_fechas[\"min\"].dt.year.astype(str) + \"-01-01\")\n",
    "rango_fechas[\"Fecha_max\"] = pd.to_datetime((rango_fechas[\"max\"].dt.year - 1).astype(str) + \"-12-31\")\n",
    "\n",
    "# para cada provincia, generar fechas completas y comparar\n",
    "fechas_faltantes = []\n",
    "\n",
    "for _, row in rango_fechas.iterrows():\n",
    "    provincia = row[\"Provincia\"]\n",
    "    fecha_inicio = row[\"Fecha_min\"]\n",
    "    fecha_fin = row[\"Fecha_max\"]\n",
    "    \n",
    "    # Generar fechas completas\n",
    "    fechas_completas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq=\"D\")\n",
    "    \n",
    "    # Fechas realmente presentes en df_filtrado\n",
    "    fechas_existentes = df_filtrado[df_filtrado[\"Provincia\"] == provincia][\"Fecha\"].unique()\n",
    "    \n",
    "    # Fechas faltantes\n",
    "    faltantes = sorted(set(fechas_completas) - set(fechas_existentes))\n",
    "    \n",
    "    # Guardar en una lista\n",
    "    fechas_faltantes.extend([{\"Provincia\": provincia, \"Fecha\": f} for f in faltantes])\n",
    "\n",
    "# convertir a DataFrame final\n",
    "df_fechas_faltantes = pd.DataFrame(fechas_faltantes)# Suponiendo que df_filtrado es el dataframe previamente generado\n",
    "df_filtrado[\"Fecha\"] = pd.to_datetime(df_filtrado[\"Fecha\"])\n",
    "\n",
    "# Paso 1: obtener rango de fechas ideal para cada provincia\n",
    "rango_fechas = df_filtrado.groupby(\"Provincia\")[\"Fecha\"].agg([\"min\", \"max\"]).reset_index()\n",
    "rango_fechas[\"Fecha_min\"] = pd.to_datetime(rango_fechas[\"min\"].dt.year.astype(str) + \"-01-01\")\n",
    "rango_fechas[\"Fecha_max\"] = pd.to_datetime((rango_fechas[\"max\"].dt.year - 1).astype(str) + \"-12-31\")\n",
    "\n",
    "# Paso 2: para cada provincia, generar fechas completas y comparar\n",
    "fechas_faltantes = []\n",
    "\n",
    "for _, row in rango_fechas.iterrows():\n",
    "    provincia = row[\"Provincia\"]\n",
    "    fecha_inicio = row[\"Fecha_min\"]\n",
    "    fecha_fin = row[\"Fecha_max\"]\n",
    "    \n",
    "    # Generar fechas completas\n",
    "    fechas_completas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq=\"D\")\n",
    "    \n",
    "    # Fechas realmente presentes en df_filtrado\n",
    "    fechas_existentes = df_filtrado[df_filtrado[\"Provincia\"] == provincia][\"Fecha\"].unique()\n",
    "    \n",
    "    # Fechas faltantes\n",
    "    faltantes = sorted(set(fechas_completas) - set(fechas_existentes))\n",
    "    \n",
    "    # Guardar en una lista\n",
    "    fechas_faltantes.extend([{\"Provincia\": provincia, \"Fecha\": f} for f in faltantes])\n",
    "\n",
    "# Paso 3: convertir a DataFrame final\n",
    "df_fechas_faltantes = pd.DataFrame(fechas_faltantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d3a21-3b5f-4e39-9d61-ae23e87655d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_filtrado[\"Fecha\"] = pd.to_datetime(df_filtrado[\"Fecha\"])\n",
    "\n",
    "# Paso 1: obtener rango de fechas ideal para cada provincia\n",
    "rango_fechas = df_filtrado.groupby(\"Provincia\")[\"Fecha\"].agg([\"min\", \"max\"]).reset_index()\n",
    "rango_fechas[\"Fecha_min\"] = pd.to_datetime(rango_fechas[\"min\"].dt.year.astype(str) + \"-01-01\")\n",
    "rango_fechas[\"Fecha_max\"] = pd.to_datetime((rango_fechas[\"max\"].dt.year - 1).astype(str) + \"-12-31\")\n",
    "\n",
    "# Paso 2: para cada provincia, generar fechas completas y comparar\n",
    "fechas_faltantes = []\n",
    "\n",
    "for _, row in rango_fechas.iterrows():\n",
    "    provincia = row[\"Provincia\"]\n",
    "    fecha_inicio = row[\"Fecha_min\"]\n",
    "    fecha_fin = row[\"Fecha_max\"]\n",
    "    \n",
    "    # Generar fechas completas\n",
    "    fechas_completas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq=\"D\")\n",
    "    \n",
    "    # Fechas realmente presentes en df_filtrado\n",
    "    fechas_existentes = df_filtrado[df_filtrado[\"Provincia\"] == provincia][\"Fecha\"].unique()\n",
    "    \n",
    "    # Fechas faltantes\n",
    "    faltantes = sorted(set(fechas_completas) - set(fechas_existentes))\n",
    "    \n",
    "    # Guardar en una lista\n",
    "    fechas_faltantes.extend([{\"Provincia\": provincia, \"Fecha\": f} for f in faltantes])\n",
    "\n",
    "# Paso 3: convertir a DataFrame final\n",
    "df_fechas_faltantes = pd.DataFrame(fechas_faltantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff2f642-dc9c-4870-be7d-788ccd1c8218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar el dataframe: agregar una columna constante para el eje Y\n",
    "df_fechas_faltantes[\"Y\"] = 1\n",
    "\n",
    "# Obtener lista de provincias\n",
    "provincias = df_fechas_faltantes[\"Provincia\"].unique()\n",
    "n = len(provincias)\n",
    "\n",
    "# Calcular tamaño de grid (cuadrado o casi cuadrado)\n",
    "cols = 4  # podés ajustar este número\n",
    "rows = math.ceil(n / cols)\n",
    "\n",
    "# Crear figura\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(18, rows * 2.5), sharex=False)\n",
    "axes = axes.flatten()  # para poder indexar fácilmente\n",
    "# Graficar por provincia\n",
    "for i, provincia in enumerate(provincias):\n",
    "    ax = axes[i]\n",
    "    datos = df_fechas_faltantes[df_fechas_faltantes[\"Provincia\"] == provincia]\n",
    "    ax.scatter(datos[\"Fecha\"], datos[\"Y\"], s=10, color='red', alpha=0.6)\n",
    "    ax.set_title(provincia, fontsize=10)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Quitar ejes vacíos si sobran\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Layout prolijo\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Fechas faltantes por provincia\", fontsize=14, y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa9a6c5-b59d-4da9-bcbf-ce9295157f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "provincias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fab60-31c7-4d5c-a215-dd96559422ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Obtener rango deseado por provincia (año mínimo a año máximo - 1)\n",
    "rango_fechas = df_largo.groupby(\"Provincia\")[\"Fecha\"].agg([\"min\", \"max\"]).reset_index()\n",
    "rango_fechas[\"Fecha_min\"] = pd.to_datetime(rango_fechas[\"min\"].dt.year.astype(str) + \"-01-01\")\n",
    "rango_fechas[\"Fecha_max\"] = pd.to_datetime((rango_fechas[\"max\"].dt.year - 1).astype(str) + \"-12-31\")\n",
    "\n",
    "#  Buscar fechas faltantes por provincia\n",
    "fechas_faltantes = []\n",
    "\n",
    "for _, row in rango_fechas.iterrows():\n",
    "    provincia = row[\"Provincia\"]\n",
    "    fecha_inicio = row[\"Fecha_min\"]\n",
    "    fecha_fin = row[\"Fecha_max\"]\n",
    "    \n",
    "    # Fechas completas esperadas\n",
    "    fechas_completas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq=\"D\")\n",
    "    \n",
    "    # Fechas existentes en df\n",
    "    fechas_existentes = df_largo[df_largo[\"Provincia\"] == provincia][\"Fecha\"].unique()\n",
    "    \n",
    "    # Obtener fechas que faltan\n",
    "    faltantes = sorted(set(fechas_completas) - set(fechas_existentes))\n",
    "    \n",
    "    # Guardar provincia + fecha faltante\n",
    "    fechas_faltantes.extend([{\"Provincia\": provincia, \"Fecha\": f} for f in faltantes])\n",
    "\n",
    "#  Crear DataFrame con fechas faltantes\n",
    "df_fechas_faltantes = pd.DataFrame(fechas_faltantes)\n",
    "\n",
    "#  Crear registros vacíos con valores nulos y completar info básica\n",
    "df_placeholder = pd.DataFrame(columns=df_largo.columns)\n",
    "df_placeholder[\"Fecha\"] = df_fechas_faltantes[\"Fecha\"]\n",
    "df_placeholder[\"Provincia\"] = df_fechas_faltantes[\"Provincia\"]\n",
    "df_placeholder[\"MES\"] = df_placeholder[\"Fecha\"].dt.month\n",
    "df_placeholder[\"YEAR\"] = df_placeholder[\"Fecha\"].dt.year\n",
    "\n",
    "#  Concatenar al DataFrame original\n",
    "df_completo = pd.concat([df_largo, df_placeholder], ignore_index=True)\n",
    "\n",
    "#  Ordenar por provincia y fecha\n",
    "df_completo = df_completo.sort_values(by=[\"Provincia\", \"Fecha\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab643cf3-a65c-4dee-b117-b76b3bd160d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb4e34-597a-4aa5-8391-c2b950f19ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d6e2e-948a-4661-8bd2-2ccf621afd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "# Paso 1: obtener rango de fechas ideal para cada provincia\n",
    "rango_fechas = df_completo.groupby(\"Provincia\")[\"Fecha\"].agg([\"min\", \"max\"]).reset_index()\n",
    "rango_fechas[\"Fecha_min\"] = pd.to_datetime(rango_fechas[\"min\"].dt.year.astype(str) + \"-01-01\")\n",
    "rango_fechas[\"Fecha_max\"] = pd.to_datetime((rango_fechas[\"max\"].dt.year - 1).astype(str) + \"-12-31\")\n",
    "\n",
    "# Paso 2: para cada provincia, generar fechas completas y comparar\n",
    "fechas_faltantes = []\n",
    "\n",
    "for _, row in rango_fechas.iterrows():\n",
    "    provincia = row[\"Provincia\"]\n",
    "    fecha_inicio = row[\"Fecha_min\"]\n",
    "    fecha_fin = row[\"Fecha_max\"]\n",
    "    \n",
    "    # Generar fechas completas\n",
    "    fechas_completas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq=\"D\")\n",
    "    \n",
    "    # Fechas realmente presentes en df_filtrado\n",
    "    fechas_existentes = df_completo[df_completo[\"Provincia\"] == provincia][\"Fecha\"].unique()\n",
    "    \n",
    "    # Fechas faltantes\n",
    "    faltantes = sorted(set(fechas_completas) - set(fechas_existentes))\n",
    "    \n",
    "    # Guardar en una lista\n",
    "    fechas_faltantes.extend([{\"Provincia\": provincia, \"Fecha\": f} for f in faltantes])\n",
    "\n",
    "# Paso 3: convertir a DataFrame final\n",
    "df_fechas_faltantes = pd.DataFrame(fechas_faltantes)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9788c6-baa9-4148-93a0-fac62e5b4e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver cuántas filas están completamente vacías (todas las columnas NaN)\n",
    "filas_nulas_totales = df_completo.isnull().all(axis=1).sum()\n",
    "print(f\"Filas completamente nulas antes de eliminar: {filas_nulas_totales}\")\n",
    "\n",
    "# Eliminar filas completamente nulas\n",
    "df_completo = df_completo[~df_completo.isnull().all(axis=1)]\n",
    "\n",
    "# Verificar nuevamente\n",
    "filas_nulas_totales_despues = df_completo.isnull().all(axis=1).sum()\n",
    "print(f\"Filas completamente nulas después de eliminar: {filas_nulas_totales_despues}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83569df2-000d-4c86-a95c-f43b0682edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f18145-8f56-4bca-92bd-0190c33d22a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be303e-42bc-4ae8-8ac9-3d6b58d389b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "completar_valores_normal(df_completo,'Velocidad_Viento_200cm_Media',provincias)\n",
    "completar_valores_medios(df_completo,'Tesion_Vapor_Media',provincias)\n",
    "completar_valores_normal(df_completo,'Precipitacion_Pluviometrica',provincias)\n",
    "completar_valores_medios(df_completo,'Humedad_Media_8_14_20',provincias)\n",
    "completar_valores_medios(df_completo,'Temperatura_Abrigo_150cm',provincias)\n",
    "completar_valores_normal(df_completo,'Temperatura_Abrigo_150cm_Minima',provincias)\n",
    "completar_valores_normal(df_completo,'Temperatura_Abrigo_150cm_Maxima',provincias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125800d8-97bd-4072-8ec7-7c48e3de977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99109e6-79d4-4db0-acc6-6eb590899b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "modas = df_completo.groupby(\"Provincia\").agg({\n",
    "    \"Localidad\": lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
    "    \"Latitud\": lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
    "    \"Longitud\": lambda x: x.mode().iloc[0] if not x.mode().empty else None\n",
    "}).reset_index()\n",
    "\n",
    "# Crear un dataframe con los valores nulos en esas columnas\n",
    "mascara_nulos = df_completo[\"Localidad\"].isnull() | df_completo[\"Latitud\"].isnull() | df_completo[\"Longitud\"].isnull()\n",
    "df_nulos = df_completo[mascara_nulos]\n",
    "\n",
    "# Reemplazar los valores nulos con las modas\n",
    "df_nulos = df_nulos.drop(columns=[\"Localidad\", \"Latitud\", \"Longitud\"])\n",
    "df_nulos = df_nulos.merge(modas, on=\"Provincia\", how=\"left\")\n",
    "\n",
    "# Combinar con el resto del dataframe\n",
    "df_no_nulos = df_completo[~mascara_nulos]\n",
    "df_completo_actualizado = pd.concat([df_no_nulos, df_nulos], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba13565-77dd-4e5a-888d-7ad21c3dac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo_actualizado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e48e61-d07c-4903-9dfa-e3122642aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo_actualizado.to_csv(\"clima_completo_largo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00e6d76-652a-42c2-818c-040fa1a450dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05649fb3-09f5-4649-9827-7b33c7ea962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    \"Tesion_Vapor_Media\",\n",
    "    \"Rocio_Medio\",\n",
    "    \"Precipitacion_Pluviometrica\",\n",
    "    \"Humedad_Media_8_14_20\",\n",
    "    \"Temperatura_Abrigo_150cm\",\n",
    "    \"Temperatura_Abrigo_150cm_Minima\",\n",
    "    \"Velocidad_Viento_200cm_Media\",\n",
    "    \"Temperatura_Abrigo_150cm_Maxima\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6f8f2-0c71-402c-b4a6-3d6782dfd13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Agrupar por Fecha y promediar todas las provincias\n",
    "df_promedios = df_completo_actualizado.groupby(\"Fecha\")[variables].mean().reset_index()\n",
    "\n",
    "# Plot general\n",
    "plt.figure(figsize=(15, 6))\n",
    "for var in variables:\n",
    "    sns.lineplot(data=df_promedios, x=\"Fecha\", y=var, label=var, linewidth=1.5)\n",
    "\n",
    "plt.title(\"Tendencias generales por variable (Promedio Nacional)\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4845fa66-517d-48c1-93c6-c266b85c779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener provincias únicas\n",
    "provincias = df_completo_actualizado[\"Provincia\"].unique()\n",
    "n_provincias = len(provincias)\n",
    "n_variables = len(variables)\n",
    "\n",
    "# Tamaño de figura ajustado según cantidad de gráficos\n",
    "fig, axes = plt.subplots(nrows=n_provincias, ncols=n_variables, figsize=(4 * n_variables, 3 * n_provincias), sharex=True)\n",
    "\n",
    "# Loop por cada provincia y variable\n",
    "for i, provincia in enumerate(provincias):\n",
    "    df_prov = df_completo_actualizado[df_completo_actualizado[\"Provincia\"] == provincia]\n",
    "    \n",
    "    for j, var in enumerate(variables):\n",
    "        ax = axes[i, j]\n",
    "        sns.lineplot(data=df_prov, x=\"Fecha\", y=var, ax=ax, linewidth=0.8)\n",
    "        ax.set_title(f\"{provincia} - {var}\", fontsize=8)\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.tick_params(labelsize=6)\n",
    "\n",
    "# Ajustes de presentación\n",
    "plt.suptitle(\"Evolución temporal por Provincia y Variable\", fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e25c70b-13d5-42a3-baf5-9954d001c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "variables = [\n",
    "    \"Tesion_Vapor_Media\",\n",
    "    \"Rocio_Medio\",\n",
    "    \"Precipitacion_Pluviometrica\",\n",
    "    \"Humedad_Media_8_14_20\",\n",
    "    \"Temperatura_Abrigo_150cm\",\n",
    "    \"Temperatura_Abrigo_150cm_Minima\",\n",
    "    \"Velocidad_Viento_200cm_Media\",\n",
    "    \"Temperatura_Abrigo_150cm_Maxima\"\n",
    "]\n",
    "provincias = df_completo_actualizado[\"Provincia\"].unique()\n",
    "diccionario_estadisticos = {}\n",
    "\n",
    "for provincia in provincias:\n",
    "    diccionario_estadisticos[provincia] = {}  # Inicializa el diccionario para la provincia\n",
    "    for mes in list(df_completo_actualizado[\"MES\"].unique()):\n",
    "        diccionario_estadisticos[provincia][mes] = {} # Inicializa el diccionario para el mes\n",
    "        for variable in variables:\n",
    "            datos = df_completo_actualizado[(df_completo_actualizado['Provincia'] == provincia) & (df_completo_actualizado['MES'] == mes)][variable].dropna()  # Obtiene los datos de la variable y provincia, eliminando valores nulos\n",
    "            if not datos.empty:  # Verifica que no este vacio el dataframe\n",
    "                Q1 = datos.quantile(0.25)\n",
    "                Q3 = datos.quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                media = datos.mean()\n",
    "                desviacion_estandar = datos.std()\n",
    "                diccionario_estadisticos[provincia][mes][variable] = {\n",
    "                    'Q1': Q1,\n",
    "                    'Q3': Q3,\n",
    "                    'IQR': IQR,\n",
    "                    'Media': media,\n",
    "                    'Desviacion_estandar': desviacion_estandar\n",
    "                }\n",
    "            else:\n",
    "                diccionario_estadisticos[provincia][mes][variable] = None  # En caso de que el dataframe este vacio, le asigno None al diccionario.\n",
    "print(diccionario_estadisticos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed65f4-df3f-4193-8377-d3644e6fa6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_estadisticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553079e6-b51e-4ac0-8760-f67511e802bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def identificar_outliers(df, diccionario_estadisticos, variables):\n",
    "    \"\"\"\n",
    "    Identifica outliers en un DataFrame utilizando los estadísticos proporcionados en un diccionario.\n",
    "\n",
    "    Args:\n",
    "        df: El DataFrame a analizar.\n",
    "        diccionario_estadisticos: Un diccionario que contiene los estadísticos por provincia, mes y variable.\n",
    "        variables: Lista de las variables a analizar.\n",
    "\n",
    "    Returns:\n",
    "        El DataFrame original con columnas adicionales indicando si cada valor es un outlier.\n",
    "    \"\"\"\n",
    "    for variable in variables:\n",
    "        nombre_columna_outlier = f'{variable}_outlier'  # Nombre de la nueva columna\n",
    "        df[nombre_columna_outlier] = False  # Inicializa la columna con False\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        provincia = row['Provincia']\n",
    "        mes = row['MES']\n",
    "\n",
    "        if provincia in diccionario_estadisticos and mes in diccionario_estadisticos[provincia]:\n",
    "            for variable in variables:\n",
    "                if variable in diccionario_estadisticos[provincia][mes] and diccionario_estadisticos[provincia][mes][variable] is not None:\n",
    "                    Q1 = diccionario_estadisticos[provincia][mes][variable]['Q1']\n",
    "                    Q3 = diccionario_estadisticos[provincia][mes][variable]['Q3']\n",
    "                    IQR = diccionario_estadisticos[provincia][mes][variable]['IQR']\n",
    "                    valor = row[variable]\n",
    "                    limite_inferior = Q1 - 1.5 * IQR\n",
    "                    limite_superior = Q3 + 1.5 * IQR\n",
    "\n",
    "                    if valor < limite_inferior or valor > limite_superior:\n",
    "                        nombre_columna_outlier = f'{variable}_outlier'\n",
    "                        df.at[index, nombre_columna_outlier] = True  # Marca el registro como outlier\n",
    "\n",
    "    return df\n",
    "\n",
    "# Aplica la función para identificar outliers\n",
    "df_completo_con_outliers = identificar_outliers(df_completo_actualizado.copy(), diccionario_estadisticos, variables)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame con las columnas de outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e91e08-5fcd-4118-842d-e813879c5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo_con_outliers[df_completo_con_outliers['Tesion_Vapor_Media_outlier']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138af85-be6b-498a-af61-11682731a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_outliers_por_anio(df, variables):\n",
    "    \"\"\"\n",
    "    Cuenta los valores atípicos (True) por año y variable en un DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: El DataFrame a analizar.\n",
    "        variables: Lista de las variables originales (sin el sufijo '_outlier').\n",
    "\n",
    "    Returns:\n",
    "        Un DataFrame con el conteo de outliers por año y variable.\n",
    "    \"\"\"\n",
    "    # Crear una lista de las columnas de outliers\n",
    "    columnas_outliers = [f'{var}_outlier' for var in variables]\n",
    "\n",
    "    # Agrupar por año y contar los valores True en las columnas de outliers\n",
    "    conteo_outliers = df.groupby(df['Fecha'].dt.year)[columnas_outliers].sum().reset_index()\n",
    "    conteo_outliers = conteo_outliers.melt(id_vars='Fecha', value_vars=columnas_outliers, var_name='Variable_Outlier', value_name='Conteo_Outliers')\n",
    "    conteo_outliers['Variable'] = conteo_outliers['Variable_Outlier'].str.replace('_outlier','')\n",
    "    return conteo_outliers\n",
    "\n",
    "# Obtener el conteo de outliers por año\n",
    "conteo_outliers_por_anio_df = contar_outliers_por_anio(df_completo_con_outliers, variables)\n",
    "\n",
    "# Imprimir el DataFrame resultante\n",
    "print(conteo_outliers_por_anio_df.head())\n",
    "\n",
    "def graficar_outliers_por_anio(df, titulo):\n",
    "    \"\"\"\n",
    "    Grafica el conteo de outliers por año para cada variable.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame con el conteo de outliers por año y variable.\n",
    "        titulo: El título del gráfico.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(x='Fecha', y='Conteo_Outliers', hue='Variable', marker='o', data=df)\n",
    "    plt.title(titulo)\n",
    "    plt.xlabel('Año')\n",
    "    plt.ylabel('Conteo de Outliers')\n",
    "    plt.xticks(df['Fecha'].unique())  # Mostrar ticks para cada año\n",
    "    plt.legend(title='Variable')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Graficar el conteo de outliers por año\n",
    "graficar_outliers_por_anio(conteo_outliers_por_anio_df, 'Conteo de Outliers por Año')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36732424-eb3c-44e8-8155-0d964299ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo['Provincia'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8628d30d-5e1d-45bf-9603-10ac150ba318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUSCAR EN EL SET DE DATOS REGISTROS SOBRE TUCUMAN,JUJUY,SALTA,NEUQUEN,CHUBUT,RIO NEGRO, SANTA CRUZ,SAN JUAN, SAN LUIS, MISIONES,CATAMARCA,LA RIOJA,CHACO,FORMOSA,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea686ca8-2e23-4f6c-980e-9422c1ccbaed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dcdff9-e65e-40c8-8866-d9698e29556a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c01419-7b06-4c6c-97f9-14da10451282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81ca808-3529-4ce9-b447-f32551297c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5ab9d-6d53-4f19-be9a-7687652262c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf6f98-7e35-4204-875b-e04a5ca772b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7575293-7ed5-42ae-9141-099a9ccc03e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e7b4d-8e2b-4bf2-a1fa-218609f2eff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca3dc9d-4779-4595-8e96-c623dc6d1091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f2317f7-3350-44a1-9e89-b4d709ea8518",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HACER BATERIA DE GRAFICOS\n",
    "\n",
    "1) Por provincia :\n",
    " HAcer un grafico de curva con todas las provincias desagregadas (una por linea) para cada una de las variables en el tiempo, y poder comparar valores absolutos y tendencias en el tiempo\n",
    " Hacer un grafico de boxplot por cada variable sobre el total de registros, luego repetir con agrupacion mensual, luego agrupacion anual. < esto permite ver dias atipicos, meses atipicos, años atipicos\n",
    " Como es analisis climatico se dan procesos ciclicos, por lo que se deberia comparar el comportamiento de cada mes de cada año de cada provincia y del general\n",
    " por ejemplo, debemos poder comparar Todos los eneros de Cordoba, luego Todos los Eneros de BsAS, etc..., luego Todos los Febreros de Cordoba, Luego Todos los febreros de bsas...etc  \n",
    " Con esto la idea es ver la tendencia de la evolucion dentro de los ciclos. Esto se debe hacer sobre cada variable de interes\n",
    " Posterior se debe contar la cantidad de outliers dentro de cada categoria dentro de cada provincia, dentro de cada ciclo (cuantos dias en enero fueron ventosos por arriba de la media o abajo de la media hubo), con ese dato sabremos cuantos eventos outliers se han ocurrido en un determinado mes de un determinado año\n",
    " La intencion es llegar a una grafica de curva que muestre la evolucion en el tiempo (general y si se puede por variable) por cada provincia de eventos atipicos.\n",
    " Si podemos encontrar una tendencia creciente de eventos atipicos podriamos hablar de una situación de inestabilidad climatica creciente y con esto demostrar la existencia de una variable que se puede usar para correlacionar con la variacion de las cosechas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
