{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fea698-b5d5-4c3a-a7b2-ef7c0396e6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a739b51-3b72-4450-b9df-9d86cffdba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos path de carpeta del proyecto\n",
    "path_relativo =  r\"../SET DE DATOS/UNIDO/CLIMA/Provinciales\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c2dfed-4bc4-4911-aee3-b6759eb4fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos los archivos disponibles\n",
    "!ls \"../SET DE DATOS/UNIDO/CLIMA/Provinciales\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b435cf1e-9013-4850-b03e-56605d265381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4d3d6-c6c5-446f-85d1-d6e72bfcbd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3ca55e-a6bc-45e5-956e-970f11231607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listar_archivos_zip(directorio):\n",
    "  \"\"\"\n",
    "  Lista todos los archivos .xls en el directorio especificado.\n",
    "\n",
    "  Args:\n",
    "    directorio: La ruta del directorio a listar.\n",
    "  \"\"\"\n",
    "\n",
    "  archivos_xls = []\n",
    "  try:\n",
    "    for archivo in os.listdir(directorio):\n",
    "      if archivo.endswith(\".zip\"):\n",
    "        archivos_xls.append(archivo)\n",
    "    return archivos_xls\n",
    "  except FileNotFoundError:\n",
    "    print(f\"Error: El directorio '{directorio}' no existe.\")\n",
    "    return []\n",
    "\n",
    "\n",
    "def listar_archivos_xls(directorio):\n",
    "  \"\"\"\n",
    "  Lista todos los archivos .xls en el directorio especificado.\n",
    "\n",
    "  Args:\n",
    "    directorio: La ruta del directorio a listar.\n",
    "  \"\"\"\n",
    "\n",
    "  archivos_xls = []\n",
    "  try:\n",
    "    for archivo in os.listdir(directorio):\n",
    "      if archivo.endswith(\".xls\"):\n",
    "        archivos_xls.append(archivo)\n",
    "    return archivos_xls\n",
    "  except FileNotFoundError:\n",
    "    print(f\"Error: El directorio '{directorio}' no existe.\")\n",
    "    return []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def descomprimir_zip(archivo_zip, directorio_destino):\n",
    "    \"\"\"\n",
    "    Descomprime un archivo ZIP en el directorio de destino especificado.\n",
    "\n",
    "    Args:\n",
    "        archivo_zip: La ruta del archivo ZIP que se va a descomprimir.\n",
    "        directorio_destino: La ruta del directorio donde se extraer치n los archivos.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(archivo_zip, 'r') as zip_ref:\n",
    "            zip_ref.extractall(directorio_destino)\n",
    "        print(f\"El archivo '{archivo_zip}' se ha descomprimido correctamente en '{directorio_destino}'.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: El archivo '{archivo_zip}' no se encontr칩.\")\n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"Error: El archivo '{archivo_zip}' no es un archivo ZIP v치lido.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurri칩 un error inesperado: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa825972-03e3-4860-91d1-2655a1adc55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1168ebe9-31e1-42cb-a560-45ed075e2acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomprimimos los archivos zip con los xls\n",
    "for archivo in listar_archivos_zip(path_relativo):\n",
    "    descomprimir_zip(path_relativo+'/'+archivo, path_relativo+'/ARCHIVOS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108ca90-090a-48cf-80e8-18b2e5071ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ecf5d8-a800-4de3-b5b8-59af71e631df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listamos los archivos obtenidos\n",
    "listar_archivos_xls(path_relativo+'/ARCHIVOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff0ff1-c5c4-4127-9edb-1c1d7727e1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0580543-6b3f-49f2-a4f9-a6046e344996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abro unos de los archivos xls para ver el formato - convierto en DataFrame\n",
    "df_tmp = pd.read_excel(path_relativo+'/ARCHIVOS/'+listar_archivos_xls(path_relativo+'/ARCHIVOS')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e014b-afc8-4e78-9873-f428baf59b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f5a2b-5666-4451-aed3-e9ef9ae5b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa43b846-e53e-4b62-ad19-c52d35f75a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebadc19b-f97c-4a12-9ef9-93475edb5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizamos los datos del dataframe para obtener datos sobre los registros que tiene\n",
    "def control_reg_utiles(df) -> dict:\n",
    "    inicio = df['Fecha'].min()\n",
    "    fin = df['Fecha'].max()\n",
    "    n_registros= df_tmp.shape[0]\n",
    "\n",
    "    dic_parametros = {}\n",
    "    for columna in df.columns:\n",
    "        reg = (df[~df[columna].isnull()].shape[0]*100)/n_registros\n",
    "        dic_parametros[columna] = reg\n",
    "        print(f\"{columna} : {reg:.2f}% validos\")\n",
    "    return dic_parametros\n",
    "control_reg_utiles(df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c1327-06e8-4e31-adb4-9a24d176dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listamos todas las columnas que encontramos entre todos los archivos y mostramos aquellos que no tienen formatu usable\n",
    "eliminar = []\n",
    "columnas=[]\n",
    "for archivo in listar_archivos_xls(path_relativo+'/ARCHIVOS'):\n",
    "    try:\n",
    "        df_tmp = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo)\n",
    "        for columna in df_tmp.columns:\n",
    "            columnas.append(columna)\n",
    "    except:\n",
    "        print(archivo)\n",
    "        eliminar.append(path_relativo+'/ARCHIVOS/'+archivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7792f-ea01-4755-82ad-b64c73f2fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_archivos(lista_archivos):\n",
    "    \"\"\"\n",
    "    Elimina los archivos especificados en la lista.\n",
    "\n",
    "    Args:\n",
    "        lista_archivos: Una lista de rutas de archivos a eliminar.\n",
    "    \"\"\"\n",
    "    for archivo in lista_archivos:\n",
    "        try:\n",
    "            os.remove(archivo)\n",
    "            print(f\"Archivo eliminado: {archivo}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: El archivo no fue encontrado: {archivo}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al eliminar el archivo {archivo}: {e}\")\n",
    "\n",
    "eliminar_archivos(eliminar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4347517-904f-4433-ad38-a7606549e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = list(set(columnas))\n",
    "\n",
    "len(columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5136e455-7d0e-47c7-ab11-3116fee880b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f70318a-02f8-46f8-9697-f00e7bf5b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_de_interes= ['Radiacion_Global','Heliofania_Efectiva','Radiacion_Neta','Velocidad_Viento_200cm_Media','Temperatura_Abrigo_150cm_Maxima','Temperatura_Inte_5cm','Humedad_Media','Tesion_Vapor_Media','Rocio_Medio','Precipitacion_Pluviometrica','Precipitacion_Maxima_30minutos','Temperatura_Intemperie_5cm_Minima','Temperatura_Suelo_10cm_Media','Temperatura_Suelo_5cm_Media','Humedad_Media_8_14_20','Temperatura_Intemperie_50cm_Minima','Velocidad_Viento_Maxima','Temperatura_Abrigo_150cm','Evapotranspiracion_Potencial','Temperatura_Intemperie_150cm_Minima','Granizo','Temperatura_Abrigo_150cm_Minima']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecdfe79-2cf1-49eb-9046-61b90d6909dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_variables ={}\n",
    "for i in variables_de_interes:\n",
    "    dic_variables[i] = 0\n",
    "print(dic_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17acfc9a-2d47-4017-a925-f3a0f760274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_archivos = 0\n",
    "lista_descripcion_archivo=[]\n",
    "for archivo in listar_archivos_xls(path_relativo+'/ARCHIVOS'):\n",
    "    print(archivo)\n",
    "    df_tmp = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo)\n",
    "    cantidad_archivos=cantidad_archivos+1\n",
    "    inicio = df_tmp['Fecha'].min()\n",
    "    fin = df_tmp['Fecha'].max()\n",
    "    n_registros= df_tmp.shape[0]\n",
    "    lista_descripcion_archivo.append((archivo,inicio,fin,n_registros))\n",
    "\n",
    "    print(f\"-----{archivo}----------\")\n",
    "    for columna in variables_de_interes:\n",
    "        try:\n",
    "            print(f\"{columna} : {(df_tmp[~df_tmp[columna].isnull()].shape[0]*100)/n_registros:.2f}% validos\")    \n",
    "            print(f\"Primer registro: {inicio} - Ultimo Registro: {fin}\")\n",
    "            dic_variables[columna] = dic_variables[columna] + 1\n",
    "        except:\n",
    "            pass\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6829ef-f88c-49e5-b395-d9ce03bad9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que las columnas esten presentes en todos los archivos\n",
    "dic_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf29da-ed4e-4f6b-9b60-6a52165e1f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e07852e-fc8b-4cc0-bc73-11c8c71d5be0",
   "metadata": {},
   "source": [
    "La mayoria de los archivos contienen los mismos registros, el problema que se plantea es que la variable Granizo solo esta presente en 26 de los archivos y es una variable de gran importancia, vamos a identificar cuales son los archivos y su procedencia para ver si el motivo es la falta de granizo en los otros 99 archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b07202-b27b-4e91-8577-1209ae31efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for archivo in listar_archivos_xls(path_relativo+'/ARCHIVOS'):\n",
    "    df_tmp = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo)\n",
    "    if 'Granizo' in df_tmp.columns:\n",
    "        print(archivo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044aa60-b2f9-4b50-8a43-516f1998b0de",
   "metadata": {},
   "source": [
    "Se presenta el problema que solo algunos centros meteorologicos guardan registros sobre el granizo, por lo que podemos perder mucha informaci칩n de utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c4d926-591e-4393-9dcb-ac391185d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos el resumen de registros de todos los archivos\n",
    "lista_descripcion_archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218cdb5-7f35-414a-a666-8250a9eb3458",
   "metadata": {},
   "source": [
    "No nos es de utilidad trabajar con registros truncos , buscamos la mayor amplitud de datos posible con una fecha de corte cercana a 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342389a3-97d6-410e-ad56-a8389812c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumen_archivos = pd.DataFrame(lista_descripcion_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ce35d-34e3-45a0-bf89-4c67a48b921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumen_archivos.columns = ['Nombre','Inicio','Fin','Registros']\n",
    "df_resumen_archivos.info()\n",
    "df_resumen_archivos['Inicio'] = pd.to_datetime(df_resumen_archivos['Inicio'])\n",
    "df_resumen_archivos['Fin'] = pd.to_datetime(df_resumen_archivos['Fin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b5b82-7076-411c-b634-a4d9848588b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumen_archivos[df_resumen_archivos['Registros']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c52e8f-3e54-4037-a0f5-05ba04e550a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumen_archivos[df_resumen_archivos['Registros']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5d885-2c94-4c46-8731-13a654094d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f7d994-f6ee-4c20-9e66-8ed7d983af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos un vistazo de cuantos archivos tienen registros hasta determinada fecha\n",
    "fecha_limite = pd.to_datetime('2021-12-31')\n",
    "print(f\"Archivos con registros hasta el 2021 incluido {df_resumen_archivos[df_resumen_archivos['Fin']>=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('2022-12-31')\n",
    "print(f\"Archivos con registros hasta el 2022 incluido {df_resumen_archivos[df_resumen_archivos['Fin']>=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('2023-12-31')\n",
    "print(f\"Archivos con registros hasta el 2023 incluido {df_resumen_archivos[df_resumen_archivos['Fin']>=fecha_limite].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c160bb5-31e9-4072-8d07-4bff01035d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos listado de archivos que vamos a conservar \n",
    "fecha_limite = pd.to_datetime('2022-12-31')\n",
    "df_listado_archivos_validos = df_resumen_archivos[df_resumen_archivos['Fin']>=fecha_limite]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a312ff-eaf2-4178-8145-4dd252e78c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos ahora la fecha de inicio de los registros, mas antiguo sea el dato mejor sera\n",
    "fecha_limite = pd.to_datetime('1970-01-01')\n",
    "print(f\"Archivos con registros desde el 1970 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('1980-01-01')\n",
    "print(f\"Archivos con registros desde el 1980 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('1990-01-01')\n",
    "print(f\"Archivos con registros desde el 1990 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('2000-01-01')\n",
    "print(f\"Archivos con registros desde el 2000 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('2010-01-01')\n",
    "print(f\"Archivos con registros desde el 2010 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "\n",
    "fecha_limite = pd.to_datetime('2012-01-01')\n",
    "print(f\"Archivos con registros desde el 2012 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('2013-01-01')\n",
    "print(f\"Archivos con registros desde el 2013 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "fecha_limite = pd.to_datetime('2014-01-01')\n",
    "print(f\"Archivos con registros desde el 2014 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fecha_limite = pd.to_datetime('2020-01-01')\n",
    "print(f\"Archivos con registros desde el 2020 incluido {df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite].shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad7b339-d997-4af4-9261-c3261dde46d8",
   "metadata": {},
   "source": [
    "De los archivos iniciales nos quedamos con 209 que tenian formato valido, luego determinamos que uno de ellos no tenia registros, posterior a eso encontramos que entre 115 y 130 archivos tienen registros \"actuales\", de estos archivos tomamos aquellos con registros hasta el 31/12/2022 y verificamos que entre 12 y 19 archivos tienen registros de 1970 y 2010. Desde el 2012 comienzan a sumarse nuevas estaciones meteorologicas para registrar datos, llegando a 106 en 2020\n",
    "\n",
    "Vamos a generar dos set de datos para poder trabajar en una etapa posterior con la intenci칩n de buscar desde una generalidad poder predecir la tendencia mas especifica, asi uniremos por un lado los 11 archivos con registros desde el 1970 hasta el 2022 inclusive, y por otro lado los archivos desde el 2020 hasta el 2022 inclusive. La intenci칩n en una primera instancia sera ver si un modelo mas general pero con registros mas antiguos puede ser predictor para registros posteriores usando el otro set de datos (considerando que las ubicaciones geograficas de los centros meteorologicos no son las mismas, pero esperamos que los datos de latitud y longitud puedan brindar una tendencia semejante)\n",
    "\n",
    "Listado \"largo\" : Tendra mayor cantidad de registros historicos pero menor cantidad de provincias\n",
    "Listado \"corto\" : Tendra menor cantidad de registros historicos pero mayor alcance en cantidad de provincias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2180d2fc-60f8-4311-b20a-118bc5bf8aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion y creacion del DataFrame de mayor rango de fecha\n",
    "fecha_limite = pd.to_datetime('1970-01-01')\n",
    "df_listado_archivos_validos_largo = df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite]\n",
    "\n",
    "# Definicion y creacion del DataFrame de menor rango de fecha\n",
    "fecha_limite = pd.to_datetime('2020-01-01')\n",
    "df_listado_archivos_validos_corto = df_listado_archivos_validos[df_listado_archivos_validos['Inicio']<=fecha_limite]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570dd78-6d06-40f5-a6e2-c3151dbb2a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listado_archivos_validos_corto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fee40c-e77e-4811-957c-b16c53c64366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587595e-0d55-4079-b1be-454afa6581df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el formato de la segunda hoja para ver si todos los archivos tienen el mismo formato\n",
    "columnas_extendido= []\n",
    "for archivo in listar_archivos_xls(path_relativo+'/ARCHIVOS'):\n",
    "    df_tmp = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo,sheet_name=1)\n",
    "    columnas= list(df_tmp.columns)\n",
    "    for col in columnas:\n",
    "        if col not in columnas_extendido:\n",
    "            columnas_extendido.append(col)\n",
    "        else:\n",
    "            pass\n",
    "print(columnas_extendido)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96334752-e2e3-4cbb-8ce4-77bdf2345a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resumen_validos = []\n",
    "for archivo_valido in list(df_listado_archivos_validos_corto['Nombre']):\n",
    "    df_tmp = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo_valido)\n",
    "\n",
    "    resumen_validos.append(control_reg_utiles(df_tmp) )\n",
    "    \n",
    "\n",
    "    \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b884a48d-610b-47ae-9c3c-ef3609996e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5664621-5ec7-45de-80ff-9656de25b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_resumen = {}\n",
    "for i in resumen_validos:\n",
    "    for parametro in list(i.keys()):\n",
    "        try:\n",
    "            dict_resumen[parametro] = i[parametro] + dict_resumen[parametro]\n",
    "        except:\n",
    "            dict_resumen[parametro] = i[parametro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa79beea-fc5f-43d7-bf27-1a59eead7ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la media de la usabilidad de una columna sobre el total de los archivos \n",
    "for param,valor in dict_resumen.items():\n",
    "    print(f\"{param} {valor/len(resumen_validos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaabe5e-445f-4b62-8441-d6954070b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la media de la usabilidad de una columna sobre el total de los archivos \n",
    "for param,valor in dict_resumen.items():\n",
    "    indice = valor/len(resumen_validos)\n",
    "    if indice > 70:\n",
    "        print(f\"{param} {indice}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fcfc84-9009-4bf6-b653-57844d57d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basado en el marco teorico seleccionamos las variables que puedan ser de interes a nuestro objetivo\n",
    "columnas_utiles= ['Fecha','Humedad_Media','Tesion_Vapor_Media','Rocio_Medio','Precipitacion_Pluviometrica','Temperatura_Suelo_10cm_Media','Humedad_Media_8_14_20','Velocidad_Viento_Maxima','Temperatura_Abrigo_150cm','Temperatura_Abrigo_150cm_Minima','Velocidad_Viento_200cm_Media','Temperatura_Abrigo_150cm_Maxima']\n",
    "                                                                        \n",
    "archivos_utiles_corto = df_listado_archivos_validos_corto['Nombre'].to_list()\n",
    "archivos_utiles_largo = df_listado_archivos_validos_largo['Nombre'].to_list()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad7254-4525-4c6b-877f-4ddbad3ae44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un DataFrame con todos los registros unidos de todos los archivos, seleccionando previamente los archivos que omitimos, las colunas de interes, y sumando datos de la estacion meteorologica\n",
    "df_corto = pd.DataFrame()\n",
    "\n",
    "for archivo in archivos_utiles_corto:\n",
    "    df_tmp_h0 = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo)\n",
    "    df_tmp_h1 = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo,sheet_name=1)\n",
    "    df_tmp_h1 = df_tmp_h1[['Provincia','Localidad','Latitud','Longitud']]\n",
    "    # Generamos el DataFrame con las columnas que vamos a rescatar de los registros\n",
    "    df_tmp_h0 = df_tmp_h0[columnas_utiles]\n",
    "    # Agregamos los datos de la segunda hoja\n",
    "    df_tmp_h0[['Provincia','Localidad','Latitud','Longitud']] = df_tmp_h1.iloc[0].tolist()\n",
    "    # Unimos todos los archivos en un unico dataframe\n",
    "    df_corto = pd.concat([df_corto,df_tmp_h0])        \n",
    "df_corto['Fecha'] = pd.to_datetime(df_corto['Fecha'])\n",
    "#punto de respaldo y backup - generamos archivo\n",
    "df_corto.to_csv(\"registro_meteorologico_20al22.csv\")\n",
    "\n",
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8fafc4-419f-4b71-8db8-8fcf548aba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" En caso de reiniciar el entorno se puede descomentar las siguientes 2 lineas y avanzar desde este punto\"\"\"\n",
    "#df_corto = pd.read_csv(\"registro_meteorologico_20al22.csv\")\n",
    "#df_corto.drop(df_corto.columns[0],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a3aeb-097f-472f-8602-cd77d48a3b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Producimos el Data Frame largo\n",
    "df_largo = pd.DataFrame()\n",
    "\n",
    "for archivo in archivos_utiles_largo:\n",
    "    df_tmp_h0 = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo)\n",
    "    df_tmp_h1 = pd.read_excel(path_relativo+'/ARCHIVOS/'+archivo,sheet_name=1)\n",
    "    df_tmp_h1 = df_tmp_h1[['Provincia','Localidad','Latitud','Longitud']]\n",
    "    # Generamos el DataFrame con las columnas que vamos a rescatar de los registros\n",
    "    df_tmp_h0 = df_tmp_h0[columnas_utiles]\n",
    "    # Agregamos los datos de la segunda hoja\n",
    "    df_tmp_h0[['Provincia','Localidad','Latitud','Longitud']] = df_tmp_h1.iloc[0].tolist()\n",
    "    # Unimos todos los archivos en un unico dataframe\n",
    "    df_largo = pd.concat([df_largo,df_tmp_h0])        \n",
    "\n",
    "df_largo['Fecha'] = pd.to_datetime(df_largo['Fecha'])\n",
    "# Respaldamos el archivo\n",
    "df_largo.to_csv(\"registro_meteorologico_70al22.csv\")\n",
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04905124-62bc-4022-8fb2-af845b529fa3",
   "metadata": {},
   "source": [
    "# INICIO ANALISIS DATAFRAME DE 2020 AL 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834f409-012b-4094-b8b4-18f17b896752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77acf3e1-611f-474f-8fcb-8ecbd564a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254c7db-065b-45a0-94c2-bed548f205d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay valores a controlar como el rocio medio cuyo minimo es un valor negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dcfce9-fe44-45b7-ac60-a3a963a43320",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_corto[df_corto['Rocio_Medio']<0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1060af-fba9-4a93-b53a-555119cc17af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos los valores negativos de Rocio Medio \n",
    "condicion = df_corto['Rocio_Medio']<0\n",
    "df_corto.loc[condicion, 'Rocio_Medio'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e441dd-90c4-491b-85c6-c1dc94462b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validamos que no hay valores negativo\n",
    "df_corto[df_corto['Rocio_Medio']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54bea9-b756-4e58-a893-13495b34bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos la distribucion de nulos por provincia por parametro\n",
    "for provincia in provincias:\n",
    "    print(f\"--------- {provincia}-----\")\n",
    "    print(df_corto[df_corto['Provincia']==provincia].info())\n",
    "    print(\"================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59cfa82-a6d3-4372-8cba-07e0447b67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a revisar los valores\n",
    "df_corto.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52118420-37e5-4fbe-b98a-d8faf44084bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos el alcance de que provincias estan listadas\n",
    "provincias = list(df_corto['Provincia'].unique())\n",
    "provincias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e95bb9-f9e6-4581-b128-f03b91b2e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos como estan conformados los registros por cada provincia\n",
    "for provincia in provincias:\n",
    "    print(f\"--------- {provincia}-----\")\n",
    "    print(df_corto[df_corto['Provincia']==provincia].info())\n",
    "    print(\"================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575fa85b-1c45-4007-a01c-28015ba9e890",
   "metadata": {},
   "source": [
    "Hay que evaluar como completar los registros faltantes de los campos que tienen valores nulos \n",
    "\n",
    " 1   Humedad_Media      \n",
    "\n",
    " 2   Tesion_Vapor_Media\n",
    " \n",
    " 3   Rocio_Medio       \n",
    " \n",
    " 4   Precipitacion_Pluviometrica\n",
    " \n",
    " 5   Temperatura_Suelo_10cm_Media \n",
    " \n",
    " 6   Humedad_Media_8_14_20        \n",
    " \n",
    " 7   Velocidad_Viento_Maxima      \n",
    " \n",
    " 8   Temperatura_Abrigo_150cm     \n",
    " \n",
    " 9   Temperatura_Abrigo_150cm_Minima\n",
    " \n",
    " 10  Velocidad_Viento_200cm_Media   \n",
    " \n",
    " 11  Temperatura_Abrigo_150cm_Maxima\n",
    "\n",
    "\n",
    " Vamos a definir una tecnica para cada parametro que siga las caracteristicas de dicha variable\n",
    " \n",
    " Humedad_Media\n",
    " \n",
    "Podriamos ver que parametros tenemos disponibles como no nulos para los valores nulos de humedad, y con esto armar un modelo simple de regresion lineal para obtener un valor estimado de humedad.\n",
    "\n",
    "Para esto vamos a verificar la correlaci칩n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc3f65-361f-4962-a15e-3ffebb9afc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que parametros tienen valores validos para nulos de Humedad Media\n",
    "df_corto[(df_corto['Humedad_Media'].isnull())].info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667d269-e460-475a-b36b-dbe0f62d235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_relacionadas = ['Velocidad_Viento_200cm_Media',\n",
    "                    'Velocidad_Viento_Maxima',\n",
    "                    'Temperatura_Abrigo_150cm_Maxima',\n",
    "                    'Humedad_Media',\n",
    "                    'Tesion_Vapor_Media',\n",
    "                    'Rocio_Medio',\n",
    "                    'Temperatura_Abrigo_150cm',\n",
    "                    'Temperatura_Abrigo_150cm_Minima',\n",
    "                    'Precipitacion_Pluviometrica',\n",
    "                    'Humedad_Media_8_14_20',\n",
    "                    'Temperatura_Suelo_10cm_Media'\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e423c0-d4ce-41f0-ba12-45d3fca83a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparamos los parametros para poder evaluar la correlacion eliminando los null\n",
    "df_corto_predictores = df_corto[var_relacionadas].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd82091-5693-404e-b709-07942ecfa348",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_correlacion = df_corto_predictores.corr()\n",
    "def ver_correlacion(matriz_correlacion):\n",
    "    # Configuraci칩n del estilo de seaborn\n",
    "    sns.set(style=\"white\")\n",
    "\n",
    "    # Creaci칩n de la m치scara para la mitad superior de la matriz\n",
    "    mask = np.triu(np.ones_like(matriz_correlacion, dtype=bool))\n",
    "\n",
    "    # Configuraci칩n de la figura matplotlib\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Creaci칩n del mapa de calor con seaborn\n",
    "    cmap = sns.diverging_palette(230, 20, as_cmap=True) # Paleta de colores divergente\n",
    "    sns.heatmap(matriz_correlacion, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True, fmt=\".2f\")\n",
    "\n",
    "    # T칤tulo y ajustes adicionales\n",
    "    plt.title('Matriz de Correlaci칩n de Predictores', fontsize=16)\n",
    "    plt.xticks(rotation=45, ha='right') # Rotaci칩n de etiquetas del eje x\n",
    "    plt.yticks(rotation=0) # Asegura que las etiquetas del eje y no est칠n rotadas\n",
    "    plt.tight_layout() # Ajusta los par치metros de subtrama para un dise침o compacto\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852dc3bd-fc15-4139-be57-83a9d2254dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ver_correlacion(matriz_correlacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c556f3d-6b36-4759-b35b-3107ceed6f03",
   "metadata": {},
   "source": [
    "La humedad media tiene un grado de correlaci칩n muy alto con la humedad_media_8_14_20 , por lo que vamos a tomar una sola de estas variables para el analisis y de ser posible y necesario completaremos la misma con los  valores de la variable Humedad_Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a75e4e-94fe-48d1-8091-446ba433b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos los registros de Humedad Media 8 14 20 nulos mientras Humedad Media no es nula\n",
    "df_corto[(df_corto['Humedad_Media_8_14_20'].isnull()) & (~df_corto['Humedad_Media'].isnull()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01afce9-1430-4b7f-a9c9-0b2ab4749614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el comportamiento estadistico de ambas variables\n",
    "df_corto[(~df_corto['Humedad_Media_8_14_20'].isnull()) & (~df_corto['Humedad_Media'].isnull()) ][['Humedad_Media_8_14_20','Humedad_Media']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb8f5f5-da4d-4893-9410-0bdae538f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La escala y valores de ambas caracteristicas es muy similar en los registros, por lo que vamos a realizar una asignacion directa de una variable a otra para los valores faltantes en vez de desarrollar una regresion para predecir los valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188cbf9-cb75-45b6-b457-61f3e4dc033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le asignamos los valores disponibles en Humedad_Media a Humedad_Media_8_14_20\n",
    "condicion = df_corto['Humedad_Media_8_14_20'].isnull() & (~df_corto['Humedad_Media'].isnull())\n",
    "df_corto.loc[condicion, 'Humedad_Media_8_14_20'] = df_corto.loc[condicion, 'Humedad_Media']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e16e8e6-29f8-4ee6-81ed-a05c72f3591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que no queden valores de Humedad_Media_8_14_20 null que puedan ser asignados por Humedad_Media\n",
    "df_corto[(df_corto['Humedad_Media_8_14_20'].isnull()) & (~df_corto['Humedad_Media'].isnull()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eab3ec-9fd6-490d-8aad-fec9da28f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a991f03-8aee-41e1-ae5a-2664e3ef0ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefinimos las variables de interes quitando la humedad_media\n",
    "df_corto = df_corto.drop(columns=['Humedad_Media'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48daa111-6018-49d9-b026-0d3005ad2c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los registros que tengan nulos en todas estas variables\n",
    "columnas_a_evaluar = [\n",
    "    'Tesion_Vapor_Media',\n",
    "    'Rocio_Medio',\n",
    "    'Precipitacion_Pluviometrica',\n",
    "    'Temperatura_Suelo_10cm_Media',\n",
    "    'Humedad_Media_8_14_20',\n",
    "    'Velocidad_Viento_Maxima',\n",
    "    'Temperatura_Abrigo_150cm',\n",
    "    'Temperatura_Abrigo_150cm_Minima',\n",
    "    'Velocidad_Viento_200cm_Media',\n",
    "    'Temperatura_Abrigo_150cm_Maxima'\n",
    "]\n",
    "\n",
    "# Crear una m치scara booleana para filas con nulos en TODAS las columnas\n",
    "mascara_nulos_en_todas = df_corto[columnas_a_evaluar].isnull().all(axis=1)\n",
    "\n",
    "# Eliminar las filas que cumplen la condici칩n (tienen nulos en TODAS las columnas)\n",
    "df_corto = df_corto[~mascara_nulos_en_todas]\n",
    "\n",
    "\n",
    "print(df_corto.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dec45a-cfbf-440e-b61b-6f8fcf73980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos la distribuci칩n de nulos en la Humedad por provincia\n",
    "for provincia in provincias:\n",
    "    print(f\"{provincia} Nulos en Humedad Media 8 14 20: {df_corto[df_corto['Provincia']==provincia]['Humedad_Media_8_14_20'].isnull().sum()} sobre {df_corto[df_corto['Provincia']==provincia]['Humedad_Media_8_14_20'].shape[0]} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055cc9a3-d075-4787-b317-f54f805da365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizar_nulos(serie):\n",
    "    \"\"\"Visualiza la ubicaci칩n de los valores nulos en una serie.\"\"\"\n",
    "    nulos = serie.isnull()\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(nulos, marker='|', linestyle='None')\n",
    "    plt.title('Ubicaci칩n de valores nulos')\n",
    "    plt.xlabel('칈ndice')\n",
    "    plt.ylabel('Nulo')\n",
    "    plt.yticks([0, 1], ['No Nulo', 'Nulo'])\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce6e7d-7a7e-46c7-94d3-63152c2729f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a ver graficamente la distribuci칩n de nulos en las principales prinvicias\n",
    "visualizar_nulos(df_corto[df_corto['Provincia']=='Buenos Aires']['Humedad_Media_8_14_20'])\n",
    "visualizar_nulos(df_corto[df_corto['Provincia']=='Buenos Aires']['Humedad_Media_8_14_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed541ad6-94a2-46a5-854a-a37d551c3c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196136af-8c68-40d2-a9b4-4b74b182f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci칩n de valores de humedad media en el tiempo por provincia\n",
    "for provincia in provincias:\n",
    "    datos = df_corto[df_corto['Provincia'] == provincia]\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.scatter(datos['Fecha'], datos['Humedad_Media_8_14_20'], alpha=0.6)\n",
    "    plt.title(f'Humedad Media (8-14-20) - {provincia}')\n",
    "    plt.xlabel('칈ndice / Fecha / Tiempo')\n",
    "    plt.ylabel('Humedad Media')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a660cf5-3017-4e7a-83d9-11b3dfbad640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos una muestra de boxplots por provincia por Humedad Media 8 14 20\n",
    "\n",
    "def plot_por_provincia_total(provincias:list,df,variable:str):\n",
    "    \"\"\"\n",
    "    Funcion para graficar un grid de boxplot de valor de la variable en la sumatoria de todos los meses\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cantidad de provincias\n",
    "    n = len(provincias)\n",
    "\n",
    "    # Organizamos el grid\n",
    "    cols = 3\n",
    "    rows = math.ceil(n / cols)\n",
    "\n",
    "    # Crear figura y ejes\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols * 5, rows * 4))\n",
    "    axs = axs.flatten()  # Para acceder a los ejes f치cilmente en 1D\n",
    "\n",
    "    # Generar los boxplots\n",
    "    for i, provincia in enumerate(provincias):\n",
    "        datos = df[df['Provincia'] == provincia][variable].dropna()\n",
    "    \n",
    "        axs[i].boxplot(datos, vert=True)\n",
    "        axs[i].set_title(f'{provincia}')\n",
    "        axs[i].set_ylabel(variable)\n",
    "        axs[i].grid(True)\n",
    "\n",
    "    # Eliminar los subplots vac칤os si hay menos provincias que cuadros\n",
    "    for j in range(i + 1, len(axs)):\n",
    "        fig.delaxes(axs[j])\n",
    "\n",
    "    fig.suptitle(f'Distribuci칩n de {variable} por Provincia', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Deja espacio para el t칤tulo general\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#------\n",
    "def plot_por_provincia_mensual(provincias:list,df,variable:str):\n",
    "    \"\"\"\n",
    "    Funcion para graficar un grid de boxplot de valor de la variable desagregado por mes\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(12, 8))  # Ajusta el tama침o de la figura para mejor visualizaci칩n\n",
    "\n",
    "    for provincia in provincias:\n",
    "        df_provincia = df[df['Provincia'] == provincia]\n",
    "        # Agrupa por MES y calcula el promedio de la variable\n",
    "        promedio_variable = df_provincia.groupby('MES')[variable].mean()\n",
    "        plt.plot(promedio_variable.index, promedio_variable.values, label=provincia)\n",
    "\n",
    "    plt.title(f'{variable} promedio por Mes y Provincia')\n",
    "    plt.xlabel('Mes')\n",
    "    plt.ylabel(variable)\n",
    "    plt.xticks(range(1, 13))  \n",
    "    plt.legend()  \n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_por_provincia_total(provincias,df_corto,'Humedad_Media_8_14_20')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd484e-1005-49ea-9ba3-e3a7389184e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a reformatear el campo Fecha para poder crear nuevas agrupaciones\n",
    "# Eliminar la hora en formato HH:MM:SS\n",
    "patron = r'\\d{2}:\\d{2}:\\d{2}'\n",
    "df_corto['Fecha'] = df_corto['Fecha'].str.replace(patron, \"\", regex=True)\n",
    "\n",
    "# Eliminar espacios extra en cada string (aplicado correctamente con .str)\n",
    "df_corto['Fecha'] = df_corto['Fecha'].str.strip()\n",
    "\n",
    "# Convertir a datetime\n",
    "df_corto['Fecha'] = pd.to_datetime(df_corto['Fecha'], format='%Y-%m-%d', errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b821a48-601b-4860-a11e-8c19eff1f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el campo MES\n",
    "df_corto['MES'] = df_corto['Fecha'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a28fc-9c31-419a-ad42-683d1a6164f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el valor medio mensual de humedad por provincia para completar los valores faltantes\n",
    "# Tomamos el valor medio mensual para el analisis debido a que el clima sigue patrones de series de tiempo regulares\n",
    "\n",
    "# Creamos un diccionario para registrar la media mensual por provincia\n",
    "dic_prov_humedad_media = {}\n",
    "\n",
    "# Asignamos a dicho diccionario la agrupacion mensual de la humedad_media_8_14_20 media\n",
    "for provincia in provincias:\n",
    "    dic_prov_humedad_media[provincia] = df_corto[df_corto['Provincia'] == provincia].groupby('MES')['Humedad_Media_8_14_20'].mean().to_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28bc512-321a-488e-83c9-2585afcbe534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteramos por cada provincia, por cada mes y asignamos el valor obtenido en el proceso anterior\n",
    "for provincia in provincias:\n",
    "    for mes in range(1, 13):  # Iteramos sobre los meses (1 a 12)\n",
    "        valor_medio = dic_prov_humedad_media[provincia][mes - 1]  # Obtenemos el valor medio del mes correspondiente\n",
    "        df_corto.loc[(df_corto['Provincia'] == provincia) & (df_corto['MES'] == mes) & (df_corto['Humedad_Media_8_14_20'].isnull()), 'Humedad_Media_8_14_20'] = valor_medio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc97b5c-3c3e-408c-8b2a-7c6fe2d0cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3798cf6-dfc1-4acb-9122-596c9ebb8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a verificar como queda la distrinuci칩n\n",
    "plot_por_provincia_total(provincias,df_corto,'Humedad_Media_8_14_20')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1843dcc-131c-4337-aaa7-42eb5784a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completar_valores_medios(df,variable:str,provincias:list):\n",
    "    # Asignamos el valor medio mensual de variable por provincia para completar los valores faltantes\n",
    "    dic_prov_media = {}\n",
    "\n",
    "    for provincia in provincias:\n",
    "        # Obtenemos el valor medio por mes por provicincia de la variable deseada , y lo cargamos en el diccionario como una lista de meses\n",
    "        dic_prov_media[provincia] = df[df['Provincia'] == provincia].groupby('MES')[variable].mean().to_list()\n",
    "\n",
    "\n",
    "    for provincia in provincias: \n",
    "        for mes in range(1, 13):  # Iteramos sobre los meses (1 a 12)\n",
    "            valor_medio = dic_prov_media[provincia][mes - 1]  # Obtenemos el valor medio del mes correspondiente\n",
    "            df.loc[(df['Provincia'] == provincia) & (df['MES'] == mes) & (df[variable].isnull()), variable] = valor_medio\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6c689-fde5-4dcc-95b1-bddb95a49f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos los valores faltantes/nulos como media de las siguientes variables\n",
    "df_corto = completar_valores_medios(df_corto,'Tesion_Vapor_Media',provincias)\n",
    "df_corto = completar_valores_medios(df_corto,'Rocio_Medio',provincias)\n",
    "df_corto = completar_valores_medios(df_corto,'Velocidad_Viento_200cm_Media',provincias)\n",
    "df_corto = completar_valores_medios(df_corto,'Precipitacion_Pluviometrica',provincias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b382d-7d75-4c1b-974b-351b8d422500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466ca5c-68bc-4bbc-b11b-97804abd3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_corto[['Temperatura_Abrigo_150cm','Temperatura_Abrigo_150cm_Minima','Temperatura_Abrigo_150cm_Maxima','Temperatura_Suelo_10cm_Media']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70bb76d-4b1a-44df-91a5-f39d7a1c2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto[['Temperatura_Abrigo_150cm','Temperatura_Abrigo_150cm_Minima','Temperatura_Abrigo_150cm_Maxima','Temperatura_Suelo_10cm_Media']].dropna().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea2829-317e-4e69-aecd-50b6365287aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "variables_predictoras = 'Temperatura_Abrigo_150cm'\n",
    "variable_objetivo = 'Temperatura_Suelo_10cm_Media'\n",
    "\n",
    "# Eliminar nulos\n",
    "df_filtrado = df_corto[(df_corto['Provincia']=='Buenos Aires') & (df_corto['MES']==1) ].dropna(subset=[variables_predictoras, variable_objetivo])\n",
    "\n",
    "# Seleccionar columnas\n",
    "X = df_filtrado[variables_predictoras]\n",
    "y = df_filtrado[variable_objetivo]\n",
    "\n",
    "\n",
    "# Graficar\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel(variables_predictoras)\n",
    "plt.ylabel(variable_objetivo)\n",
    "plt.title('Relaci칩n entre ' + variables_predictoras + ' y ' + variable_objetivo)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d718a5-3466-472f-83b7-88e9ce9997f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b2444e-bd2a-455c-8080-8f1cc6a3404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a completar los datos faltantes de Temperatura Suelo a 10cm media, como faltan tantos valores vamos a intentar \n",
    "#aprovechar que las otras temperaturas tienen una correlacion aceptable e intentaremos hacer un regresor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def regresion_lineal_total(df: pd.DataFrame, variables_predictoras: list,variable_objetivo: str):\n",
    "    \"\"\"\n",
    "    Funcion para obtener un regresor con sus metricas\n",
    "    \"\"\"\n",
    "\n",
    "    # Filtrar registros sin valores nulos en variables predictoras y objetivo\n",
    "    df_filtrado = df.dropna(subset=variables_predictoras + [variable_objetivo])\n",
    "\n",
    "    # Separar variables predictoras (X) y variable objetivo (y)\n",
    "    X = df_filtrado[variables_predictoras]\n",
    "    y = df_filtrado[variable_objetivo]\n",
    "\n",
    "    #Divisi칩n de los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    #Creaci칩n y entrenamiento del modelo de regresi칩n lineal\n",
    "    modelo = LinearRegression()\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    #Predicciones y evaluaci칩n del modelo\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    # Calcular m칠tricas de evaluaci칩n\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Error Cuadr치tico Medio (MSE): {mse}\")\n",
    "    print(f\"Coeficiente de Determinaci칩n (R2): {r2}\")\n",
    "\n",
    "    #Visualizaci칩n de los resultados\n",
    "\n",
    "\n",
    "    plt.scatter(y_test, y_pred)\n",
    "    plt.xlabel(\"Valores reales\")\n",
    "    plt.ylabel(\"Valores predichos\")\n",
    "    plt.title(\"Valores reales vs. Valores predichos\")\n",
    "    plt.show()\n",
    "\n",
    "    return modelo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def regresion_lineal_provincial(df: pd.DataFrame ,prov,variables_predictoras: list,variable_objetivo: str):\n",
    "    \"\"\"\n",
    "    Funcion para obtener un regresor con sus metricas\n",
    "    \"\"\"\n",
    "\n",
    "    # Filtrar registros sin valores nulos en variables predictoras y objetivo\n",
    "    df_filtrado = df.dropna(subset=variables_predictoras + [variable_objetivo])\n",
    "\n",
    "    # Separar variables predictoras (X) y variable objetivo (y)\n",
    "    X = df_filtrado[df_filtrado['Provincia']==prov][variables_predictoras]\n",
    "    y = df_filtrado[df_filtrado['Provincia']==prov][variable_objetivo]\n",
    "\n",
    "    #Divisi칩n de los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    #Creaci칩n y entrenamiento del modelo de regresi칩n lineal\n",
    "    modelo = LinearRegression()\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    #Predicciones y evaluaci칩n del modelo\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    # Calcular m칠tricas de evaluaci칩n\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Error Cuadr치tico Medio (MSE): {mse}\")\n",
    "    print(f\"Coeficiente de Determinaci칩n (R2): {r2}\")\n",
    "\n",
    "    #Visualizaci칩n de los resultados\n",
    "\n",
    "\n",
    "    plt.scatter(y_test, y_pred)\n",
    "    plt.xlabel(\"Valores reales\")\n",
    "    plt.ylabel(\"Valores predichos\")\n",
    "    plt.title(\"Valores reales vs. Valores predichos\")\n",
    "    plt.show()\n",
    "\n",
    "    return modelo\n",
    "\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm',\n",
    "    'Temperatura_Abrigo_150cm_Minima',\n",
    "    'Temperatura_Abrigo_150cm_Maxima'\n",
    "                        ]\n",
    "\n",
    "variable_objetivo = 'Temperatura_Suelo_10cm_Media'\n",
    "\n",
    "prov=\"Buenos Aires\"\n",
    "\n",
    "modelo_bsas = regresion_lineal_provincial(df_corto ,prov,variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4dd6dc-fc97-4297-baec-b3d352787ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_lineal_provincial_mensual(df: pd.DataFrame ,prov,variables_predictoras: list,variable_objetivo: str,mes=int):\n",
    "    \"\"\"\n",
    "    Funcion para obtener un regresor con sus metricas\n",
    "    \"\"\"\n",
    "\n",
    "    # Filtrar registros sin valores nulos en variables predictoras y objetivo\n",
    "    df_filtrado = df[ (df['Provincia']==prov) & (df['MES']==mes)].dropna(subset=variables_predictoras + [variable_objetivo])\n",
    "\n",
    "    # Separar variables predictoras (X) y variable objetivo (y)\n",
    "    X = df_filtrado[variables_predictoras]\n",
    "    y = df_filtrado[variable_objetivo]\n",
    "\n",
    "    #Divisi칩n de los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    #Creaci칩n y entrenamiento del modelo de regresi칩n lineal\n",
    "    modelo = LinearRegression()\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    #Predicciones y evaluaci칩n del modelo\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    # Calcular m칠tricas de evaluaci칩n\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Error Cuadr치tico Medio (MSE): {mse}\")\n",
    "    print(f\"Coeficiente de Determinaci칩n (R2): {r2}\")\n",
    "\n",
    "    #Visualizaci칩n de los resultados\n",
    "\n",
    "\n",
    "    plt.scatter(y_test, y_pred)\n",
    "    plt.xlabel(\"Valores reales\")\n",
    "    plt.ylabel(\"Valores predichos\")\n",
    "    plt.title(\"Valores reales vs. Valores predichos\")\n",
    "    plt.show()\n",
    "\n",
    "    return modelo\n",
    "\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm',\n",
    "    'Temperatura_Abrigo_150cm_Minima',\n",
    "    'Temperatura_Abrigo_150cm_Maxima'\n",
    "                        ]\n",
    "\n",
    "variable_objetivo = 'Temperatura_Suelo_10cm_Media'\n",
    "\n",
    "prov=\"Buenos Aires\"\n",
    "\n",
    "modelo_bsas = regresion_lineal_provincial_mensual(df_corto ,prov,variables_predictoras,variable_objetivo,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c23b7b-72e6-4e19-81b0-87e3a1b3d367",
   "metadata": {},
   "source": [
    "Vemos un valor de predicci칩n bastante malo, intentaremos otra forma de regresi칩n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b278104-dcca-4f45-9beb-1551415bb5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetimos quitando las variables con menor correlacion y ejecutamos sobre todo el set de datos\n",
    "\n",
    "\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm'\n",
    "]\n",
    "\n",
    "variable_objetivo = 'Temperatura_Suelo_10cm_Media'\n",
    "\n",
    "\n",
    "prov=\"Buenos Aires\"\n",
    "\n",
    "modelo_bsas = regresion_lineal_provincial(df_corto ,prov,variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d34a3-7f6d-42ee-b8da-408051520579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ae231ad-5a6f-4225-b6c3-3286ed08c4d1",
   "metadata": {},
   "source": [
    "Si bien logramos mejorar los resultados, siguen siendo muy bajos para que tenga sentido utilizar un regresor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc4aacc-a868-4b7a-b5e3-0dd8f6c6aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los valores siguen siendo bajos por lo que vamos a utilizar directamente el valor medio estacional\n",
    "df_corto = completar_valores_medios(df_corto,'Temperatura_Suelo_10cm_Media',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd12b8-9371-471e-8146-437f91dc813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e6b36a-7a4a-4fe1-ae8b-b32b4979b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avanzamos con la variable Precipitacion_Pluviometrica, para esto realizamos una inspeccion de sus estadisticos\n",
    "df_corto['Precipitacion_Pluviometrica'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f7df15-697d-4ff0-951a-9dcb30c4907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_por_provincia_mensual(provincias,df_corto,'Precipitacion_Pluviometrica')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eed728-9935-41ae-8684-2ce76a3c6160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_boxplot_grid(df, provincia_col:str, mes_col:str, valor_col:str):\n",
    "    \"\"\"Crea una grid de boxplots\n",
    "    in: \n",
    "        df: DataFrame a analizar\n",
    "        provincia_col: nombre de la columna donde estan listadas las provincias\n",
    "        mes_col: nombre de la columna donde estan listados los meses\n",
    "        valor_col: nombre de la columna a analizar\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Cada grupo tenga todos los meses\n",
    "    grupos_completos = []\n",
    "    for provincia in df[provincia_col].unique():\n",
    "        for mes in range(1, 13):\n",
    "            grupos_completos.append((provincia, mes))\n",
    "\n",
    "    df_grupos_completos = pd.DataFrame(grupos_completos, columns=[provincia_col, mes_col])\n",
    "    df_completo = pd.merge(df_grupos_completos, df, on=[provincia_col, mes_col], how='left')\n",
    "\n",
    "    # Crear FacetGrid con datos completos\n",
    "    g = sns.FacetGrid(df_completo, col=provincia_col, col_wrap=3, height=4, aspect=1.2)\n",
    "\n",
    "    # Crear boxplots\n",
    "    def boxplot_con_manejo_de_errores(data, **kwargs):\n",
    "        try:\n",
    "            sns.boxplot(data=data, x=mes_col, y=valor_col, **kwargs)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error en boxplot: {e}\")\n",
    "\n",
    "    g.map_dataframe(boxplot_con_manejo_de_errores)\n",
    "\n",
    "    g.set_axis_labels('Mes', valor_col)\n",
    "    g.set_titles(col_template='{col_name}')\n",
    "    g.set_xticklabels(range(1, 13))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "crear_boxplot_grid(df_corto, 'Provincia', 'MES', 'Precipitacion_Pluviometrica')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ee60d-452c-4329-89da-b51306e556ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El evento lluvia sigue siendo atipico , sobre todo en los meses mas lluviosos, en los menos lluviosos es menor el indice de valores oultiers\n",
    "# La matriz de correlacion no mostro ninguna correlacion lineal entre la lluvia y otras variables, por lo que vamos a tomar la normal mensual para completar los regisros.\n",
    "def completar_valores_normal(df: pd.DataFrame,variable:str,provincias:list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Funcion para completar los valores NA de la columna variable con los valores Normales de dicha columna por MES por Provincia\n",
    "    \"\"\"\n",
    "    # Obtenemos el valor medio mensual de humedad por provincia para completar los valores faltantes\n",
    "    dic_prov_normal = {}\n",
    "    # Obtengo la mediana o el valor normal mensual por provincia de la variable\n",
    "    for provincia in provincias:\n",
    "        dic_prov_normal[provincia] = df[df['Provincia'] == provincia].groupby('MES')[variable].median().to_list()\n",
    "\n",
    "\n",
    "    for provincia in provincias: \n",
    "        for mes in range(1, 13):  # Iteramos sobre los meses (1 a 12)\n",
    "            # Obtenemos el valor medio del mes correspondiente\n",
    "            valor_normal = dic_prov_normal[provincia][mes - 1]  \n",
    "            # Asignamos el valor medio del mes correspondiente para cada Provincia\n",
    "            df.loc[(df['Provincia'] == provincia) & (df['MES'] == mes) & (df[variable].isnull()), variable] = valor_normal\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af5da25-9c85-4495-b4d1-ad3f8efe4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completamos los NA de Precipitacion_Pluviometrica usando su valor normal mensua\n",
    "df_corto = completar_valores_normal(df_corto,'Precipitacion_Pluviometrica',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a61ccd-4d7a-42c2-976c-ecca2377b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26855837-620c-45f3-abe1-aea7f14a218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_por_provincia_mensual(provincias,df_corto,'Precipitacion_Pluviometrica')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b11dab-55aa-47a0-8487-6e71040d9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comenzamos a analizar la Velocidad_Viento_Maxima , corroboramos sus estadisticos\n",
    "df_corto[\"Velocidad_Viento_Maxima\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a20b07-e718-4cc6-9c4a-d638d40c9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_por_provincia_mensual(provincias,df_corto,'Velocidad_Viento_Maxima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d28a2b-a422-44bf-ad81-9c6b51e5bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_boxplot_grid(df_corto, 'Provincia', 'MES', 'Velocidad_Viento_Maxima')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec85d532-acf5-4dbb-a292-83afdbdceb4e",
   "metadata": {},
   "source": [
    "Pareceria que hay varias provincias que no tienen datos historicos sobre la velocidad de viento maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f163a543-f10c-40d8-813c-1e14b3f5182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a realizar un control mas simple sobre la cantidad de registros por mes por Provincia\n",
    "conteo_por_mes_provincia = df_corto.groupby(['Provincia', 'MES'])['Velocidad_Viento_Maxima'].count().reset_index(name='conteo')\n",
    "\n",
    "for provincia in provincias:\n",
    "    print(conteo_por_mes_provincia[conteo_por_mes_provincia['Provincia']==provincia])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96ba7c-fd67-497a-aea9-5f569d28cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si bien podriamos intentar generar artificialmente valores para las provincias que no tengan registros, no podemos hacerlo con mecanismos de aprendizaje supervizado, lo que nos llevaria a no tener una buena metrica para evaluar el resultado.\n",
    "# Por lo que vamos a completar los valores de las provincias que tenemos registros y esperar poder conseguir en un futuro registros desde otra base de datos.\n",
    "\n",
    "# Completamos los valores na con el valor normal entre ellos\n",
    "df_corto = completar_valores_normal(df_corto,'Velocidad_Viento_Maxima',provincias)\n",
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a07f197-0cc4-4ec5-bb85-8f84df5af56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_boxplot_grid(df_corto, 'Provincia', 'MES', 'Velocidad_Viento_Maxima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4a976-2efa-467a-aa3f-114ab0115ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_por_provincia_mensual(provincias,df_corto,'Velocidad_Viento_Maxima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62368ac8-f7b8-4528-9f95-b86962f5c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avanzamos con la reconstruccion de registros de las Temperaturas de Abrigo, para esto analizamos la correlacion entre ellas\n",
    "df_corto[['Temperatura_Abrigo_150cm','Temperatura_Abrigo_150cm_Minima','Temperatura_Abrigo_150cm_Maxima']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edbbd1-c2ed-4647-aec7-878391af2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos que variables podrian poblar a cual\n",
    "print(f\"Registros Temp Abrigo null con Temp Abrigo Min no null:{df_corto[(df_corto['Temperatura_Abrigo_150cm'].isnull()) & ~(df_corto['Temperatura_Abrigo_150cm_Minima'].isnull())].shape[0]}\")\n",
    "print(f\"Registros Temp Abrigo null con Temp Abrigo Max no null:{df_corto[(df_corto['Temperatura_Abrigo_150cm'].isnull()) & ~(df_corto['Temperatura_Abrigo_150cm_Maxima'].isnull())].shape[0]}\")\n",
    "print(f\"Registros Temp Abrigo null con Temp Abrigo Min y Max no null:{df_corto[(df_corto['Temperatura_Abrigo_150cm'].isnull()) & ~(df_corto['Temperatura_Abrigo_150cm_Maxima'].isnull()) & ~(df_corto['Temperatura_Abrigo_150cm_Minima'].isnull()) ].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc9d432-8544-4c4a-ac1c-35c4cfc8eb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm_Minima'\n",
    "    \n",
    "]\n",
    "\n",
    "# Variable objetivo\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "\n",
    "\n",
    "\n",
    "regresion_lineal_total(df_corto,variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcffc7d-b656-48be-9f15-d29decfe84cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedemos a probar regresiones que puedan servir para completar registros.\n",
    "#Preparaci칩n de los datos\n",
    "# Variables predictoras\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm_Minima'\n",
    "    \n",
    "]\n",
    "\n",
    "# Variable objetivo\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "\n",
    "\n",
    "regresion_lineal_provincial(df_corto,'Buenos Aires',variables_predictoras,variable_objetivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3695f39c-20dc-4b8a-be40-3efbf2773215",
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_lineal_provincial_mensual(df_corto,'Buenos Aires',variables_predictoras,variable_objetivo,mes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66364772-f427-4dfa-8e73-f1fa1ef24ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_lineal_provincial(df_corto,'Santa Fe',variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad048c8b-9c36-41ac-9580-57e12e0aa322",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_predictoras = [ 'Temperatura_Abrigo_150cm_Minima']\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "\n",
    "modelo_min = regresion_lineal_total(df_corto,variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6204a09c-018e-495d-a249-1bd8e434fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Preparaci칩n de los datos\n",
    "# Variables predictoras\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm_Maxima'\n",
    "    \n",
    "]\n",
    "\n",
    "# Variable objetivo\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "regresion_lineal_provincial(df_corto,'Santa Fe',variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083f737-d4ab-424f-a6df-a4b91d76cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_predictoras = [ 'Temperatura_Abrigo_150cm_Maxima']\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "\n",
    "modelo_max = regresion_lineal_total(df_corto,variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1fbe4-e0c9-4464-a3a6-d216e4d968b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Preparaci칩n de los datos\n",
    "# Variables predictoras\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm_Minima','Temperatura_Abrigo_150cm_Maxima'\n",
    "    \n",
    "]\n",
    "\n",
    "# Variable objetivo\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "regresion_lineal_provincial(df_corto,'Santa Fe',variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b59e75-8986-419b-bcba-a305605da7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_predictoras = ['Temperatura_Abrigo_150cm_Minima', 'Temperatura_Abrigo_150cm_Maxima']\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "modelo_comb = regresion_lineal_total(df_corto,variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c7719-2480-4f87-a00c-31b551eadc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos a los valores null de Temperatura Abrigo 150 los valores del modelo de regresion para las variables Minima y Maxima\n",
    "# Definir variables predictoras\n",
    "variables_predictoras = ['Temperatura_Abrigo_150cm_Minima', 'Temperatura_Abrigo_150cm_Maxima']\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "# Filtro de filas que cumplen ambas condiciones\n",
    "# Resguardamos el Df\n",
    "df_corto_bk = df_corto.copy()\n",
    "\n",
    "filtro = df_corto[variables_predictoras].notnull().all(axis=1) & df_corto[variable_objetivo].isnull()\n",
    "\n",
    "# Seleccionar las filas y variables predictoras para la predicci칩n\n",
    "df_prediccion = df_corto.loc[filtro, variables_predictoras]\n",
    "\n",
    "# Realizar la predicci칩n\n",
    "predicciones = modelo_comb.predict(df_prediccion)\n",
    "\n",
    "# Asignar las predicciones a los valores nulos en el DataFrame original\n",
    "df_corto.loc[filtro, variable_objetivo] = predicciones\n",
    "\n",
    "# 3. (Opcional) Verificar los resultados\n",
    "print(df_corto[filtro][[variable_objetivo] + variables_predictoras])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e676941b-ed89-4605-bd28-d2a4dea8bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos los valores predichos con la predictora de Minima\n",
    "\n",
    "# Definir variables predictoras\n",
    "variables_predictoras = ['Temperatura_Abrigo_150cm_Minima']\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "# Filtro de filas que cumplen ambas condiciones\n",
    "\n",
    "filtro = df_corto[variables_predictoras].notnull().all(axis=1) & df_corto[variable_objetivo].isnull()\n",
    "\n",
    "# Seleccionar las filas y variables predictoras para la predicci칩n\n",
    "df_prediccion = df_corto.loc[filtro, variables_predictoras]\n",
    "\n",
    "# Realizar la predicci칩n\n",
    "predicciones = modelo_min.predict(df_prediccion)\n",
    "\n",
    "# Asignar las predicciones a los valores nulos en el DataFrame original\n",
    "df_corto.loc[filtro, variable_objetivo] = predicciones\n",
    "\n",
    "\n",
    "print(df_corto[filtro][[variable_objetivo] + variables_predictoras])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04676bf5-af8e-4a0d-9a49-a591fec1950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos los valores predichos con la predictora de Maxima\n",
    "# Definir variables predictoras\n",
    "variables_predictoras = ['Temperatura_Abrigo_150cm_Maxima']\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm'\n",
    "# Filtro de filas que cumplen ambas condiciones\n",
    "\n",
    "df_corto_bk = df_corto.copy()\n",
    "filtro = df_corto[variables_predictoras].notnull().all(axis=1) & df_corto[variable_objetivo].isnull()\n",
    "\n",
    "# Seleccionar las filas y variables predictoras para la predicci칩n\n",
    "df_prediccion = df_corto.loc[filtro, variables_predictoras]\n",
    "\n",
    "# Realizar la predicci칩n\n",
    "predicciones = modelo_max.predict(df_prediccion)\n",
    "\n",
    "# Asignar las predicciones a los valores nulos en el DataFrame original\n",
    "df_corto.loc[filtro, variable_objetivo] = predicciones\n",
    "\n",
    "# 3. (Opcional) Verificar los resultados\n",
    "print(df_corto[filtro][[variable_objetivo] + variables_predictoras])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef597dbe-661b-40c6-9dbc-af4276fbd5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a74f959-4ea0-4f52-8306-12ba5e734f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los registros que quedan sin completar los obtenemos por medio de la media mensual por provincia\n",
    "df_corto = completar_valores_medios(df_corto,'Temperatura_Abrigo_150cm',provincias)\n",
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3a26a-db9b-4850-9958-80c2410e7e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los registros que faltan los obtenemos por medio de la norma por provincia\n",
    "df_corto = completar_valores_normal(df_corto,'Temperatura_Abrigo_150cm_Minima',provincias)\n",
    "df_corto = completar_valores_normal(df_corto,'Temperatura_Abrigo_150cm_Maxima',provincias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e00b86-a626-4c95-b12c-259e460a612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad0af1b-9850-499d-8473-2e1d7692da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for provincia in list(df_corto['Provincia'].unique()):\n",
    "    print(f\"{provincia} - {df_corto[df_corto['Provincia'] == provincia]['Fecha'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710704e0-e3c6-4610-8538-b92b7f7a14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el set de datos reconstruido\n",
    "df_corto.to_csv(\"meteorologico_22_23.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa42da4b-6c11-4e84-939a-1bd7afefb3ba",
   "metadata": {},
   "source": [
    "# INICIO ANALISIS df_largo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2b1fc-fd01-41b1-af4f-48410c15c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_largo = pd.read_csv(\"registro_meteorologico_70al22.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac5849-f534-4133-aed4-c802fbd5ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22523a7e-55e1-4b5f-87f2-1f210f63dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f46cfc-2de7-42c8-ab1e-022a8fd2f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dejamos en 0 los valores de Rocio_Medio negativos\n",
    "condicion = df_largo['Rocio_Medio']<0\n",
    "df_largo.loc[condicion, 'Rocio_Medio'] = 0\n",
    "df_largo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f70074-2a56-4fed-9539-c33496d9dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un repaso de los registros historicos de este set de datos\n",
    "for provincia in list(df_largo['Provincia'].unique()):\n",
    "    print(f\"{provincia} - {df_largo[df_largo['Provincia'] == provincia]['Fecha'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a3c004-d601-4b0d-b212-5159e7048dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos la distribucion de nulos por provincia por parametro\n",
    "for provincia in provincias:\n",
    "    print(f\"--------- {provincia}-----\")\n",
    "    print(df_largo[df_largo['Provincia']==provincia].info())\n",
    "    print(\"================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ec6d2-c3c7-4180-a98e-9d6ca962a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos Chaco de los registros ya que no presenta ningun registro valido \n",
    "df_largo = df_largo[df_largo['Provincia']!=\"Chaco\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed3bcd-fca5-41b0-97b6-0685a64b2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comenzamos a regenerar los datos faltantes\n",
    "# Los datos originales de humedad media son muy pocos, por lo que intentar correr algun analisis sobre esta variable seria un desperdicio de recursos, ya vimos en el analisis de df_corto que era posible eliminar esta columna\n",
    "# Mismo criterio vamos a tener con la Temepratura_suelo_10cm\n",
    "df_largo.drop('Unnamed: 0', inplace=True,axis=1)\n",
    "df_largo.drop('Humedad_Media', inplace=True,axis=1)\n",
    "df_largo.drop('Temperatura_Suelo_10cm_Media', inplace=True,axis=1)\n",
    "df_largo.drop('Velocidad_Viento_Maxima', inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d2833-f36c-4678-9025-82929cae2fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2598c72-c2bc-4ab9-a0db-a924a9280c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la hora en formato HH:MM:SS\n",
    "patron = r'\\d{2}:\\d{2}:\\d{2}'\n",
    "df_largo['Fecha'] = df_largo['Fecha'].str.replace(patron, \"\", regex=True)\n",
    "\n",
    "# Eliminar espacios extra en cada string (aplicado correctamente con .str)\n",
    "df_largo['Fecha'] = df_largo['Fecha'].str.strip()\n",
    "\n",
    "# Convertir a datetime\n",
    "df_largo['Fecha'] = pd.to_datetime(df_largo['Fecha'], format='%Y-%m-%d', errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3decf32d-e08f-4c27-99de-9496a3d4ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Recortamos los registros para que no superen el 31 de dic de 2023 ya que no tendremos otros datos para cruzar\n",
    "fecha_limite_max = pd.to_datetime('2023-12-31')\n",
    "fecha_limite_min = pd.to_datetime('1970-01-01')\n",
    "\n",
    "# Filtrar el DataFrame primero por registros anteriores a fecha lim max\n",
    "df_filtrado = df_largo[df_largo['Fecha'] <= fecha_limite_max]\n",
    "# Filtrar por registros posteriores a fecha min\n",
    "df_filtrado = df_largo[df_largo['Fecha'] >= fecha_limite_min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421614a-f1ab-425a-af60-4ef4c3cbb52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c40477-7d62-4cd4-a8c1-2c985e170400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respaldamos el set de datos largo y pasamos a utilizar la version filtrada por a침os\n",
    "df_largo_bk = df_largo.copy()\n",
    "df_largo = df_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525e4bc0-879c-4697-98bd-b7f4ab0436a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f6b4e-6d33-487c-bfc1-babf2f52155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74e89e-105f-4fbe-a4e7-d60bb426b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correlaciones(df: pd.DataFrame,var_relacionadas:list):\n",
    "\n",
    "    # Eliminamos registros con NA para analizar la correlacion\n",
    "    df_largo_predictores = df[var_relacionadas].dropna()\n",
    "    matriz_correlacion = df_largo_predictores.corr()\n",
    "\n",
    "    # Configuraci칩n del estilo de seaborn\n",
    "    sns.set(style=\"white\")\n",
    "\n",
    "    # Creaci칩n de la m치scara para la mitad superior de la matriz\n",
    "    mask = np.triu(np.ones_like(matriz_correlacion, dtype=bool))\n",
    "\n",
    "    # Configuraci칩n de la figura matplotlib\n",
    "    f, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "    # Creaci칩n del mapa de calor con seaborn\n",
    "    cmap = sns.diverging_palette(230, 20, as_cmap=True) # Paleta de colores divergente\n",
    "    sns.heatmap(matriz_correlacion, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True, fmt=\".2f\")\n",
    "\n",
    "    # T칤tulo y ajustes adicionales\n",
    "    plt.title('Matriz de Correlaci칩n de Predictores', fontsize=16)\n",
    "    plt.xticks(rotation=45, ha='right') # Rotaci칩n de etiquetas del eje x\n",
    "    plt.yticks(rotation=0) # Asegura que las etiquetas del eje y no est칠n rotadas\n",
    "    plt.tight_layout() # Ajusta los par치metros de subtrama para un dise침o compacto\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ef0d0-8691-4335-a382-aec61aa57ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_relacionadas = ['Velocidad_Viento_200cm_Media', 'Temperatura_Abrigo_150cm_Maxima', 'Tesion_Vapor_Media', 'Rocio_Medio', 'Temperatura_Abrigo_150cm', 'Precipitacion_Pluviometrica', 'Humedad_Media_8_14_20','Temperatura_Abrigo_150cm_Minima']\n",
    "\n",
    "correlaciones(df_largo,var_relacionadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e95055-64e1-471b-9026-7a5641753618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero el parametro MES\n",
    "df_largo['MES'] = df_largo['Fecha'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ded13c-5788-4bc2-9212-3f3be854f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el parametro Tesion_Vapor_Media\n",
    "\n",
    "crear_boxplot_grid(df_largo, 'Provincia', 'MES', 'Tesion_Vapor_Media')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ffacf6-5c3a-4303-89c2-b2c8ae6b8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo[(df_largo['Provincia']==\"Corrientes\") & (df_largo['MES']==1)]['Tesion_Vapor_Media'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a86985-c7d3-4a4e-af8a-f39456535c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tesion_Vapor_Media nulos: {df_largo['Tesion_Vapor_Media'].isnull().sum()}\")\n",
    "print(f\"Rocio_Medio nulos: {df_largo['Rocio_Medio'].isnull().sum()}\")\n",
    "\n",
    "# Cruces de condiciones\n",
    "print(\"Rocio Medio Nulo para Tesion Vapor Media v치lido:\")\n",
    "print(df_largo[df_largo['Tesion_Vapor_Media'].notnull() & df_largo['Rocio_Medio'].isnull()].shape[0])\n",
    "\n",
    "print(\"Tesion de Vapor Media Nulo para Rocio Medio v치lido:\")\n",
    "print(df_largo[df_largo['Tesion_Vapor_Media'].isnull() & df_largo['Rocio_Medio'].notnull()].shape[0])\n",
    "\n",
    "print(\"Tesion de Vapor Media Nulo para Temperatura de Abrigo M칤nima v치lida:\")\n",
    "print(df_largo[df_largo['Tesion_Vapor_Media'].isnull() & df_largo['Temperatura_Abrigo_150cm_Minima'].notnull()].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85165788-ed46-44d2-8acb-8cab43c1ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_predictoras = ['Tesion_Vapor_Media']\n",
    "variable_objetivo = 'Rocio_Medio'\n",
    "modelo1 = regresion_lineal_total(df_largo,variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa6db5c-ff0e-4708-98f8-ecda6d2888c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resguardamos el Df\n",
    "df_largo_bk = df_largo.copy()\n",
    "\n",
    "filtro = df_largo[variables_predictoras].notnull().all(axis=1) & df_largo[variable_objetivo].isnull()\n",
    "\n",
    "# Seleccionar las filas y variables predictoras para la predicci칩n\n",
    "df_prediccion = df_largo.loc[filtro, variables_predictoras]\n",
    "\n",
    "# Realizar la predicci칩n\n",
    "predicciones = modelo1.predict(df_prediccion)\n",
    "\n",
    "# Asignar las predicciones a los valores nulos en el DataFrame original\n",
    "df_largo.loc[filtro, variable_objetivo] = predicciones\n",
    "\n",
    "# 3. (Opcional) Verificar los resultados\n",
    "print(df_largo[filtro][[variable_objetivo] + variables_predictoras])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b2f583-c7f3-4372-8de7-3bef0bcecce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corregimos los valores por debajo de 0\n",
    "df_largo.loc[df_largo['Rocio_Medio'] < 0, 'Rocio_Medio'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b318458-08b3-45e8-996f-97d29ce37e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedemos a completar los valores faltantes usando la media y la moda\n",
    "provincias = list(df_largo['Provincia'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5105c-a157-487a-ba68-201f2ac5b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo = completar_valores_normal(df_largo,'Tesion_Vapor_Media',provincias)\n",
    "df_largo = completar_valores_normal(df_largo,'Rocio_Medio',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc018d-7705-4cc9-9539-b4a9c1cade86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71753957-39b1-4799-97f3-6cb2b4b6b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empezamos a verificar los valores de Humedad_Media_8_14_20\n",
    "crear_boxplot_grid(df_largo, 'Provincia', 'MES', 'Humedad_Media_8_14_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f7ab6-655c-4627-9a5a-a8306aad6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como ya se pudo ver la humedad no tiene correlacion con otras variables, y no encontramos grandes cantidades de outliers, por lo que usamos la media\n",
    "df_largo = completar_valores_medios(df_largo,'Humedad_Media_8_14_20',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d65256-3c66-4182-a641-bae05822cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_boxplot_grid(df_largo, 'Provincia', 'MES', 'Temperatura_Abrigo_150cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d8f9c-1972-4b2b-830e-03c055b23571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo['Temperatura_Abrigo_150cm'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afffb32-5928-4723-8d8d-a5ee64f6c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo['Temperatura_Abrigo_150cm'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8074acac-6a9a-4bcb-ab02-c16fa2068d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16a547-b16e-4afe-8a2a-67fd34b554d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo = completar_valores_medios(df_largo,'Temperatura_Abrigo_150cm',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb1bf4-7e64-4466-adb2-53357135f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313c77f-85e2-41a5-9fa5-de509005ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_boxplot_grid(df_largo, 'Provincia', 'MES', 'Precipitacion_Pluviometrica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981dbfb4-2742-445a-8144-8b9992fd1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673478b1-fc6e-465a-98ec-c9ebab34a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def asignar_precipitacion_global(df):\n",
    "    \"\"\"\n",
    "    Asigna valores de 'Precipitacion_Pluviometrica' de registros v치lidos a registros nulos\n",
    "    en la misma fecha y provincia, pero en diferente localidad, latitud o longitud.\n",
    "\n",
    "    Args:\n",
    "        df: El DataFrame a modificar.\n",
    "\n",
    "    Returns:\n",
    "        El DataFrame modificado con los valores nulos de 'Precipitacion_Pluviometrica' actualizados.\n",
    "    \"\"\"\n",
    "    # 1. Agrupar por 'Provincia' y 'Fecha'\n",
    "    grouped = df.groupby(['Provincia', 'Fecha'])\n",
    "\n",
    "    # 2. Funci칩n para aplicar a cada grupo\n",
    "    def asignar_grupo(grupo):\n",
    "        # 3. Verificar si hay alg칰n valor no nulo de 'Precipitacion_Pluviometrica' en el grupo\n",
    "        existen_validos = grupo['Precipitacion_Pluviometrica'].notnull().any()\n",
    "\n",
    "        if existen_validos:\n",
    "            # 4. Filtrar los registros nulos de 'Precipitacion_Pluviometrica' en el grupo\n",
    "            df_nulos = grupo[grupo['Precipitacion_Pluviometrica'].isnull()]\n",
    "\n",
    "            # 5. Filtrar los registros no nulos de 'Precipitacion_Pluviometrica' en el grupo\n",
    "            df_no_nulos = grupo[grupo['Precipitacion_Pluviometrica'].notnull()]\n",
    "\n",
    "            # 6. Verificar si existen registros no nulos con diferente Localidad, Latitud o Longitud\n",
    "            if not df_nulos.empty:\n",
    "                registros_validos_distintos = df_no_nulos[\n",
    "                    (~df_no_nulos['Localidad'].isin(df_nulos['Localidad'].unique())) |\n",
    "                    (~df_no_nulos['Latitud'].isin(df_nulos['Latitud'].unique())) |\n",
    "                    (~df_no_nulos['Longitud'].isin(df_nulos['Longitud'].unique()))\n",
    "                ]\n",
    "                if not registros_validos_distintos.empty:\n",
    "                    # 7. Asignar el primer valor no nulo de 'Precipitacion_Pluviometrica' a los registros nulos\n",
    "                    valor_asignar = registros_validos_distintos.iloc[0]['Precipitacion_Pluviometrica']\n",
    "                    grupo.loc[grupo['Precipitacion_Pluviometrica'].isnull(), 'Precipitacion_Pluviometrica'] = valor_asignar\n",
    "        return grupo\n",
    "\n",
    "    # 8. Aplicar la funci칩n a cada grupo y concatenar los resultados\n",
    "    df_modificado = grouped.apply(asignar_grupo).reset_index(level=[0,1], drop=True)\n",
    "    return df_modificado\n",
    "\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# Supongamos que tienes un DataFrame llamado df_largo\n",
    "df_largo_modificado = asignar_precipitacion_global(df_largo.copy()) #Se realiza una copia para no modificar el dataframe original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747d9f4-e335-4223-9223-48a6c6bd8fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo_modificado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f4da6-fa31-4b2c-875a-b310d1519a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_por_provincia_mensual(provincias,df_largo_modificado,'Precipitacion_Pluviometrica')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa74e65d-759f-49b8-8db3-bfeaf59e3d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo = df_largo_modificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e53411-a105-4c2d-811d-73e1aca7120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo[(df_largo['Temperatura_Abrigo_150cm_Minima'].isnull()) & (~df_largo['Temperatura_Abrigo_150cm'].isnull())]['Temperatura_Abrigo_150cm_Minima'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfb4957-62d2-4dc5-934a-a54f15ed2e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preparaci칩n de los datos\n",
    "# Variables predictoras\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm'\n",
    "    \n",
    "]\n",
    "\n",
    "# Variable objetivo\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm_Minima'\n",
    "\n",
    "modelo1 = regresion_lineal_total(df_largo,variables_predictoras,variable_objetivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e41fc-3f0a-4494-bf27-b793c6ffc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_lineal_provincial(df_largo ,'Buenos Aires',variables_predictoras,variable_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abecfcc-707c-44bf-989b-2af150511190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtro de filas que cumplen ambas condiciones\n",
    "# Resguardamos el Df\n",
    "df_largo_bk = df_corto.copy()\n",
    "\n",
    "filtro = df_largo[variables_predictoras].notnull().all(axis=1) & df_largo[variable_objetivo].isnull()\n",
    "\n",
    "# Seleccionar las filas y variables predictoras para la predicci칩n\n",
    "df_prediccion = df_largo.loc[filtro, variables_predictoras]\n",
    "\n",
    "# Realizar la predicci칩n\n",
    "predicciones = modelo1.predict(df_prediccion)\n",
    "\n",
    "# Asignar las predicciones a los valores nulos en el DataFrame original\n",
    "df_largo.loc[filtro, variable_objetivo] = predicciones\n",
    "\n",
    "# 3. (Opcional) Verificar los resultados\n",
    "print(df_largo[filtro][[variable_objetivo] + variables_predictoras])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727fccb-44a7-4135-823d-8fcd293e5fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b4047-94c2-45c8-83ee-58ff5cee9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables= ['Tesion_Vapor_Media',\n",
    " 'Rocio_Medio',\n",
    " 'Precipitacion_Pluviometrica',\n",
    " 'Humedad_Media_8_14_20',\n",
    " 'Temperatura_Abrigo_150cm',\n",
    " 'Temperatura_Abrigo_150cm_Minima',\n",
    " 'Velocidad_Viento_200cm_Media',\n",
    " 'Temperatura_Abrigo_150cm_Maxima']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1925c279-f7b9-4f80-b9b4-48b7b9409bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlaciones(df_largo, variables )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab1d99c-2eea-4763-b55d-7341a5929e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_boxplot_grid(df_largo,'Provincia','MES','Humedad_Media_8_14_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdc496d-22eb-4d98-bbb5-6f11ad68810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos los valores medios\n",
    "completar_valores_medios(df_largo,'Humedad_Media_8_14_20',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf8218-69d5-4684-a91a-437ca4e0560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b52f92-7b40-4bf6-8dcc-64544dfdcb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preparaci칩n de los datos\n",
    "# Variables predictoras\n",
    "variables_predictoras = [\n",
    "    'Temperatura_Abrigo_150cm','Rocio_Medio'\n",
    "    \n",
    "]\n",
    "\n",
    "# Variable objetivo\n",
    "variable_objetivo = 'Temperatura_Abrigo_150cm_Maxima'\n",
    "\n",
    "\n",
    "modelo1 = regresion_lineal_total(df_largo , variables_predictoras,variable_objetivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ae6dc-8300-4242-aea7-b3c904e68ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Filtro de filas que cumplen ambas condiciones\n",
    "# Resguardamos el Df\n",
    "df_largo_bk = df_largo.copy()\n",
    "\n",
    "filtro = df_largo[variables_predictoras].notnull().all(axis=1) & df_largo[variable_objetivo].isnull()\n",
    "\n",
    "# Seleccionar las filas y variables predictoras para la predicci칩n\n",
    "\n",
    "df_prediccion = df_largo.loc[filtro, variables_predictoras]\n",
    "\n",
    "# Realizar la predicci칩n\n",
    "predicciones = modelo1.predict(df_prediccion)\n",
    "\n",
    "# Asignar las predicciones a los valores nulos en el DataFrame original\n",
    "df_largo.loc[filtro, variable_objetivo] = predicciones\n",
    "\n",
    "# 3. (Opcional) Verificar los resultados\n",
    "print(df_largo[filtro][[variable_objetivo] + variables_predictoras])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9da1e-8404-49bc-84e3-10b90a51f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c95261-15df-4f82-b1c2-1cef1c83fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_boxplot_grid(df_largo, 'Provincia', 'MES', 'Velocidad_Viento_200cm_Media')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee3dd1a-e0c3-4e3d-98ed-d4c7de32776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo = completar_valores_normal(df_largo,'Velocidad_Viento_200cm_Media',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56306f6-d8be-4849-b784-3f68b9cdcef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487ee05-2c71-4c04-afe6-fa5bdd5df095",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo = completar_valores_normal(df_largo,'Precipitacion_Pluviometrica',provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c31cfcb-0300-4b63-a389-55ef48db5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo['YEAR'] = df_largo['Fecha'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9069500-403e-4e69-a6e5-f1a7b13fe6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo.groupby(['Provincia','YEAR'])['Fecha'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9401e4-778e-4c4e-a188-03d9762d63b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for provincia in provincias:\n",
    "    min=df_largo[df_largo['Provincia']==provincia]['YEAR'].min()\n",
    "    max=df_largo[df_largo['Provincia']==provincia]['YEAR'].max()\n",
    "    year = df_largo[df_largo['Provincia']==provincia]['YEAR'].unique()\n",
    "    year_reg = year.size\n",
    "    mes_a =0\n",
    "    for a in year:\n",
    "        mes_reg = df_largo[(df_largo['Provincia']==provincia) & (df_largo['YEAR']==a) ]['MES'].unique().size\n",
    "        mes_a = mes_a + mes_reg\n",
    "    \n",
    "    print(\"----------\")\n",
    "    print(f\"{provincia} --- {min}-{max}\")\n",
    "    print(f\"Cantidad de a침os esperados: {max+1-min} registrados: {year_reg}\")\n",
    "    print(f\"Cantidad de meses esperados: {(max+1-min)*12} registrados: {mes_a}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efaa3e6-45bc-40ba-8c26-0ca755e42063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitamos los set de datos a registros de a침os completos, es decir con registros desde que comienza hasta que termina el a침o\n",
    "\n",
    "# Paso 1: Obtener a침o m칤nimo y m치ximo por provincia\n",
    "rango_a침os = df_largo.groupby(\"Provincia\")[\"Fecha\"].agg([\"min\", \"max\"]).reset_index()\n",
    "\n",
    "# Paso 2: Crear los l칤mites ajustados\n",
    "rango_a침os[\"Fecha_min\"] = pd.to_datetime(rango_a침os[\"min\"].dt.year.astype(str) + \"-01-01\")\n",
    "rango_a침os[\"Fecha_max\"] = pd.to_datetime((rango_a침os[\"max\"].dt.year - 1).astype(str) + \"-12-31\")\n",
    "\n",
    "# Paso 3: Merge con el dataframe original\n",
    "df = df_largo.merge(rango_a침os[[\"Provincia\", \"Fecha_min\", \"Fecha_max\"]], on=\"Provincia\")\n",
    "\n",
    "# Paso 4: Filtrar seg칰n esas fechas\n",
    "df_filtrado = df[(df[\"Fecha\"] >= df[\"Fecha_min\"]) & (df[\"Fecha\"] <= df[\"Fecha_max\"])]\n",
    "\n",
    "# Paso 5:  eliminar columnas auxiliares\n",
    "df_filtrado = df_filtrado.drop(columns=[\"Fecha_min\", \"Fecha_max\"])\n",
    "df_filtrado['Fecha'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367a9ab-59ee-4454-8759-5188df21715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado['Fecha'].max()\n",
    "df_filtrado[\"Fecha\"] = pd.to_datetime(df_filtrado[\"Fecha\"])\n",
    "\n",
    "# obtener rango de fechas para cada provincia\n",
    "rango_fechas = df_filtrado.groupby(\"Provincia\")[\"Fecha\"].agg([\"min\", \"max\"]).reset_index()\n",
    "rango_fechas[\"Fecha_min\"] = pd.to_datetime(rango_fechas[\"min\"].dt.year.astype(str) + \"-01-01\")\n",
    "rango_fechas[\"Fecha_max\"] = pd.to_datetime((rango_fechas[\"max\"].dt.year - 1).astype(str) + \"-12-31\")\n",
    "\n",
    "# para cada provincia, generar fechas completas y comparar\n",
    "fechas_faltantes = []\n",
    "\n",
    "for _, row in rango_fechas.iterrows():\n",
    "    provincia = row[\"Provincia\"]\n",
    "    fecha_inicio = row[\"Fecha_min\"]\n",
    "    fecha_fin = row[\"Fecha_max\"]\n",
    "    \n",
    "    # Generar fechas completas\n",
    "    fechas_completas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq=\"D\")\n",
    "    \n",
    "    # Fechas realmente presentes en df_filtrado\n",
    "    fechas_existentes = df_filtrado[df_filtrado[\"Provincia\"] == provincia][\"Fecha\"].unique()\n",
    "    \n",
    "    # Fechas faltantes\n",
    "    faltantes = sorted(set(fechas_completas) - set(fechas_existentes))\n",
    "    \n",
    "    # Guardar en una lista\n",
    "    fechas_faltantes.extend([{\"Provincia\": provincia, \"Fecha\": f} for f in faltantes])\n",
    "\n",
    "# convertir a DataFrame final\n",
    "df_fechas_faltantes = pd.DataFrame(fechas_faltantes)# Suponiendo que df_filtrado es el dataframe previamente generado\n",
    "df_filtrado[\"Fecha\"] = pd.to_datetime(df_filtrado[\"Fecha\"])\n",
    "\n",
    "# obtener rango de fechas ideal para cada provincia\n",
    "rango_fechas = df_filtrado.groupby(\"Provincia\")[\"Fecha\"].agg([\"min\", \"max\"]).reset_index()\n",
    "rango_fechas[\"Fecha_min\"] = pd.to_datetime(rango_fechas[\"min\"].dt.year.astype(str) + \"-01-01\")\n",
    "rango_fechas[\"Fecha_max\"] = pd.to_datetime((rango_fechas[\"max\"].dt.year - 1).astype(str) + \"-12-31\")\n",
    "\n",
    "# para cada provincia, generar fechas completas y comparar\n",
    "fechas_faltantes = []\n",
    "\n",
    "for _, row in rango_fechas.iterrows():\n",
    "    provincia = row[\"Provincia\"]\n",
    "    fecha_inicio = row[\"Fecha_min\"]\n",
    "    fecha_fin = row[\"Fecha_max\"]\n",
    "    \n",
    "    # Generar fechas completas\n",
    "    fechas_completas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq=\"D\")\n",
    "    \n",
    "    # Fechas realmente presentes en df_filtrado\n",
    "    fechas_existentes = df_filtrado[df_filtrado[\"Provincia\"] == provincia][\"Fecha\"].unique()\n",
    "    \n",
    "    # Fechas faltantes\n",
    "    faltantes = sorted(set(fechas_completas) - set(fechas_existentes))\n",
    "    \n",
    "    # Guardar en una lista\n",
    "    fechas_faltantes.extend([{\"Provincia\": provincia, \"Fecha\": f} for f in faltantes])\n",
    "\n",
    "# convertir a DataFrame final\n",
    "df_fechas_faltantes = pd.DataFrame(fechas_faltantes)# Suponiendo que df_filtrado es el dataframe previamente generado\n",
    "df_filtrado[\"Fecha\"] = pd.to_datetime(df_filtrado[\"Fecha\"])\n",
    "\n",
    "# Paso 1: obtener rango de fechas ideal para cada provincia\n",
    "rango_fechas = df_filtrado.groupby(\"Provincia\")[\"Fecha\"].agg([\"min\", \"max\"]).reset_index()\n",
    "rango_fechas[\"Fecha_min\"] = pd.to_datetime(rango_fechas[\"min\"].dt.year.astype(str) + \"-01-01\")\n",
    "rango_fechas[\"Fecha_max\"] = pd.to_datetime((rango_fechas[\"max\"].dt.year - 1).astype(str) + \"-12-31\")\n",
    "\n",
    "# Paso 2: para cada provincia, generar fechas completas y comparar\n",
    "fechas_faltantes = []\n",
    "\n",
    "for _, row in rango_fechas.iterrows():\n",
    "    provincia = row[\"Provincia\"]\n",
    "    fecha_inicio = row[\"Fecha_min\"]\n",
    "    fecha_fin = row[\"Fecha_max\"]\n",
    "    \n",
    "    # Generar fechas completas\n",
    "    fechas_completas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq=\"D\")\n",
    "    \n",
    "    # Fechas realmente presentes en df_filtrado\n",
    "    fechas_existentes = df_filtrado[df_filtrado[\"Provincia\"] == provincia][\"Fecha\"].unique()\n",
    "    \n",
    "    # Fechas faltantes\n",
    "    faltantes = sorted(set(fechas_completas) - set(fechas_existentes))\n",
    "    \n",
    "    # Guardar en una lista\n",
    "    fechas_faltantes.extend([{\"Provincia\": provincia, \"Fecha\": f} for f in faltantes])\n",
    "\n",
    "# Paso 3: convertir a DataFrame final\n",
    "df_fechas_faltantes = pd.DataFrame(fechas_faltantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d3a21-3b5f-4e39-9d61-ae23e87655d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_filtrado[\"Fecha\"] = pd.to_datetime(df_filtrado[\"Fecha\"])\n",
    "\n",
    "# Paso 1: obtener rango de fechas ideal para cada provincia\n",
    "rango_fechas = df_filtrado.groupby(\"Provincia\")[\"Fecha\"].agg([\"min\", \"max\"]).reset_index()\n",
    "rango_fechas[\"Fecha_min\"] = pd.to_datetime(rango_fechas[\"min\"].dt.year.astype(str) + \"-01-01\")\n",
    "rango_fechas[\"Fecha_max\"] = pd.to_datetime((rango_fechas[\"max\"].dt.year - 1).astype(str) + \"-12-31\")\n",
    "\n",
    "# Paso 2: para cada provincia, generar fechas completas y comparar\n",
    "fechas_faltantes = []\n",
    "\n",
    "for _, row in rango_fechas.iterrows():\n",
    "    provincia = row[\"Provincia\"]\n",
    "    fecha_inicio = row[\"Fecha_min\"]\n",
    "    fecha_fin = row[\"Fecha_max\"]\n",
    "    \n",
    "    # Generar fechas completas\n",
    "    fechas_completas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq=\"D\")\n",
    "    \n",
    "    # Fechas realmente presentes en df_filtrado\n",
    "    fechas_existentes = df_filtrado[df_filtrado[\"Provincia\"] == provincia][\"Fecha\"].unique()\n",
    "    \n",
    "    # Fechas faltantes\n",
    "    faltantes = sorted(set(fechas_completas) - set(fechas_existentes))\n",
    "    \n",
    "    # Guardar en una lista\n",
    "    fechas_faltantes.extend([{\"Provincia\": provincia, \"Fecha\": f} for f in faltantes])\n",
    "\n",
    "# Paso 3: convertir a DataFrame final\n",
    "df_fechas_faltantes = pd.DataFrame(fechas_faltantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff2f642-dc9c-4870-be7d-788ccd1c8218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar el dataframe: agregar una columna constante para el eje Y\n",
    "df_fechas_faltantes[\"Y\"] = 1\n",
    "\n",
    "# Obtener lista de provincias\n",
    "provincias = df_fechas_faltantes[\"Provincia\"].unique()\n",
    "n = len(provincias)\n",
    "\n",
    "# Calcular tama침o de grid (cuadrado o casi cuadrado)\n",
    "cols = 4  # pod칠s ajustar este n칰mero\n",
    "rows = math.ceil(n / cols)\n",
    "\n",
    "# Crear figura\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(18, rows * 2.5), sharex=False)\n",
    "axes = axes.flatten()  # para poder indexar f치cilmente\n",
    "# Graficar por provincia\n",
    "for i, provincia in enumerate(provincias):\n",
    "    ax = axes[i]\n",
    "    datos = df_fechas_faltantes[df_fechas_faltantes[\"Provincia\"] == provincia]\n",
    "    ax.scatter(datos[\"Fecha\"], datos[\"Y\"], s=10, color='red', alpha=0.6)\n",
    "    ax.set_title(provincia, fontsize=10)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Quitar ejes vac칤os si sobran\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Layout prolijo\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Fechas faltantes por provincia\", fontsize=14, y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa9a6c5-b59d-4da9-bcbf-ce9295157f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "provincias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fab60-31c7-4d5c-a215-dd96559422ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Obtener rango deseado por provincia (a침o m칤nimo a a침o m치ximo - 1)\n",
    "rango_fechas = df_largo.groupby(\"Provincia\")[\"Fecha\"].agg([\"min\", \"max\"]).reset_index()\n",
    "rango_fechas[\"Fecha_min\"] = pd.to_datetime(rango_fechas[\"min\"].dt.year.astype(str) + \"-01-01\")\n",
    "rango_fechas[\"Fecha_max\"] = pd.to_datetime((rango_fechas[\"max\"].dt.year - 1).astype(str) + \"-12-31\")\n",
    "\n",
    "#  Buscar fechas faltantes por provincia\n",
    "fechas_faltantes = []\n",
    "\n",
    "for _, row in rango_fechas.iterrows():\n",
    "    provincia = row[\"Provincia\"]\n",
    "    fecha_inicio = row[\"Fecha_min\"]\n",
    "    fecha_fin = row[\"Fecha_max\"]\n",
    "    \n",
    "    # Fechas completas esperadas\n",
    "    fechas_completas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq=\"D\")\n",
    "    \n",
    "    # Fechas existentes en df\n",
    "    fechas_existentes = df_largo[df_largo[\"Provincia\"] == provincia][\"Fecha\"].unique()\n",
    "    \n",
    "    # Obtener fechas que faltan\n",
    "    faltantes = sorted(set(fechas_completas) - set(fechas_existentes))\n",
    "    \n",
    "    # Guardar provincia + fecha faltante\n",
    "    fechas_faltantes.extend([{\"Provincia\": provincia, \"Fecha\": f} for f in faltantes])\n",
    "\n",
    "#  Crear DataFrame con fechas faltantes\n",
    "df_fechas_faltantes = pd.DataFrame(fechas_faltantes)\n",
    "\n",
    "#  Crear registros vac칤os con valores nulos y completar info b치sica\n",
    "df_placeholder = pd.DataFrame(columns=df_largo.columns)\n",
    "df_placeholder[\"Fecha\"] = df_fechas_faltantes[\"Fecha\"]\n",
    "df_placeholder[\"Provincia\"] = df_fechas_faltantes[\"Provincia\"]\n",
    "df_placeholder[\"MES\"] = df_placeholder[\"Fecha\"].dt.month\n",
    "df_placeholder[\"YEAR\"] = df_placeholder[\"Fecha\"].dt.year\n",
    "\n",
    "#  Concatenar al DataFrame original\n",
    "df_completo = pd.concat([df_largo, df_placeholder], ignore_index=True)\n",
    "\n",
    "#  Ordenar por provincia y fecha\n",
    "df_completo = df_completo.sort_values(by=[\"Provincia\", \"Fecha\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab643cf3-a65c-4dee-b117-b76b3bd160d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb4e34-597a-4aa5-8391-c2b950f19ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d6e2e-948a-4661-8bd2-2ccf621afd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "# Paso 1: obtener rango de fechas ideal para cada provincia\n",
    "rango_fechas = df_completo.groupby(\"Provincia\")[\"Fecha\"].agg([\"min\", \"max\"]).reset_index()\n",
    "rango_fechas[\"Fecha_min\"] = pd.to_datetime(rango_fechas[\"min\"].dt.year.astype(str) + \"-01-01\")\n",
    "rango_fechas[\"Fecha_max\"] = pd.to_datetime((rango_fechas[\"max\"].dt.year - 1).astype(str) + \"-12-31\")\n",
    "\n",
    "# Paso 2: para cada provincia, generar fechas completas y comparar\n",
    "fechas_faltantes = []\n",
    "\n",
    "for _, row in rango_fechas.iterrows():\n",
    "    provincia = row[\"Provincia\"]\n",
    "    fecha_inicio = row[\"Fecha_min\"]\n",
    "    fecha_fin = row[\"Fecha_max\"]\n",
    "    \n",
    "    # Generar fechas completas\n",
    "    fechas_completas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq=\"D\")\n",
    "    \n",
    "    # Fechas realmente presentes en df_filtrado\n",
    "    fechas_existentes = df_completo[df_completo[\"Provincia\"] == provincia][\"Fecha\"].unique()\n",
    "    \n",
    "    # Fechas faltantes\n",
    "    faltantes = sorted(set(fechas_completas) - set(fechas_existentes))\n",
    "    \n",
    "    # Guardar en una lista\n",
    "    fechas_faltantes.extend([{\"Provincia\": provincia, \"Fecha\": f} for f in faltantes])\n",
    "\n",
    "# Paso 3: convertir a DataFrame final\n",
    "df_fechas_faltantes = pd.DataFrame(fechas_faltantes)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9788c6-baa9-4148-93a0-fac62e5b4e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver cu치ntas filas est치n completamente vac칤as (todas las columnas NaN)\n",
    "filas_nulas_totales = df_completo.isnull().all(axis=1).sum()\n",
    "print(f\"Filas completamente nulas antes de eliminar: {filas_nulas_totales}\")\n",
    "\n",
    "# Eliminar filas completamente nulas\n",
    "df_completo = df_completo[~df_completo.isnull().all(axis=1)]\n",
    "\n",
    "# Verificar nuevamente\n",
    "filas_nulas_totales_despues = df_completo.isnull().all(axis=1).sum()\n",
    "print(f\"Filas completamente nulas despu칠s de eliminar: {filas_nulas_totales_despues}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83569df2-000d-4c86-a95c-f43b0682edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f18145-8f56-4bca-92bd-0190c33d22a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be303e-42bc-4ae8-8ac9-3d6b58d389b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "completar_valores_normal(df_completo,'Velocidad_Viento_200cm_Media',provincias)\n",
    "completar_valores_medios(df_completo,'Tesion_Vapor_Media',provincias)\n",
    "completar_valores_normal(df_completo,'Precipitacion_Pluviometrica',provincias)\n",
    "completar_valores_medios(df_completo,'Humedad_Media_8_14_20',provincias)\n",
    "completar_valores_medios(df_completo,'Temperatura_Abrigo_150cm',provincias)\n",
    "completar_valores_normal(df_completo,'Temperatura_Abrigo_150cm_Minima',provincias)\n",
    "completar_valores_normal(df_completo,'Temperatura_Abrigo_150cm_Maxima',provincias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125800d8-97bd-4072-8ec7-7c48e3de977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99109e6-79d4-4db0-acc6-6eb590899b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "modas = df_completo.groupby(\"Provincia\").agg({\n",
    "    \"Localidad\": lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
    "    \"Latitud\": lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
    "    \"Longitud\": lambda x: x.mode().iloc[0] if not x.mode().empty else None\n",
    "}).reset_index()\n",
    "\n",
    "# Crear un dataframe con los valores nulos en esas columnas\n",
    "mascara_nulos = df_completo[\"Localidad\"].isnull() | df_completo[\"Latitud\"].isnull() | df_completo[\"Longitud\"].isnull()\n",
    "df_nulos = df_completo[mascara_nulos]\n",
    "\n",
    "# Reemplazar los valores nulos con las modas\n",
    "df_nulos = df_nulos.drop(columns=[\"Localidad\", \"Latitud\", \"Longitud\"])\n",
    "df_nulos = df_nulos.merge(modas, on=\"Provincia\", how=\"left\")\n",
    "\n",
    "# Combinar con el resto del dataframe\n",
    "df_no_nulos = df_completo[~mascara_nulos]\n",
    "df_completo_actualizado = pd.concat([df_no_nulos, df_nulos], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba13565-77dd-4e5a-888d-7ad21c3dac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo_actualizado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e48e61-d07c-4903-9dfa-e3122642aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo_actualizado.to_csv(\"clima_completo_largo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00e6d76-652a-42c2-818c-040fa1a450dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05649fb3-09f5-4649-9827-7b33c7ea962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    \"Tesion_Vapor_Media\",\n",
    "    \"Rocio_Medio\",\n",
    "    \"Precipitacion_Pluviometrica\",\n",
    "    \"Humedad_Media_8_14_20\",\n",
    "    \"Temperatura_Abrigo_150cm\",\n",
    "    \"Temperatura_Abrigo_150cm_Minima\",\n",
    "    \"Velocidad_Viento_200cm_Media\",\n",
    "    \"Temperatura_Abrigo_150cm_Maxima\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6f8f2-0c71-402c-b4a6-3d6782dfd13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Agrupar por Fecha y promediar todas las provincias\n",
    "df_promedios = df_completo_actualizado.groupby(\"Fecha\")[variables].mean().reset_index()\n",
    "\n",
    "# Plot general\n",
    "plt.figure(figsize=(15, 6))\n",
    "for var in variables:\n",
    "    sns.lineplot(data=df_promedios, x=\"Fecha\", y=var, label=var, linewidth=1.5)\n",
    "\n",
    "plt.title(\"Tendencias generales por variable (Promedio Nacional)\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4845fa66-517d-48c1-93c6-c266b85c779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener provincias 칰nicas\n",
    "provincias = df_completo_actualizado[\"Provincia\"].unique()\n",
    "n_provincias = len(provincias)\n",
    "n_variables = len(variables)\n",
    "\n",
    "# Tama침o de figura ajustado seg칰n cantidad de gr치ficos\n",
    "fig, axes = plt.subplots(nrows=n_provincias, ncols=n_variables, figsize=(4 * n_variables, 3 * n_provincias), sharex=True)\n",
    "\n",
    "# Loop por cada provincia y variable\n",
    "for i, provincia in enumerate(provincias):\n",
    "    df_prov = df_completo_actualizado[df_completo_actualizado[\"Provincia\"] == provincia]\n",
    "    \n",
    "    for j, var in enumerate(variables):\n",
    "        ax = axes[i, j]\n",
    "        sns.lineplot(data=df_prov, x=\"Fecha\", y=var, ax=ax, linewidth=0.8)\n",
    "        ax.set_title(f\"{provincia} - {var}\", fontsize=8)\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.tick_params(labelsize=6)\n",
    "\n",
    "# Ajustes de presentaci칩n\n",
    "plt.suptitle(\"Evoluci칩n temporal por Provincia y Variable\", fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e25c70b-13d5-42a3-baf5-9954d001c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "variables = [\n",
    "    \"Tesion_Vapor_Media\",\n",
    "    \"Rocio_Medio\",\n",
    "    \"Precipitacion_Pluviometrica\",\n",
    "    \"Humedad_Media_8_14_20\",\n",
    "    \"Temperatura_Abrigo_150cm\",\n",
    "    \"Temperatura_Abrigo_150cm_Minima\",\n",
    "    \"Velocidad_Viento_200cm_Media\",\n",
    "    \"Temperatura_Abrigo_150cm_Maxima\"\n",
    "]\n",
    "provincias = df_completo_actualizado[\"Provincia\"].unique()\n",
    "diccionario_estadisticos = {}\n",
    "\n",
    "for provincia in provincias:\n",
    "    diccionario_estadisticos[provincia] = {}  # Inicializa el diccionario para la provincia\n",
    "    for mes in list(df_completo_actualizado[\"MES\"].unique()):\n",
    "        diccionario_estadisticos[provincia][mes] = {} # Inicializa el diccionario para el mes\n",
    "        for variable in variables:\n",
    "            datos = df_completo_actualizado[(df_completo_actualizado['Provincia'] == provincia) & (df_completo_actualizado['MES'] == mes)][variable].dropna()  # Obtiene los datos de la variable y provincia, eliminando valores nulos\n",
    "            if not datos.empty:  # Verifica que no este vacio el dataframe\n",
    "                Q1 = datos.quantile(0.25)\n",
    "                Q3 = datos.quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                media = datos.mean()\n",
    "                desviacion_estandar = datos.std()\n",
    "                diccionario_estadisticos[provincia][mes][variable] = {\n",
    "                    'Q1': Q1,\n",
    "                    'Q3': Q3,\n",
    "                    'IQR': IQR,\n",
    "                    'Media': media,\n",
    "                    'Desviacion_estandar': desviacion_estandar\n",
    "                }\n",
    "            else:\n",
    "                diccionario_estadisticos[provincia][mes][variable] = None  # En caso de que el dataframe este vacio, le asigno None al diccionario.\n",
    "print(diccionario_estadisticos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed65f4-df3f-4193-8377-d3644e6fa6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_estadisticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553079e6-b51e-4ac0-8760-f67511e802bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def identificar_outliers(df, diccionario_estadisticos, variables):\n",
    "    \"\"\"\n",
    "    Identifica outliers en un DataFrame utilizando los estad칤sticos proporcionados en un diccionario.\n",
    "\n",
    "    Args:\n",
    "        df: El DataFrame a analizar.\n",
    "        diccionario_estadisticos: Un diccionario que contiene los estad칤sticos por provincia, mes y variable.\n",
    "        variables: Lista de las variables a analizar.\n",
    "\n",
    "    Returns:\n",
    "        El DataFrame original con columnas adicionales indicando si cada valor es un outlier.\n",
    "    \"\"\"\n",
    "    for variable in variables:\n",
    "        nombre_columna_outlier = f'{variable}_outlier'  # Nombre de la nueva columna\n",
    "        df[nombre_columna_outlier] = False  # Inicializa la columna con False\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        provincia = row['Provincia']\n",
    "        mes = row['MES']\n",
    "\n",
    "        if provincia in diccionario_estadisticos and mes in diccionario_estadisticos[provincia]:\n",
    "            for variable in variables:\n",
    "                if variable in diccionario_estadisticos[provincia][mes] and diccionario_estadisticos[provincia][mes][variable] is not None:\n",
    "                    Q1 = diccionario_estadisticos[provincia][mes][variable]['Q1']\n",
    "                    Q3 = diccionario_estadisticos[provincia][mes][variable]['Q3']\n",
    "                    IQR = diccionario_estadisticos[provincia][mes][variable]['IQR']\n",
    "                    valor = row[variable]\n",
    "                    limite_inferior = Q1 - 1.5 * IQR\n",
    "                    limite_superior = Q3 + 1.5 * IQR\n",
    "\n",
    "                    if valor < limite_inferior or valor > limite_superior:\n",
    "                        nombre_columna_outlier = f'{variable}_outlier'\n",
    "                        df.at[index, nombre_columna_outlier] = True  # Marca el registro como outlier\n",
    "\n",
    "    return df\n",
    "\n",
    "# Aplica la funci칩n para identificar outliers\n",
    "df_completo_con_outliers = identificar_outliers(df_completo_actualizado.copy(), diccionario_estadisticos, variables)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame con las columnas de outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e91e08-5fcd-4118-842d-e813879c5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo_con_outliers[df_completo_con_outliers['Tesion_Vapor_Media_outlier']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138af85-be6b-498a-af61-11682731a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_outliers_por_anio(df, variables):\n",
    "    \"\"\"\n",
    "    Cuenta los valores at칤picos (True) por a침o y variable en un DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: El DataFrame a analizar.\n",
    "        variables: Lista de las variables originales (sin el sufijo '_outlier').\n",
    "\n",
    "    Returns:\n",
    "        Un DataFrame con el conteo de outliers por a침o y variable.\n",
    "    \"\"\"\n",
    "    # Crear una lista de las columnas de outliers\n",
    "    columnas_outliers = [f'{var}_outlier' for var in variables]\n",
    "\n",
    "    # Agrupar por a침o y contar los valores True en las columnas de outliers\n",
    "    conteo_outliers = df.groupby(df['Fecha'].dt.year)[columnas_outliers].sum().reset_index()\n",
    "    conteo_outliers = conteo_outliers.melt(id_vars='Fecha', value_vars=columnas_outliers, var_name='Variable_Outlier', value_name='Conteo_Outliers')\n",
    "    conteo_outliers['Variable'] = conteo_outliers['Variable_Outlier'].str.replace('_outlier','')\n",
    "    return conteo_outliers\n",
    "\n",
    "# Obtener el conteo de outliers por a침o\n",
    "conteo_outliers_por_anio_df = contar_outliers_por_anio(df_completo_con_outliers, variables)\n",
    "\n",
    "# Imprimir el DataFrame resultante\n",
    "print(conteo_outliers_por_anio_df.head())\n",
    "\n",
    "def graficar_outliers_por_anio(df, titulo):\n",
    "    \"\"\"\n",
    "    Grafica el conteo de outliers por a침o para cada variable.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame con el conteo de outliers por a침o y variable.\n",
    "        titulo: El t칤tulo del gr치fico.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(x='Fecha', y='Conteo_Outliers', hue='Variable', marker='o', data=df)\n",
    "    plt.title(titulo)\n",
    "    plt.xlabel('A침o')\n",
    "    plt.ylabel('Conteo de Outliers')\n",
    "    plt.xticks(df['Fecha'].unique())  # Mostrar ticks para cada a침o\n",
    "    plt.legend(title='Variable')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Graficar el conteo de outliers por a침o\n",
    "graficar_outliers_por_anio(conteo_outliers_por_anio_df, 'Conteo de Outliers por A침o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36732424-eb3c-44e8-8155-0d964299ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largo['Provincia'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8628d30d-5e1d-45bf-9603-10ac150ba318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUSCAR EN EL SET DE DATOS REGISTROS SOBRE TUCUMAN,JUJUY,SALTA,NEUQUEN,CHUBUT,RIO NEGRO, SANTA CRUZ,SAN JUAN, SAN LUIS, MISIONES,CATAMARCA,LA RIOJA,CHACO,FORMOSA,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea686ca8-2e23-4f6c-980e-9422c1ccbaed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dcdff9-e65e-40c8-8866-d9698e29556a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c01419-7b06-4c6c-97f9-14da10451282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81ca808-3529-4ce9-b447-f32551297c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5ab9d-6d53-4f19-be9a-7687652262c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf6f98-7e35-4204-875b-e04a5ca772b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7575293-7ed5-42ae-9141-099a9ccc03e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e7b4d-8e2b-4bf2-a1fa-218609f2eff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca3dc9d-4779-4595-8e96-c623dc6d1091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f2317f7-3350-44a1-9e89-b4d709ea8518",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HACER BATERIA DE GRAFICOS\n",
    "\n",
    "1) Por provincia :\n",
    " HAcer un grafico de curva con todas las provincias desagregadas (una por linea) para cada una de las variables en el tiempo, y poder comparar valores absolutos y tendencias en el tiempo\n",
    " Hacer un grafico de boxplot por cada variable sobre el total de registros, luego repetir con agrupacion mensual, luego agrupacion anual. < esto permite ver dias atipicos, meses atipicos, a침os atipicos\n",
    " Como es analisis climatico se dan procesos ciclicos, por lo que se deberia comparar el comportamiento de cada mes de cada a침o de cada provincia y del general\n",
    " por ejemplo, debemos poder comparar Todos los eneros de Cordoba, luego Todos los Eneros de BsAS, etc..., luego Todos los Febreros de Cordoba, Luego Todos los febreros de bsas...etc  \n",
    " Con esto la idea es ver la tendencia de la evolucion dentro de los ciclos. Esto se debe hacer sobre cada variable de interes\n",
    " Posterior se debe contar la cantidad de outliers dentro de cada categoria dentro de cada provincia, dentro de cada ciclo (cuantos dias en enero fueron ventosos por arriba de la media o abajo de la media hubo), con ese dato sabremos cuantos eventos outliers se han ocurrido en un determinado mes de un determinado a침o\n",
    " La intencion es llegar a una grafica de curva que muestre la evolucion en el tiempo (general y si se puede por variable) por cada provincia de eventos atipicos.\n",
    " Si podemos encontrar una tendencia creciente de eventos atipicos podriamos hablar de una situaci칩n de inestabilidad climatica creciente y con esto demostrar la existencia de una variable que se puede usar para correlacionar con la variacion de las cosechas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
